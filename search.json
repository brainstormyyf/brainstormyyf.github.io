[{"content":"在C++中，标准库提供了一套强大的字符串流类，它们位于\u0026lt;sstream\u0026gt;头文件中。这些类包括std::istringstream、std::ostringstream和std::stringstream，它们允许你在内存中的字符串上进行流式输入输出操作。这些流类为字符串提供了类似于文件I/O的功能，使得字符串的解析和格式化变得非常方便。\nsstream的含义 std::istringstream：这是一个输入字符串流，它可以将一个C++字符串（std::string）作为输入流来处理。使用istringstream，你可以从字符串中读取数据，就像从文件或标准输入流（std::cin）中读取数据一样。 std::ostringstream：这是一个输出字符串流，它允许你向一个C++字符串（std::string）中写入数据。使用ostringstream，你可以将数据格式化成一个字符串，就像格式化输出到文件或标准输出流（std::cout）一样。 std::stringstream：这是一个可以进行双向操作的字符串流，即它可以用于字符串的输入和输出。stringstream结合了istringstream和ostringstream的功能。 sstream的常用用法 1. 初始化 在使用sstream之前，需要包含\u0026lt;sstream\u0026gt;头文件。\n1#include \u0026lt;iostream\u0026gt; 2#include \u0026lt;sstream\u0026gt; 3#include \u0026lt;string\u0026gt; 2. 创建字符串流对象 创建istringstream、ostringstream或stringstream对象，并将字符串传递给构造函数。\n1std::string str = \u0026#34;Hello World This Is A Test\u0026#34;; 2std::istringstream iss(str); 3std::ostringstream oss; 4std::stringstream ss; 3. 输入操作 对于istringstream，你可以使用\u0026gt;\u0026gt;运算符从流中读取数据。\n1std::string token; 2while (iss \u0026gt;\u0026gt; token) { 3 std::cout \u0026lt;\u0026lt; token \u0026lt;\u0026lt; std::endl; 4} 4. 输出操作 对于ostringstream，你可以使用\u0026lt;\u0026lt;运算符向流中写入数据。\n1oss \u0026lt;\u0026lt; \u0026#34;Hello, \u0026#34; \u0026lt;\u0026lt; \u0026#34;World!\u0026#34; \u0026lt;\u0026lt; std::endl; 2oss \u0026lt;\u0026lt; 123 \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; 45.67 \u0026lt;\u0026lt; std::endl; 3std::cout \u0026lt;\u0026lt; oss.str(); 5. 输入输出操作 对于stringstream，你可以同时进行输入和输出操作。\n1ss \u0026lt;\u0026lt; \u0026#34;Hello, World!\u0026#34; \u0026lt;\u0026lt; std::endl; 2std::string str; 3ss \u0026gt;\u0026gt; str; 4std::cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; std::endl; 6. 清除流 使用clear()方法可以清除sstream对象中的内容。\n1oss.clear(); 2oss \u0026lt;\u0026lt; \u0026#34;Hello, C++!\u0026#34;; 3std::cout \u0026lt;\u0026lt; oss.str(); 7. 获取字符串 使用str()方法可以将sstream对象中的内容转换为std::string。\n1std::string str = oss.str(); 2std::cout \u0026lt;\u0026lt; str; 总结 sstream是C++标准库中一个非常有用的部分，它提供了一种在内存中处理字符串的高级方法。通过使用istringstream、ostringstream和stringstream，你可以轻松地对字符串进行解析、格式化和存储。这些流类使得字符串的处理变得更加灵活和高效，是C++编程中不可或缺的工具。\n","date":1709807071,"headings":[{"anchor":"1-初始化","title":"1. 初始化"},{"anchor":"2-创建字符串流对象","title":"2. 创建字符串流对象"},{"anchor":"3-输入操作","title":"3. 输入操作"},{"anchor":"4-输出操作","title":"4. 输出操作"},{"anchor":"5-输入输出操作","title":"5. 输入输出操作"},{"anchor":"6-清除流","title":"6. 清除流"},{"anchor":"7-获取字符串","title":"7. 获取字符串"},{"anchor":"sstream的含义","title":"sstream的含义"},{"anchor":"sstream的常用用法","title":"sstream的常用用法"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","summary":"","title":"sstream的含义和用法","url":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/c++%E8%AF%AD%E6%B3%95/sstream%E7%9A%84%E5%90%AB%E4%B9%89%E5%92%8C%E7%94%A8%E6%B3%95/","year":"2024"},{"content":"在 C++ 中，整数与字符串之间的转换是常见的操作，特别是在处理用户输入、文件读写、数据格式化等场景时。C++ 提供了多种方法来实现这种转换，下面将详细介绍这些方法。\n字符串到整数的转换 atoi 函数 atoi 是一个在 C 语言中广泛使用的函数，它将字符串转换为整数。在 C++ 中，atoi 同样可用，但请注意，它只接受 C 风格的字符串作为参数，即字符串的末尾需要有一个空字符（'\\0'）。\n1#include \u0026lt;cstdlib\u0026gt; 2int num = atoi(\u0026#34;123\u0026#34;); 如果是要转换c++中的string类型字符串,需要使用atoi(str.c_str()) std::stoi 函数 std::stoi 是 C++11 引入的，它更加安全且功能更强大。它可以处理 C++ 风格的字符串，自动处理正负号，并且可以识别多种整数格式（如二进制、八进制、十六进制等）。 1#include \u0026lt;string\u0026gt; 2int num = std::stoi(\u0026#34;123\u0026#34;); std::istringstream 流 使用 std::istringstream 也可以实现字符串到整数的转换。 1#include \u0026lt;sstream\u0026gt; 2std::string str = \u0026#34;123\u0026#34;; 3int num; 4std::istringstream iss(str); 5iss \u0026gt;\u0026gt; num; 整数到字符串的转换 itoa 函数 itoa 函数将整数转换为字符串。在 C++ 中，可以使用 sprintf 函数或 std::to_string 函数来达到类似的效果。 1#include \u0026lt;cstdlib\u0026gt; 2char buffer[10]; 3itoa(123, buffer, 10); // 将123转换为字符串并存储在buffer中 std::to_string 函数 std::to_string 函数是 C++11 引入的，它将整数转换为字符串，并且更加安全和方便。 1#include \u0026lt;string\u0026gt; 2std::string str = std::to_string(123); std::ostringstream 流 使用 std::ostringstream 也可以实现整数到字符串的转换。 1#include \u0026lt;sstream\u0026gt; 2int num = 123; 3std::ostringstream oss; 4oss \u0026lt;\u0026lt; num; 5std::string str = oss.str(); 注意事项 在使用 atoi 和 itoa 时，需要特别注意缓冲区溢出的问题。 std::stoi 和 std::to_string 是 C++ 标准库中推荐使用的函数，它们提供了更好的安全性和便利性。 使用 sprintf 和 std::ostringstream 时，需要确保目标缓冲区足够大，以避免缓冲区溢出。 通过以上介绍，您应该能够了解如何在 C++ 中实现整数与字符串之间的转换。这些方法各有优缺点，选择哪一种取决于您的具体需求和上下文环境。在现代 C++ 编程中，推荐使用 std::stoi 和 std::to_string 函数，因为它们更加安全和高效。 ","date":1709742430,"headings":[{"anchor":"字符串到整数的转换","title":"字符串到整数的转换"},{"anchor":"整数到字符串的转换","title":"整数到字符串的转换"},{"anchor":"注意事项","title":"注意事项"}],"kind":"page","lang":"zh-hans","summary":"","title":"整数与字符串的转换","url":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/c++%E8%AF%AD%E6%B3%95/%E6%95%B4%E6%95%B0%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E8%BD%AC%E6%8D%A2/","year":"2024"},{"content":"C++中的std::string是一个非常有用的类，它提供了对字符串的丰富操作。在这篇博客中，我们将详细介绍std::string的用法，包括它的常用函数和用法。\n1. 定义和初始化 std::string是C++标准库中的一个类，用于表示和处理字符串。你可以使用以下方式来定义和初始化一个std::string对象：\n1#include \u0026lt;iostream\u0026gt; 2#include \u0026lt;string\u0026gt; 3int main() { 4 std::string str1; // 默认构造函数，创建一个空字符串 5 std::string str2 = \u0026#34;Hello World\u0026#34;; // 使用字符串字面量初始化 6 std::string str3(5, \u0026#39;a\u0026#39;); // 创建一个包含5个\u0026#39;a\u0026#39;的字符串 7 return 0; 8} 2. 常用函数 2.1 添加和连接字符串 1std::string str1 = \u0026#34;Hello\u0026#34;; 2std::string str2 = \u0026#34;World\u0026#34;; 3std::string str3 = str1 + \u0026#34; \u0026#34; + str2; // \u0026#34;Hello World\u0026#34; 4str1 += str2; // \u0026#34;HelloWorld\u0026#34; 2.2 访问和修改字符串 1std::string str = \u0026#34;Hello World\u0026#34;; 2char ch = str[0]; // 获取第一个字符 \u0026#39;H\u0026#39; 3str[0] = \u0026#39;h\u0026#39;; // 修改第一个字符为 \u0026#39;h\u0026#39; 2.3 查找子字符串 1std::string str = \u0026#34;Hello World\u0026#34;; 2size_t pos = str.find(\u0026#34;World\u0026#34;); // 查找子字符串 \u0026#34;World\u0026#34;，返回其在str中的位置 3if (pos != std::string::npos) { 4 std::cout \u0026lt;\u0026lt; \u0026#34;Found at position: \u0026#34; \u0026lt;\u0026lt; pos \u0026lt;\u0026lt; std::endl; 5} 2.4 插入和删除字符 1std::string str = \u0026#34;Hello World\u0026#34;; 2str.insert(5, \u0026#34; C++\u0026#34;); // 在位置5插入字符串 \u0026#34; C++\u0026#34;，结果为 \u0026#34;Hello C++ World\u0026#34; 3str.erase(5, 3); // 从位置5开始删除3个字符，结果为 \u0026#34;Hello World\u0026#34; 2.5 子字符串 1std::string str = \u0026#34;Hello World\u0026#34;; 2std::string substr = str.substr(6, 5); // 获取从位置6开始的5个字符，结果为 \u0026#34;World\u0026#34; 2.6 大小写转换 1std::string str = \u0026#34;Hello World\u0026#34;; 2str.erase(0, 5); // 删除前5个字符，结果为 \u0026#34;World\u0026#34; 2.7 删除和替换字符 1std::string str = \u0026#34;Hello World\u0026#34;; 2str.erase(5, 3); // 从位置5开始删除3个字符，结果为 \u0026#34;Hello World\u0026#34; 3str.replace(5, 5, \u0026#34;C++\u0026#34;); // 从位置5开始替换5个字符为 \u0026#34;C++\u0026#34;，结果为 \u0026#34;Hello C++\u0026#34; 2.8 字符串长度 1std::string str = \u0026#34;Hello World\u0026#34;; 2size_t length = str.size(); // 获取字符串长度 3size_t length = str.length(); // 获取字符串长度 3. 迭代器 std::string提供了迭代器，你可以使用它们来遍历字符串中的每个字符：\n1std::string str = \u0026#34;Hello World\u0026#34;; 2for (std::string::iterator it = str.begin(); it != str.end(); ++it) { 3 std::cout \u0026lt;\u0026lt; *it; // 输出字符串中的每个字符 4} 4. 输入和输出 你可以使用std::cin和std::cout来输入和输出std::string对象：\n1std::string str; 2std::cout \u0026lt;\u0026lt; \u0026#34;Enter a string: \u0026#34;; 3std::cin \u0026gt;\u0026gt; str; // 输入字符串 4std::cout \u0026lt;\u0026lt; \u0026#34;You entered: \u0026#34; \u0026lt;\u0026lt; str \u0026lt;\u0026lt; std::endl; // 输出字符串 请注意，std::cin \u0026gt;\u0026gt; str只会读取一个单词，直到遇到空白符。如果你想要读取整行，可以使用std::getline()：\n1std::string line; 2std::getline(std::cin, line); // 读取整行 3std::cout \u0026lt;\u0026lt; \u0026#34;Read line: \u0026#34; \u0026lt;\u0026lt; line \u0026lt;\u0026lt; std::endl; std::getline() 函数可以有第三个参数，这个参数用于指定分隔符。默认情况下，std::getline() 使用换行符（\\n）作为分隔符，但是可以通过第三个参数来改变这个行为。 std::getline() 函数的第三个参数是一个字符，它指定了在读取过程中作为行结束标志的字符。当你指定了这个字符作为分隔符时，std::getline() 会读取输入流，直到遇到这个字符或者到达文件结束（EOF）。这个分隔符字符本身不会被读取或者存储在结果字符串中。 下面是一个使用第三个参数的例子：\n1#include \u0026lt;iostream\u0026gt; 2#include \u0026lt;string\u0026gt; 3int main() { 4 std::string line; 5 std::getline(std::cin, line, \u0026#39;$\u0026#39;); // 使用 \u0026#39;$\u0026#39; 作为分隔符 6 std::cout \u0026lt;\u0026lt; \u0026#34;Read line: \u0026#34; \u0026lt;\u0026lt; line \u0026lt;\u0026lt; std::endl; 7 return 0; 8} 在这个例子中，std::getline() 会读取输入流，直到遇到字符'$'或者换行符。如果输入流中包含'$'，它将不会被包含在line字符串中，而是作为分隔符，导致std::getline()停止读取。 请注意，如果你使用std::getline()来读取文件，并且指定了一个字符作为分隔符，那么这个字符必须在文件结束之前出现，否则std::getline()将会读取直到文件结束，这可能会导致内存问题，因为它会尝试读取整个文件到内存中的字符串。\n5. 总结 std::string是C++中处理字符串的强大工具。它提供了丰富的函数和操作，使字符串处理变得简单和直观。通过掌握std::string的用法，你可以更有效地处理文本数据。\n","date":1709659201,"headings":[{"anchor":"1-定义和初始化","title":"1. 定义和初始化"},{"anchor":"2-常用函数","title":"2. 常用函数"},{"anchor":"21-添加和连接字符串","title":"2.1 添加和连接字符串"},{"anchor":"22-访问和修改字符串","title":"2.2 访问和修改字符串"},{"anchor":"23-查找子字符串","title":"2.3 查找子字符串"},{"anchor":"24-插入和删除字符","title":"2.4 插入和删除字符"},{"anchor":"25-子字符串","title":"2.5 子字符串"},{"anchor":"26-大小写转换","title":"2.6 大小写转换"},{"anchor":"27-删除和替换字符","title":"2.7 删除和替换字符"},{"anchor":"28-字符串长度","title":"2.8 字符串长度"},{"anchor":"3-迭代器","title":"3. 迭代器"},{"anchor":"4-输入和输出","title":"4. 输入和输出"},{"anchor":"5-总结","title":"5. 总结"}],"kind":"page","lang":"zh-hans","summary":"","title":"字符串string","url":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/c++%E8%AF%AD%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2string/","year":"2024"},{"content":"在C++中，没有内建的 for -- in -- 这种循环结构，因为C++是一种静态类型语言，它的循环结构不像一些动态语言（如Python）那样可以直接遍历容器中的元素。不过，C++提供了几种方式来遍历容器或数组：\n1. 使用范围基础的 for 循环（C++11及以后版本）： 你可以使用基于范围的 for 循环来遍历数组或容器中的每个元素。这种循环结构在语法上类似于 for -- in -- 循环。\n1#include \u0026lt;vector\u0026gt; 2#include \u0026lt;iostream\u0026gt; 3int main() { 4 std::vector\u0026lt;int\u0026gt; numbers = {1, 2, 3, 4, 5}; 5 6 for (int number : numbers) { 7 std::cout \u0026lt;\u0026lt; number \u0026lt;\u0026lt; \u0026#34; \u0026#34;; 8 } 9 std::cout \u0026lt;\u0026lt; std::endl; 10 return 0; 11} 2. 使用传统的 for 循环： 对于数组，你可以使用传统的 for 循环来遍历元素。\n1int arr[] = {1, 2, 3, 4, 5}; 2int len = sizeof(arr) / sizeof(arr[0]); 3for (int i = 0; i \u0026lt; len; ++i) { 4 std::cout \u0026lt;\u0026lt; arr[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; 5} 6std::cout \u0026lt;\u0026lt; std::endl; 3. 使用迭代器： 对于标准模板库（STL）中的容器，你可以使用迭代器来遍历元素。\n1#include \u0026lt;vector\u0026gt; 2#include \u0026lt;iostream\u0026gt; 3int main() { 4 std::vector\u0026lt;int\u0026gt; numbers = {1, 2, 3, 4, 5}; 5 6 for (std::vector\u0026lt;int\u0026gt;::iterator it = numbers.begin(); it != numbers.end(); ++it) { 7 std::cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; 8 } 9 std::cout \u0026lt;\u0026lt; std::endl; 10 return 0; 11} 在C++11及以后的版本中，推荐使用基于范围的 for 循环，因为它更加简洁和直观。如果你需要索引，你可以同时使用基于范围的 for 循环和 std::distance 函数来获取当前元素的索引。\n4. 逆向遍历容器 在C++中，vector 是一个顺序容器，它提供了随机访问迭代器，因此你可以很容易地从后向前遍历一个 vector。有几种方法可以实现这一点：\n使用逆向迭代器 vector 类提供了一个名为 rbegin() 的成员函数，它返回一个指向容器最后一个元素的后一个位置的逆向迭代器。还有一个名为 rend() 的成员函数，它返回一个指向容器第一个元素的前一个位置的逆向迭代器。你可以使用这两个迭代器来从后向前遍历 vector。\n1#include \u0026lt;iostream\u0026gt; 2#include \u0026lt;vector\u0026gt; 3int main() { 4 std::vector\u0026lt;int\u0026gt; vec = {1, 2, 3, 4, 5}; 5 for (auto it = vec.rbegin(); it != vec.rend(); ++it) { 6 std::cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; 7 } 8 std::cout \u0026lt;\u0026lt; std::endl; 9 return 0; 10} 使用普通迭代器和自减运算符 如果你不想使用逆向迭代器，你也可以使用普通迭代器和自减运算符来从后向前遍历 vector。\n1#include \u0026lt;iostream\u0026gt; 2#include \u0026lt;vector\u0026gt; 3int main() { 4 std::vector\u0026lt;int\u0026gt; vec = {1, 2, 3, 4, 5}; 5 for (auto it = vec.end() - 1; it \u0026gt;= vec.begin(); --it) { 6 std::cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; 7 } 8 std::cout \u0026lt;\u0026lt; std::endl; 9 return 0; 10} 使用基于范围的for循环和逆向迭代器 从C++11开始，你可以使用基于范围的for循环来简化遍历容器的过程。要使用基于范围的for循环从后向前遍历 vector，你可以结合使用 rbegin() 和 rend()。\n1#include \u0026lt;iostream\u0026gt; 2#include \u0026lt;vector\u0026gt; 3int main() { 4 std::vector\u0026lt;int\u0026gt; vec = {1, 2, 3, 4, 5}; 5 for (auto it : std::vector\u0026lt;int\u0026gt;(vec.rbegin(), vec.rend())) { 6 std::cout \u0026lt;\u0026lt; it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; 7 } 8 std::cout \u0026lt;\u0026lt; std::endl; 9 return 0; 10} 在这个例子中，我们创建了一个新的 vector，它包含了原始 vector 的逆向迭代器范围。这样，基于范围的for循环就可以从后向前遍历元素了。\n","date":1709656030,"headings":[{"anchor":"1-使用范围基础的-for-循环c11及以后版本","title":"1. 使用范围基础的 for 循环（C++11及以后版本）："},{"anchor":"2-使用传统的-for-循环","title":"2. 使用传统的 for 循环："},{"anchor":"3-使用迭代器","title":"3. 使用迭代器："},{"anchor":"4-逆向遍历容器","title":"4. 逆向遍历容器"},{"anchor":"使用基于范围的for循环和逆向迭代器","title":"使用基于范围的for循环和逆向迭代器"},{"anchor":"使用普通迭代器和自减运算符","title":"使用普通迭代器和自减运算符"},{"anchor":"使用逆向迭代器","title":"使用逆向迭代器"}],"kind":"page","lang":"zh-hans","summary":"","title":"循环结构","url":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/c++%E8%AF%AD%E6%B3%95/%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84/","year":"2024"},{"content":"在 C++ 中，array 和 vector 是两种常用的容器类型，用于存储和操作数据集合。它们分别替代了 C 语言中的静态数组和动态数组（通过 malloc 和 realloc 分配的数组）。\nC++ array 的使用 array 是 C++11 引入的，它是一个固定大小的容器，提供了比传统 C 数组更安全、更方便的操作。array 的使用需要包含 \u0026lt;array\u0026gt; 头文件。 成员函数:\nsize()：返回数组的大小。 empty()：检查数组是否为空。 front()：返回数组的第一个元素。 back()：返回数组的最后一个元素。 data()：返回指向数组内部数据的指针。 使用示例: 1#include \u0026lt;iostream\u0026gt; 2#include \u0026lt;array\u0026gt; 3int main() { 4 std::array\u0026lt;int, 5\u0026gt; arr = {1, 2, 3, 4, 5}; // 创建一个包含5个整数的array 5 // 访问元素 6 std::cout \u0026lt;\u0026lt; \u0026#34;第一个元素: \u0026#34; \u0026lt;\u0026lt; arr.front() \u0026lt;\u0026lt; std::endl; 7 std::cout \u0026lt;\u0026lt; \u0026#34;最后一个元素: \u0026#34; \u0026lt;\u0026lt; arr.back() \u0026lt;\u0026lt; std::endl; 8 // 遍历数组 9 for (int i = 0; i \u0026lt; arr.size(); ++i) { 10 std::cout \u0026lt;\u0026lt; arr[i] \u0026lt;\u0026lt; \u0026#39; \u0026#39;; 11 } 12 std::cout \u0026lt;\u0026lt; std::endl; 13 // 使用范围-based for 循环 14 for (const int\u0026amp; num : arr) { 15 std::cout \u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#39; \u0026#39;; 16 } 17 std::cout \u0026lt;\u0026lt; std::endl; 18 return 0; 19} C++ vector 的使用 vector 是一个动态数组，其大小可以在运行时改变。vector 的使用需要包含 \u0026lt;vector\u0026gt; 头文件。 成员函数:\nsize()：返回向量中元素的数量。 capacity()：返回向量当前分配的存储空间大小。 empty()：检查向量是否为空。 push_back()：在向量的末尾添加一个元素。 pop_back()：删除向量的最后一个元素。 front()：返回向量的第一个元素。 back()：返回向量的最后一个元素。 data()：返回指向向量内部数据的指针。 使用示例: 1#include \u0026lt;iostream\u0026gt; 2#include \u0026lt;vector\u0026gt; 3int main() { 4 std::vector\u0026lt;int\u0026gt; vec = {1, 2, 3, 4, 5}; // 创建一个包含5个整数的vector 5 // 添加元素 6 vec.push_back(6); 7 // 访问元素 8 std::cout \u0026lt;\u0026lt; \u0026#34;第一个元素: \u0026#34; \u0026lt;\u0026lt; vec.front() \u0026lt;\u0026lt; std::endl; 9 std::cout \u0026lt;\u0026lt; \u0026#34;最后一个元素: \u0026#34; \u0026lt;\u0026lt; vec.back() \u0026lt;\u0026lt; std::endl; 10 // 遍历向量 11 for (int i = 0; i \u0026lt; vec.size(); ++i) { 12 std::cout \u0026lt;\u0026lt; vec[i] \u0026lt;\u0026lt; \u0026#39; \u0026#39;; 13 } 14 std::cout \u0026lt;\u0026lt; std::endl; 15 // 使用范围-based for 循环 16 for (const int\u0026amp; num : vec) { 17 std::cout \u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#39; \u0026#39;; 18 } 19 std::cout \u0026lt;\u0026lt; std::endl; 20 // 删除最后一个元素 21 vec.pop_back(); 22 return 0; 23} 替代 C 语言中的数组 array 替代了 C 语言中固定大小的数组。 vector 替代了 C 语言中动态分配的数组，如通过 malloc 和 realloc 分配的数组。 ","date":1709572801,"headings":[{"anchor":"c-array-的使用","title":"C++ array 的使用"},{"anchor":"c-vector-的使用","title":"C++ vector 的使用"},{"anchor":"替代-c-语言中的数组","title":"替代 C 语言中的数组"}],"kind":"page","lang":"zh-hans","summary":"","title":"array与vector","url":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/c++%E8%AF%AD%E6%B3%95/array%E4%B8%8Evector/","year":"2024"},{"content":" ","date":1709178234,"headings":[],"kind":"page","lang":"zh-hans","summary":"这篇论文是Hinton的GLOM这个idea的具体实现","title":"Interpretable part-whole hierarchies and conceptual-semantic relationships in neural networks","url":"/ai%E8%AE%BA%E6%96%87/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/interpretable-part-whole-hierarchies-and-conceptual-semantic-relationships-in-neural-networks/","year":"2024"},{"content":" ","date":1709177267,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"Robust Person Re-identification with Neighbor Transformer","url":"/ai%E8%AE%BA%E6%96%87/%E9%87%8D%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/robust-person-re-identification-with-neighbor-transformer/","year":"2024"},{"content":" ","date":1709177267,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"Robust Person Re-identification with Neighbor Transformer","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/%E9%87%8D%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/robust-person-re-identification-with-neighbor-transformer/","year":"2024"},{"content":" ","date":1709176865,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"Feature-Level Modality Compensation for Visible-Infrared Person Re-Identification","url":"/ai%E8%AE%BA%E6%96%87/%E9%87%8D%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/feature-level-modality-compensation-for-visible-infrared-person-re-identification/","year":"2024"},{"content":" ","date":1709176865,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"Feature-Level Modality Compensation for Visible-Infrared Person Re-Identification","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/%E9%87%8D%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/feature-level-modality-compensation-for-visible-infrared-person-re-identification/","year":"2024"},{"content":" ","date":1709175732,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"Transformer-based Object Re-Identification","url":"/ai%E8%AE%BA%E6%96%87/%E9%87%8D%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/transformer-based-object-re-identification/","year":"2024"},{"content":" ","date":1709175732,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"Transformer-based Object Re-Identification","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/%E9%87%8D%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/transformer-based-object-re-identification/","year":"2024"},{"content":" 尽管近年来深度学习在很多单项任务上取得了相当或超过人类水平的成绩，这些深度学习模型都是为固定的任务所设计，无法动态地根据环境而更新。这意味着每当有来自新的分布的数据输入的时候，此类模型都需要同时在整个历史数据上重新进行训练。显然，在持续变化的现实情境中，进行这种数量级的训练是不现实的。\n人工智能的一个关键挑战是建立能在动态变化的环境中运行的实体系统。这样的系统必须在动态变化的环境中，适应不同的任务。Easy for human！Hard for model！\nCNN transformer 获取更具区分性的分类特征\nIdentity loss 三元组四元组 loss\nRe-ranking给定一张query图片q和一个gallery的集和G, 我们把图像映射到一个语义特征空间并根据特征相似度排序得到初始检索列表。然后re-ranking方法能够进一步来修正初始检索结果。\n不拘泥于重识别对象的类型\n聚合（aggregation）指的是在Backbone输出不同尺度的特征图聚合成一个特征向量来表征一个目标\nAuto-augment：直觉上讲，数据增强教会了模型数据不变性。通常图像的数据增强是一个手动设计并完成的过程，比如改变一些像素，水平翻转等。AutoAugment通过强化学习作为搜索策略来自动搜索和改进数据增强。\n聚合（aggregation）指的是在Backbone输出的特征图聚合成一个特征向量来表征一个目标\n小的学习率先训练几个epoch，这是因为网络的参数是随机初始化的，一开始就采用较大的学习率容易数值不稳定。\n为了重新训练分类网络以满足我们的任务要求，使用从任务中收集的数据对ImageNet预训练的模型进行微调。一般来说，我们会添加一个分类器，为了更好地初始化分类器的参数，在训练开始时冻结网络参数只训练分类器的参数，之后再进行整个的端到端训练。\nfind the most similar spatial feature in gallery feature、\nreid涉及ranking list\n拓展查询(QE, Query Expansion): 指对返回的前top@K个结果,包括查询样本本身,对它们的特征求和取平均,以此为检索特征，再做一次查询。目的是为了提高召回率。\n","date":1709174973,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"FastReID A Pytorch Toolbox for General Instance Re-identification","url":"/ai%E8%AE%BA%E6%96%87/%E9%87%8D%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fastreid-a-pytorch-toolbox-for-general-instance-re-identification/","year":"2024"},{"content":" 尽管近年来深度学习在很多单项任务上取得了相当或超过人类水平的成绩，这些深度学习模型都是为固定的任务所设计，无法动态地根据环境而更新。这意味着每当有来自新的分布的数据输入的时候，此类模型都需要同时在整个历史数据上重新进行训练。显然，在持续变化的现实情境中，进行这种数量级的训练是不现实的。\n人工智能的一个关键挑战是建立能在动态变化的环境中运行的实体系统。这样的系统必须在动态变化的环境中，适应不同的任务。Easy for human！Hard for model！\nCNN transformer 获取更具区分性的分类特征\nIdentity loss 三元组四元组 loss\nRe-ranking给定一张query图片q和一个gallery的集和G, 我们把图像映射到一个语义特征空间并根据特征相似度排序得到初始检索列表。然后re-ranking方法能够进一步来修正初始检索结果。\n不拘泥于重识别对象的类型\n聚合（aggregation）指的是在Backbone输出不同尺度的特征图聚合成一个特征向量来表征一个目标\nAuto-augment：直觉上讲，数据增强教会了模型数据不变性。通常图像的数据增强是一个手动设计并完成的过程，比如改变一些像素，水平翻转等。AutoAugment通过强化学习作为搜索策略来自动搜索和改进数据增强。\n聚合（aggregation）指的是在Backbone输出的特征图聚合成一个特征向量来表征一个目标\n小的学习率先训练几个epoch，这是因为网络的参数是随机初始化的，一开始就采用较大的学习率容易数值不稳定。\n为了重新训练分类网络以满足我们的任务要求，使用从任务中收集的数据对ImageNet预训练的模型进行微调。一般来说，我们会添加一个分类器，为了更好地初始化分类器的参数，在训练开始时冻结网络参数只训练分类器的参数，之后再进行整个的端到端训练。\nfind the most similar spatial feature in gallery feature、\nreid涉及ranking list\n拓展查询(QE, Query Expansion): 指对返回的前top@K个结果,包括查询样本本身,对它们的特征求和取平均,以此为检索特征，再做一次查询。目的是为了提高召回率。\n","date":1709174973,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"FastReID A Pytorch Toolbox for General Instance Re-identification","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/%E9%87%8D%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fastreid-a-pytorch-toolbox-for-general-instance-re-identification/","year":"2024"},{"content":"论文获取链接：Driver State Monitoring System Based on YOLOv5 and Dlib | SpringerLink\n","date":1709140335,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"论文内容","url":"/%E5%AE%89%E5%85%A8%E9%A9%BE%E9%A9%B6/%E8%AE%BA%E6%96%87%E5%86%85%E5%AE%B9/","year":"2024"},{"content":" ","date":1709140313,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"论文接收证书","url":"/%E5%AE%89%E5%85%A8%E9%A9%BE%E9%A9%B6/%E8%AE%BA%E6%96%87%E6%8E%A5%E6%94%B6%E8%AF%81%E4%B9%A6/","year":"2024"},{"content":" ","date":1709137630,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"获奖证书","url":"/%E8%A7%86%E9%A2%91%E4%BA%BA%E5%83%8F%E5%88%86%E5%89%B2/%E8%8E%B7%E5%A5%96%E8%AF%81%E4%B9%A6/","year":"2024"},{"content":"赛题编号及名称： 【A05】视频人像分割算法【万兴科技】团队编号： 2103655\n完成时间： 2022 年 4 月\n第一章 前言 近年来，随着深度学习的不断发展，计算机视觉应用火热。第十三届中国大学生服务外包-创新创业大赛上，在【A05】给出了视频人像分割算法的赛题，来自中南大学的计院打工人队基于已有技术和可实现的模型，实现了在不依赖网络的情况下，向程序输入一个待分割的视频，程序自动输出分割后的人像前景结果的既定需求。并且团队在此基础上精益求精，不断改进模型性能，在应用到赛题方提供的测试集时，获得良好的效果。接下来，我们将会从产品概述，产品设计，产品的测试与实现等维度对于相关成果进行阐述。\n第二章 作品概述 2.1 背景及研发意义 计算机视觉因为深度学习的发展,近年来应用非常的火热。效能和速度也不断的精进, 过去从云端的服务,逐步脱离云服务发展到 PC 端边缘运算,到这几年再往移动端运算发展。尽管移动端运算能力越来越强大,轻量级模型的架构设计也是一个很重要的因素。\n图像语义分割算法逐步成熟，计算机硬件的计算能力越来越强大,算法的落地装置从云服务器端转移到边缘计算端,不管是在视频特效应用或是视频会议软件虚拟背景相关应用则越来越常见。图像语义分割中的视频人像分割算法,主要注重的是精细度和速度，尤其是在 PC 或是移动端上更有其挑战性。\n此赛题专注在快速的人像分割算法,主要目标为设计一个抠图算法在不使用 GPU 的环境下运行,在精细度、速度和模型大小上取得平衡。\n而在产品的研发意义方面，我们发现在当下，随着直播等在线多媒体行业的发展，高效的视频人像分割算法应用前景十分广阔。在一些例如在线会议，新闻播报等需要实 时交互的场合，替换背景往往需要在主持人身后添加绿屏道具。此时若能利用视频人像分割算法，便可在无需道具的条件下替换背景，从而降低替换背景的成本。另外，视频人像分割算法也可以被用于处理部分视频素材，对其中的人像或人像外的背景进行提取，方便创作者利用素材，创作出大众喜闻乐见的娱乐视频作品。\n2.2 作品简介 团队以收集开源数据和自主建立数据集的方式获得数据、建立人像分割算法模型。并完成模型训练、优化、工程化等工作，最终产出一个可执行程序，针对赛题方给出的 20 个视频测试集进行人像分割。\n并且，程序提供 PC 端可执行程序入口，实现了在不依赖网络的情况下，向程序输入一个待分割的视频，程序自动输出分割后的人像前景结果与视频 Mask；向程序输入待分割的图片，程序自动输出分割后的图片 Mask。\n2.3 模型特色 （1）连贯提取视频人像，抑制了闪烁、残影问题\n其主要解决方法在 RNN 的应用，视频是有关联图像的序列，在处理视频时充分考虑了视频前几帧与本帧在时间和空间维度上的相关性，减少了残影与闪烁问题；\n我们发现,当前主流的视频处理算法把视频的每一帧当作独立的图像来处理，输出都是只考虑前一个输入的影响而不考虑其它时刻输入的影响,这样仅对于单个图像的识别具有较好的效果。但是, 这种算法没有考虑到视频本身的特性，不能利用到视频时间序列给出的信息。对于解决一些与时间先后有关的问题, 比如视频的下一时刻的预测等,这些算法的表现就不尽如人意。RNN 是一种特殊的神经网络结构,具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。\n（2）对高清视频的快速处理\n首先通过下采样的操作，使我们的算法在较低像素维度上进行运算处理，最后再通过 DGF（deep guided filter）上采样的处理,把抠图 mask 恢复到原始分辨率，这极大加速了对于高分辨率视频的处理。其中，对 1080P 视频的处理，在不使用 GPU 的情况下，也能达到 20fps。\n（3）“发丝级”的精准识别\n模型在多个维度上进行学习，使其自身更好地理解了人像本身的特征，能够识别高矮胖瘦的人，能够识别全身像、半身像，进而提高了预测的精准度，实现了“发丝级”的抠图；\n我们通过应用运动和时间增强来增加数据的多样性。运动增强包括仿射平移、缩放、旋转、纯粹、亮度、饱和度、对比度、色调、噪声和模糊。增强还向图像数据集添加了人工运动。时间增强包括剪辑反转、速度变化、随机暂停和跳帧。此外还有其他的离散增强也被应用到了模型中去。\n第三章 系统设计 3.1 总体设计 3.1.1 什么是人像抠图、人像分割 对于一张图 I， 我们感兴趣的人像部分称为前景 F，其余部分为背景 B，则图像 I 可以视为 F 与 B 的加权融合：I = alpha * F + (1 - alpha) * B，而抠图任务就是找到合适的权重 alpha。值得一提的是，如图，查看抠图 ground truth 可以看到，alpha 是 [0, 1]之间的连续值，可以理解为像素属于前景的概率。而在人像分割任务中，alpha只能取 0 或 1，本质上是分类任务，而抠图是回归任务。虽然人像抠图与人像分割有细微的不同，但是我们认为二者是联系紧密的，人像抠图可以看作是人像分割的边缘细化处理，人像分割也可以帮助人像抠图的训练过程。\n抠图 ground truth 分割 ground truth 3.1.2 视频人像抠图 视频人像分割实现的抠图部分是实现从输入帧中预测 alpha 和 foreground 的过程。每一帧 I 可以看作是前景 F 和背景 B 通过α系数的线性组合:I=αA +（1-α）B。通过提取α，我们获得一个图像的背景与前景，达到视频人像分割的效果。\n在处理视频人像抠图时我们应充分考虑到视频的特殊性，视频是一系列帧的序列，序列包含了时间上的信息，如果我们把每一帧当作独立的图像来做处理，则没有利用到时间上的信息，提取出的人像存在不连贯的问题，体现在提取视频上则是闪烁和残影问题。\n为此在现有理论下，我们采用的模型使用了 RNN 的方法（RNN 网络具有时间序列学习的先验知识），使模型可以学习到时间序列的信息，以此可以提高视频抠图性能。首先，它允许预测更连贯的结果，因为模型可以看到多个帧和它自己的预测。这显著减少了闪烁并提高了感知质量。其次，时间信息可以提高抠图的鲁棒性。第三，时间信息允许模型随着时间的推移更多地了解背景。因此，我们采用的是一种循环架构来利用时间信息。并且，在应用时，该模型不需要任何 trimap 输入。\n不仅如此，模型采用一种新的训练策略来满足抠图和语义分割目标。大多数现有方法都是在合成消光数据集上训练的。样本通常看起来很假，并阻止网络泛化为真实图像。我们认为人类抠图任务与人类分割任务密切相关。\n3.2 模型设计 3.2.1 模型架构 模型流程图展示\n我们的架构由一个提取单个帧特征的编码器（encoder）、一个聚合时间信息的循环解码器（recurrent decoder）和一个用于高分辨率上采样的深度引导滤波器模块（Deep Guided Filter module）组成。上图显示了我们的模型架构。其中，我们的精度格式为 FP32，参数量（Params）为 3.75MB，计算量（Flops）为 0.775GFlops，模型大小 14.2MB。\n模型的算法总的来说就是一个将输入帧通过下采样得到不同分辨率下的尺度特征，再一步步通过卷积的上采样形式结合矫正算法使得输入帧重新得到高分辨率的前景以及 alpha 的过程。\n3.2.2 编码器 在编码器部分，我们采用 MobileNetV3-Large 作为我们的主干， 然后采用 MobileNetV3 提出的用于语义分割任务的 LR-ASPP 模块。此外，MobileNetV3 的最后一个块使用扩张卷积而没有下采样步幅。编码器模块对单个帧进行操作，并为循环解码器提取 1/2 、1/4 、1/8 和 1/16 尺度的特征。由此来适应十六个通道的工作。上述即为 Encoder 覆盖括号内的内容。\n3.2.3 循环解码器 在解码器部分，鉴于循环机制可以在连续的视频流上自行学习要保留和忘记哪些信息以及循环机制自适应地保留长期和短期时间信息的能力非常可观，我们的解码器采用多个尺度的 ConvGRU 来聚合时间信息。\n解码器由瓶颈块（bottle-neck block）、上采样块（upsampling block）和输出块（out put）组成。通过 split 和 concatation 在一半的通道上应用 ConvGRU 有效且高效。这种设计有助于 ConvGRU 专注于聚合时间信息，而另一个被 split 的分支则转发特定于当前帧的空间特征。除了最后一个投影使用 1 × 1 内核之外，所有卷积都使用3 × 3 内核。\nMobileNetV3 通过结合硬件感知网络架构搜索(NAS)和 NetAdapt 算法，对移动端的 cpu进行调优，然后通过新的架构改进对其进行改进。MobileNetV1 使用高效的深度可分离卷积来替代传统卷积。深度可分离卷积通过将空间滤波与特征生成机制分离，有效的分解了传统卷积。MobileNetV2 引入线性 bottleneck 与反向 ResNet 结构来利用问题的低秩性使得层结构更加高效。而对于 MobileNetV3，则使用这些层的组合来构建更加高效的模块。因此获得更加高效和便捷的运算模块。\nLR-ASPP 主要将MobileNetV3 的最后一个 block 中不同 resolution 的信息，通过与 SE- net，skip-connection 相结合，实现移动端的图像分割。\nConvGRU 是一种循环神经网络，是 LSTM 的变种，在 LSTM 神经网络的基础上优化了 cell结构减少了参数，加快了训练速度。LSTM 的 cell 结构分为：遗忘门，决定前一层传递过来的多大程度被遗忘掉；输入门，控制当前计算的新状态多大程度更新到记忆细胞中；输出门，控制当前输出有多大程度取决于当前的记忆单元；记忆单元，可以看出细胞状态是有权重、输入、上一层的隐含层输入、上一层的记忆单元状态、输入门综合计算得到的；而本层的隐含层状态则是由输出门与记忆细胞状态决定。GRU 摒弃了 LSTM 中的记忆单元，并将输入门和遗忘门结合成了更新门（update gate），用来决定有多少迁移一层的状态要更新当前神经元中，因此更容易用来聚合时间信息。\nbottle-neck block 在 LR-ASPP 模块之后，瓶颈块以 1/16 个特征尺度运行。ConvGRU层通过 split 和 concat 仅在一半的通道上运行。这显着减少了参数和计算量，因为 ConvGRU 在计算上是可扩展的。\n上采样块以 1/8 、 1/4 和 1/2 的比例重复。首先，它将前一个块的双线性上采样输出、编码器相应比例的特征图和通过重复的 2×2 平均池化下采样的输入图像连接起来。然后，应用卷积，然后是 Batch Normalization（深度网络中经常用到的加速神经网络训练，加速收敛速度及稳定性的算法）和 ReLU（使用激活函数来加入非线性因素，提高模型的表达能力）来执行特征合并和通道缩减。最后，通过 split 和 concat 将 ConvGRU 应用于一半的通道。\nOutput 使用常规卷积来细化结果。它首先连接输入图像和前一个块的双线性上采样输出。然后它使用 2 次重复卷积、批量归一化和 ReLU 堆栈来产生最终的隐藏特征。最后，将特征投影到输出。\n3.2.4 上采样模块 我们采用深度引导滤波器（DGF）进行高分辨率预测。在处理高分辨率视频时，我们将输入帧通过下采样（downsample）得到一个因子 s，然后再通过编码器-解码器网络。然后将低分辨率 alpha、foreground、final hidden features 以及高分辨率输入帧提供给 DGF 模块以产生高分辨率 alpha 和前景。DGF 模块是可选模块，如果要处理的视频分辨率较低，则编码器解码器网络可以独立运行。\n：DGF 为深度引导滤波器，是在引导滤波器的基础上加入了可学习的参数之后使其对于联合上采样问题的解决具有较好的处理能力。DFG 可以解决 Joint Upsampling 任务，给它一个高分辨率的输入图像和一个低分辨率输出图像，算法可以输出高分辨率的输出图像，它的细节和边缘与原始给定图像相似。\n第四章 工程化实现 4.1 深度学习的工作流程 下图为深度学习的一般工作流程。在得到训练好的 pytorch 模型后，最终要应用到实际社会生产中，模型的部署是必不可少的一步。直接使用基于 python 的深度学习框架在 CPU 部署模型，模型运算效率较低。在追求低延时的场景下，这样的方式几乎不可取。那么在这种情况下 ONNX 就是一个大杀器了。\n4.2 什么是 ONNX 优化用于推理（或模型评分）的深度学习模型非常困难，因为需要调整模型和推理库，充分利用硬件功能。 如果想要在不同类型的平台（云、CPU/GPU 等）上获得最佳性能，实现起来会异常困难，因为每个平台都有不同的功能和特性。 如果模型来自需要在各种平台上运行的多种框架，会极大增加复杂性。 优化框架和硬件的所有不同组合非常耗时。这就需要一种解决方案，在首选框架中训练一次后能在云上的任意位置运行。此时 ONNX 便派上了用场。\nONNX 是一种用于表示机器学习模型的开放格式。 ONNX 定义了一组通用运算符——机器学习和深度学习模型的构建块——以及一种通用文件格式，使 AI 开发人员能够 使用具有各种框架、工具、运行时和编译器的模型。许多框架（包括 TensorFlow、PyTorch、 SciKit-Learn、Keras、Chainer、MXNet、MATLAB 和 SparkML）中的模型都可以导出或转换为标准 ONNX 格式。 模型采用 ONNX 格式后，可在各种平台和设备上运行。\n4.3 基于 ONNX 进行 C++工程化部署： 基于 ONNX 进行的 C++模型部署在技术上主要分为四个步骤：构建模型、导出为 ONNX的格式、使用 ONNX 进行推理、导出为 C++框架。\n4.3.1 将模型导出为 ONNX 格式 在形式上，我们在完成基于 Pytorch 的模型构建之后，使用的 Pytorch 自带的模块torch.onnx 将模型转换到 ONNX 格式\n4.3.2 实现 Python 版本的 ONNXRuntime 推理 在进行 C++实现之前，我们先实现了一份 python 的推理。如果要更好地将该项目转换成 C++工程，需要考虑工程依赖的问题。因为，Python 中一些非常便于使用的第三方\n依赖库，通常情况下，难以在 C++中找到同等的实现。所以，为了便于实现 C++和 Python的工程效果对齐，我们编写了一个只依赖于 OpenCV、numpy 和 onnxruntime 的 python推理。\n4.3.3 实现 C++版本的 ONNXRuntime 推理 相关代码附上百度网盘链接：链接：百度网盘 请输入提取码 (baidu.com) 提取码：p29o\n4.4 ONNXRuntime 推理优化加速 本地运行模型时，我们发现相应的 FPS 并不理想，与赛题方所要求的 20FPS 相差甚远，于是我们在部署 ONNXRuntime 推理时，采用了以下的方法进行了优化加速。\n（1）使用 opencv 自带的 resize 方法代替设置 downratio 值（即 downratio=1）\n因为在 python 中，downratio!=1 时，由 pytorch 中 F.interpolate 的方法先将输入图像进行缩放，而在 ONNXRuntime 中，代替 F.interpolate 的方法仍然没有 cv::resize的方法运行的快，因此在推理过程中只使用 cv::resize 进行一次缩放以提速。\n（2）在推理过程中，设置合适的 cpu 推理线程数。根据 onnxruntime 自带的设置线程接口函数，根据 cpu 的实际最大线程数。以 i7-9700k 为例，cpu 的最大线程数为 8，将 onnxruntime 推理线程数设置为 5 或 6 时推理速度最快。\n（3）尽可能用第三库的矩阵运算代替自己写的 for 循环遍历。虽然矩阵运算的底层代码也是数组的遍历，但是好的第三方库中（如 opencv 等），将矩阵运算进行了加速处理（例如使用多线程、SIMD 等方式），使得运行速度比自己写的 for 循环快很多。因此在图像的预处理和后处理过程中，尽可能的使用矩阵运算，比如通过 cv::Mat 的构造函数直接将 onnxruntime 的输出 float转化成一个二维图像矩阵。\n第五章 模型测试 我们在给定的二十个测试集上进行了实例的测试：\n具体测试过程为：将测试样例输入到模型中得出对应的人像前景输出与人像 Mask视频，并将手动打标签得到的视频与模型得出的人像 Mask 视频输入到设计好的 MIOU 指标计算程序中计算 MIOU 数值（在计算时我们分别计算了两种不同的 MIOU 数值，分别是包括背景的与去除背景的两种数值）\n具体系统测试数据如下：（左一为模型测试效果，左二为人像原图，右一为手动打标签图像）\nTest 03\nTest 10\nTest 14\n本地 MIOU 数值计算：\n测试集序号 MIOU MIOU with no_back Test01 0.9877 0.9798 Test02 0.9798 0.9757 Test03 0.9733 0.9604 Test04 0.9785 0.9693 Test05 0.8401 0.6934 Test06 0.9878 0.9793 Test07 0.9663 0.9378 Test08 0.9222 0.8523 Test09 0.9207 0.8464 Test10 0.9427 0.9052 可见，我们的模型对于视频人像分割得出了一个令人满意的结果\n第六章 参考文献资料与引用 Liang-Chieh Chen, G. Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. ArXiv, abs/1706.05587, 2017.\nKyunghyun Cho, B. V. Merrienboer, C¸ aglar Gulc¸ehre, ¨ Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder–decoder for statistical machine translation. ArXiv, abs/1406.1078, 2014.\nAndrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, and Hartwig Adam. Searching for mobilenetv3, 2019.\nZhanghan Ke, Kaican Li, Yurou Zhou, Qiuhua Wu, Xiangyu Mao, Qiong Yan, and Rynson W.H. Lau. Is a green screen really necessary for real-time portrait matting? ArXiv,abs/2011.11961, 2020.\nShanchuan Lin, Andrey Ryabtsev, Soumyadip Sengupta, Brian Curless, Steve Seitz, and Ira KemelmacherShlizerman. Real-time high-resolution background matting. In Computer Vision and Pattern Regognition (CVPR), 2021.\nSoumyadip Sengupta, Vivek Jayaram, Brian Curless, Steve Seitz, and Ira Kemelmacher-Shlizerman. Background matting: The world is your green screen. In Computer Vision and Pattern Regognition (CVPR), 2020.\nHuikai Wu, Shuai Zheng, Junge Zhang, and Kaiqi Huang. Fast end-to-end trainable guided filter, 2019.\nShanchuan Lin, Linjie Yang, Imran Saleemi and Soumyadip Sengupta.Robust High-Resolution Video Matting with Temporal Guidance. arXiv:2108.11515 [cs.CV]\n","date":1709134184,"headings":[{"anchor":"21-背景及研发意义","title":"2.1 背景及研发意义"},{"anchor":"22-作品简介","title":"2.2 作品简介"},{"anchor":"23-模型特色","title":"2.3 模型特色"},{"anchor":"31-总体设计","title":"3.1 总体设计"},{"anchor":"311-什么是人像抠图人像分割","title":"3.1.1 什么是人像抠图、人像分割"},{"anchor":"312-视频人像抠图","title":"3.1.2 视频人像抠图"},{"anchor":"32-模型设计","title":"3.2 模型设计"},{"anchor":"321-模型架构","title":"3.2.1 模型架构"},{"anchor":"322-编码器","title":"3.2.2 编码器"},{"anchor":"323-循环解码器","title":"3.2.3 循环解码器"},{"anchor":"324-上采样模块","title":"3.2.4 上采样模块"},{"anchor":"41-深度学习的工作流程","title":"4.1 深度学习的工作流程"},{"anchor":"42-什么是-onnx","title":"4.2 什么是 ONNX"},{"anchor":"43-基于-onnx-进行-c工程化部署","title":"4.3 基于 ONNX 进行 C++工程化部署："},{"anchor":"431-将模型导出为-onnx-格式","title":"4.3.1 将模型导出为 ONNX 格式"},{"anchor":"432-实现-python-版本的-onnxruntime-推理","title":"4.3.2 实现 Python 版本的 ONNXRuntime 推理"},{"anchor":"433-实现-c版本的-onnxruntime-推理","title":"4.3.3 实现 C++版本的 ONNXRuntime 推理"},{"anchor":"44-onnxruntime-推理优化加速","title":"4.4 ONNXRuntime 推理优化加速"},{"anchor":"第一章-前言","title":"第一章 前言"},{"anchor":"第三章-系统设计","title":"第三章 系统设计"},{"anchor":"第二章-作品概述","title":"第二章 作品概述"},{"anchor":"第五章-模型测试","title":"第五章 模型测试"},{"anchor":"第六章-参考文献资料与引用","title":"第六章 参考文献资料与引用"},{"anchor":"第四章-工程化实现","title":"第四章 工程化实现"}],"kind":"page","lang":"zh-hans","summary":"","title":"项目详细方案","url":"/%E8%A7%86%E9%A2%91%E4%BA%BA%E5%83%8F%E5%88%86%E5%89%B2/%E9%A1%B9%E7%9B%AE%E8%AF%A6%E7%BB%86%E6%96%B9%E6%A1%88/","year":"2024"},{"content":"1. 项目概述 1.1 项目名称 中小学学生行为跟踪与分析系统\n1.2 项目背景 随着社会的发展，教育和安全问题越来越受到重视。在课堂上，对中小学生的行为进行追踪与分析，有助于了解学生的上课状态，及时发现不良行为并进行干预，保障学生的安全与健康。本研究旨在开发一种中小学生行为追踪与分析系统，通过对学生行为的实时监测和分析，为教育工作者提供有益的信息，以提高教育质量和保障学生安全。 随着课程改革的不断深入，课堂研究的逐渐兴起，课堂观察作为研究课堂的一种方法开始受到学界的关注与中小学教师的青睐。近年来人工智能技术的兴起，为教育信息化、个性化、智能化的发展提供了一个全新的思路，该场景需求围绕人工智能技术服务于课堂教学，尝试建立基于人工智能的课堂行为分析系统，为促进学生个性化成长，辅助改进课堂教学、打造智能高效、富有智慧的课堂教学环境提供了一条新的探索之路。\n2. 项目总体建设思路 中小学学生行为跟踪与分析系统是一个综合管理系统，它集图像采集和处理、语音采集与处理、人脸识别以及信息管理系统于一身，运用最新的人脸识别、行为分析、视频结构化和大数据等技术，实现作弊检测，课堂专注度分析，人脸考勤等功能，助力学生的个性化学习，教师的专业化成长、高效精细的教学管理。\n图1 系统架构图\n3. 建设目标与建设内容 3.1 建设目标 该系统运用最新的人脸识别、行为分析、视频结构化和大数据等技术，实现作弊检测，课堂专注度分析，人脸考勤等功能，助力学生的个性化学习，教师的专业化成长、高效精细的教学管理。\n3.2 建设内容 中小学学生行为跟踪与分析系统是一个综合管理系统，它集图像采集和处理、语音采集与处理、人脸识别以及信息管理系统于一身，系统功能主要包括课堂行为异常检测、课堂专注度分析、人脸注册和动态点名四个部分。\n4. 项目需求分析 4.1 功能需求分析 4.1.1 视频异常监测 课堂异常行为检测是指通过人工智能技术对学生课堂行为进行实时监测和分析，发现学生出现异常行为时及时报警，以便教师及时干预和纠正，提高课堂管理效率和学生学习效果。\n该功能包括以下详细介绍：\n（1）监测和分析学生课堂行为：通过人工智能技术，对学生课堂行为进行监测和分析，包括坐姿、注意力等方面；\n（2）异常行为类型：将动作自主规定为正常、传纸条、低头偷看、东张西望等四种类型，其中后三种行为均属于异常行为；\n（3）异常行为记录与统计：系统可以记录学生的异常行为情况，并进行统计分析，以便教师更好地了解学生的课堂表现；\n（4）异常行为干预和纠正：教师可以根据系统标记的异常行为，及时干预和纠正学生的异常行为，提高管理效率。\n4.1.2 人脸注册 人脸注册功能模块主要是通过摄像头获取视频流，采用静默活体检测技术，借助开源模型，对视频流的单帧图片进行人脸检测，对检测到的人脸进行活体检测，若大于阈值，则判定为活体，否则为非活体，并检测到的活体存储在人脸数据库中，实现人脸注册功能。教师可以在系统中对学生进行人脸注册。在注册过程中，系统会要求学生面对摄像头进行人脸采集。采集完成后，系统会自动进行人脸检测和活体检测。如果检测结果为活体，学生的人脸信息将被存储在人脸数据库中，完成注册。\n该功能包括以下详细介绍：\n（1）人脸检测\n人脸检测是基于视频流进行的。摄像头采集的视频流会经过人脸检测算法的处理，以便在视频中识别出人脸。常用的人脸检测算法包括基于深度学习的卷积神经网络（CNN）等。这些算法可以识别出人脸的位置、大小和关键点，为后续的活体检测做好准备。\n（2） 活体检测\n在识别出人脸后，需要对检测到的人脸进行活体检测，以确保获取到的人脸信息是真实的。活体检测通常基于深度学习技术，如卷积神经网络（CNN）等。在检测过程中，系统会分析人脸图像的纹理、颜色、形状等特征，并与预设的活体检测阈值进行比较。如果特征值大于阈值，则判定为活体；否则为非活体。\n（3）人脸数据存储\n经过人脸检测和活体检测后，检测到的活体人脸信息会被存储在人脸数据库中，以便教师在后续的教学管理中进行身份核实。\n（4）人脸信息管理\n教师可以在系统中对学生的人脸信息进行管理，包括添加、删除和查询学生人脸信息。当学生信息发生变化时，如转学、退学等，教师可以在系统中对学生的人脸信息进行相应操作。此外，教师还可以通过系统查询学生的人脸信息，了解学生身份是否真实有效。\n（5）安全保护\n为了保护学生隐私，系统需要采取一定的安全措施。在人脸采集和识别过程中，系统应遵循相关法律法规，确保学生的人脸信息不被泄露。\n（6）异常处理\n在人脸注册过程中，可能会出现一些异常情况，如学生人脸信息无法识别、学生拒绝参加人脸采集等。针对这些异常情况，系统需提供相应的处理措施，如重新采集人脸信息、手动输入学生信息等，以确保学生身份真实有效。\n4.1.3 动态点名 动态点名功能模块为学生通过摄像头完成签到，可多人同时签到，主要借助dlib库实现人脸识别功能，对人脸特征进行提取，在视频流中抓取人脸特征，然后将要识别的对象与人脸数据库中的图片进行距离计算，实现人脸识别，完成动态点名功能。\n该功能包括以下详细介绍：\n（1）对视频流进行人脸检测，以识别出参与签到的学生。人脸检测可以基于 dlib 库等开源工具，通过卷积神经网络（CNN）等算法实现。在检测过程中，系统会分析视频流中的每一帧图像，找出其中的人脸，并记录人脸的位置、大小、关键点等信息。\n（2）人脸识别。在提取人脸特征后，系统会将要识别的对象与人脸数据库中的图片进行距离计算，实现人脸识别。常用的距离计算方法包括欧几里得距离、余弦相似度等。如果计算得到的距离小于预设的阈值，则判定为匹配成功，表示学生已签到；否则为匹配失败，表示学生未签到。\n4.1.4 课堂专注度分析 课堂专注度分析是指通过人工智能技术对学生上课情况进行实时监测和分析，以便教师及时干预和纠正，提高课堂管理效率和学生学习效果。\n该功能包括以下详细介绍：\n（1）监测和分析学生课堂行为：通过人工智能技术，对学生课堂专注度进行监测和分析，包括行为、情绪、头部姿态等方面；\n（2）专注度分析报告：系统可以根据学生课堂专注度的监测和分析结果，生成专注度分析报告，供教师参考；\n（3）专注度记录和统计：系统可以记录每个学生课堂专注度的情况，并进行统计分析，以便教师更好地了解学生的学习状况；\n（4）课堂行为干预和纠正：教师可以根据系统专注度记录情况，及时干预和纠正学生的上课状态，提高管理效率。\n5. 系统总体设计 5.1 建设原则 系统建设严格按照如下原则\n开闭原则 依赖倒置 单一职责原则 接口隔离原则 迪米特法则 里氏替换原则 合成复用原则 5.2 建设思路 1）数据挖掘：收集学生的行为数据，并采用数据挖掘方法对数据进行分析和处理；2）机器学习和人工智能技术：利用机器学习和人工智能技术，建立学生行为预测模型，并根据预测结果进行分析；3）多元分析和数据可视化：采用多元分析和数据可视化技术，对学生行为进行综合分析和展示，以便更好地了解学生课堂情况；4）文献检索：通过阅读相关文献突破项目重难点。\n5.3 系统总体架构 5.3.1 总体架构 本项目采用人工智能等技术，对学生课堂行为进行检测与分析，学生行为检测系统的功能架构图如下所示：\n（1）视频异常检测模块从摄像头或者本地视频中获取视频流，采用多人姿态估计技术，自顶向下先进行目标检测，对检测到的人进行单人的关键点检测，是否有转头、低头、传递物品等异常行为，若有，则截取该帧视频图片并进行异常行为动作的标记。\n（2）课堂专注度分析模块主要通过摄像头或者视频获取视频流，进行图像帧的序列处理，并利用yolov5进行目标检测，对检测到的人体通过行为识别、头背部姿态估计、面部遮挡、面部表情分析等方式进行注意力评估，可视化最终结果。\n（3）人脸注册功能模块主要是通过摄像头获取视频流，采用静默活体检测技术，借助开源模型，对视频流的单帧图片进行人脸检测，对检测到的人脸进行活体检测，若大于阈值，则判定为活体，否则为非活体，并检测到的活体存储在人脸数据库中，实现人脸注册功能。\n（4）动态点名功能模块为学生通过摄像头完成签到，可多人同时签到，主要借助dlib库实现人脸识别功能，对人脸特征进行提取，在视频流中抓取人脸特征，然后将要识别的对象与人脸数据库中的图片进行距离计算，实现人脸识别，完成动态点名功能。\n5.3.2 技术架构 5.4 关键技术 5.4.1 Yolo目标检测算法 YOLOv5是一种单阶段目标检测算法，仅仅使用一个CNN网络直接预测不同目标的类别与位置。将其划分为4个通用的模块，具体包括：输入端、基准网络、Neck网络与Head输出端，该 算法在YOLOv4的基础上添加了一些新的改进思路，使得其速度与精度都得到了极大的性能提升。\n5.4.2 MOT\u0026ndash;多目标跟踪算法 MOT 获取单个连续视频并以特定帧速率 (fps) 将其拆分为离散帧以输出：\n检测每帧中存在哪些对象、标注对象在每一帧中的位置、关联不同帧中的对象是属于同一个对象还是属于不同对象。\n5.4.3 DeepSORT\u0026ndash;目标跟踪初探算法 检测器得到bbox → 生成detections → 卡尔曼滤波预测→ 使用匈牙利算法将预测后的tracks和当前帧中的detecions进行匹配（级联匹配和IOU匹配） → 卡尔曼滤波更新\nAlphaPose 是一种基于 top-down 的人体姿态估计网络。该网络使用了 SpatialTransformerNetworks（STN）结构，能够实现对图像中多人姿态的估计。AlphaPose 是基于 RMPE（RegionalMulti-PersonPoseEstimation）的部分算法开发的，其中包括 poseNMS 和 PGPG 等算法。该网络使用了 STN 结构中的映射转换功能，可以实现对原图的移动、旋转、缩放等操作，从而实现对人体姿态的准确估计。 6. 详细功能设计 6.1 作弊检测 课堂作弊检测共由五个顺序处理部分组成：\n6.1.1 视频源读取模块 该模块负责从本地视频源或摄像头视频源中读取视频序列，并将其转换为图像帧序列，速度为12fps。这个模块使用OpenCV这个计算机视觉库来实现。\n视频源读取模块是整个课堂行为追踪与分析系统的第一个模块，它的主要任务是从本地视频源或摄像头视频源中读取视频序列，并将其转换为图像帧序列，速度为12fps。该模块的实现离不开计算机视觉库的支持，这里我们选择使用 OpenCV 这个广泛应用的库来实现。\nOpenCV 是一个跨平台的计算机视觉库，它提供了丰富的函数和接口，可以方便地处理视频流、图像和特征。在这个模块中，我们将使用OpenCV的 VideoCapture类来读取视频源，并将视频序列转换为图像帧序列。VideoCapture 类提供了一个简单的方法，即可以通过调用read()函数从视频文件或摄像头中读取图像帧。\n在实际应用中，我们需要考虑如何优化视频源读取模块的性能，以保证系统在处理大量视频数据时能够稳定运行。为此，我们可以采用以下策略：\n使用硬件加速：例如使用GPU加速，可以大幅度提高视频处理的速度。\n调整帧率：根据实际需求，我们可以适当调整帧率，以降低处理速度，从而节省计算资源。\n采用多线程：通过将视频源读取模块设计为多线程，可以实现并发处理，进一步提高系统的性能。\n总之，视频源读取模块作为整个课堂行为追踪与分析系统的起点，通过使用 OpenCV库，可以方便地从本地视频源或摄像头视频源中读取视频序列，并将其转换为图像帧序列，为后续模块提供数据支持。同时，在实际应用中，我们还需要考虑性能优化问题，以确保系统在处理大量视频数据时能够稳定高效地运行。\n6.1.2 目标检测模块 该模块使用Yolo算法对图像帧进行目标检测，并检测出图像中的所有人。然后，为每个人打上锚框，并将他们送往下一个模块。Yolo是一种基于深度学习的目标检测算法，可以在实时视频处理中快速准确地检测出目标。\n作为课堂行为追踪与分析系统的核心模块之一，目标检测模块负责对每一帧图像进行目标检测，以找到图像中的所有人。\n目标检测是一件比较实际的且具有挑战性的计算机视觉任务，其可以看成图像分类与定位的结合，给定一张图片，目标检测系统要能够识别出图片的目标并给出其位置，由于图片中目标数是不定的，且要给出目标的精确位置，目标检测相比分类任务更复杂。近几年来，目标检测算法取得了很大的突破。比较流行的算法可以分为两类，一类是基于Region Proposal的R-CNN系算法（R-CNN，Fast R-CNN, Faster R-CNN），它们是two-stage的，需要先使用启发式方法（selective search）或者CNN网络（RPN）产生Region Proposal，然后再在Region Proposal上做分类与回归。而另一类是Yolo，SSD这类one-stage算法，其仅仅使用一个CNN网络直接预测不同目标的类别与位置。第一类方法是准确度高一些，但是速度慢，但是第二类算法是速度快，但是准确性要低一些。 Yolov5（You Only Look Once v5）算法是Yolo第五版改进的目标检测器，它采用了卷积神经网络对图像进行端到端的训练，能够实现对多种目标的实时检测。相较于传统目标检测算法，Yolov5 具有检测速度快、准确率高等优势，这使得它成为实时视频处理中目标检测的理想选择。\n在目标检测模块中，我们首先使用 Yolov5 算法对每一帧图像进行预处理，从而在图像中识别出所有人的目标。接着，我们对检测到的目标进行锚框处理，为每个人打上锚框，以便将他们送往下一个模块进行后续处理。\n在实际应用中，为了提高目标检测模块的性能，我们采用以下策略：\n数据增强：通过对训练数据进行旋转、缩放、翻转等操作，可以扩充数据集，提高模型的泛化能力。 模型优化：通过调整网络结构和参数，可以进一步优化模型的性能，提高检测速度和准确率。 并行计算：利用多核处理器和显卡并行计算，可以大幅度缩短目标检测的时间。 总之，目标检测模块在课堂行为追踪与分析系统中起着关键作用，通过使用 Yolov5 算法对图像帧进行目标检测，为每个人打上锚框，从而为后续模块提供准确的数据。在实际应用中，我们还需不断优化目标检测模块的性能，以满足实时视频处理的需求。\n6.1.3 多人体姿态估计模块 该模块使用 alphapose 模型对多人的姿态进行估计。alphapose 是一种基于深度学习的人体姿态估计算法，可以准确地估计人体关节的位置和姿态，将估计好的姿态送往下一个模块。\n多人体姿态估计模块是课堂行为追踪与分析系统中一个关键模块，它负责对多人的姿态进行精确估计。\n为了实现这一目标，我们选择了 AlphaPose 模型，这是一种基于深度学习的区域多人姿态估计算法，具备准确估计人体关节位置和姿态的能力。目前多人姿态估计的方法分为两类：一种是自顶向下，另一种是自底向上。自顶向下检测方法是先检测图片中的每个人的边界框，再独立检测每个人体边界框中的姿态。这种方法的缺点是高度依赖人体边界框的检测质量，如果人体边界框定位不准确，就无法正确预测人体姿态。自底向上是先检测出图像中的所有关节点，然后拼接得到人体骨架，这种方法的缺点是当人体距离相近时，关节点的分组容易出现模棱两可的情况，肢体关节不知道如何匹配到相应的骨架。Alphapose采用的是自顶向下的方法。\nAlphaPose 模型是一种基于单人关键点检测的人体姿态估计算法，它由多个卷积神经网络组成，可以实时地对图像中的每个人体进行姿态估计。AlphaPose 模型通过预测人体关键点的坐标，然后利用这些坐标计算出人体关节的位置和姿态。相较于传统人体姿态估计算法，AlphaPose 具有检测速度快、准确率高等优势，这使得它成为课堂行为追踪与分析系统中多人体姿态估计的理想选择。AlphaPose 模型的训练过程主要分为两个阶段。第一个阶段是关键点检测，即识别人体关节的位置。在这个阶段，AlphaPose 使用卷积神经网络对图像进行处理，并预测人体关键点的坐标。第二个阶段是姿态估计，即根据关键点坐标计算人体关节的位置和姿态。在这个阶段，AlphaPose 利用人体关键点之间的几何关系，通过优化算法计算出人体关节的位置和姿态。\n6.1.4 异常行为回归预测模块 异常行为回归预测模块是一个基于深度学习的模块，主要用于分析学生课堂上的行为。该模块通过估计好人体姿态图后，进行回归预测，并对学生的动作进行多分类问题。这里使用了全连接神经网络来实现，以便对学生的行为进行准确的分类。\n该模块根据估计好的人体姿态图进行回归预测，并对学生的动作进行多分类问题。此模块使用深度学习算法，全连接神经网络来实现。\n在这个模块中，我们共分了19 个标签，它们分别对应着不同的学生行为。这些行为包括正常坐姿不动、正常低头写字、正常伸懒腰、举右手低、举左手低、举右手高、举左手高、起立、抬手、右伸手、左伸手、右伸手、左伸手、右转身、左转身、右转头、左转头、上课睡觉和严重低头。这些标签有助于模型对学生行为进行细致的分类。\n经过多分类问题后，接下来根据预测出来的十九个标签进行单分类问题，以判断学生处于以下四种状态中的哪一种：正常、传纸条、低头偷看和东张西望。这样的分类结果有助于教师了解学生在课堂上的行为状况，以便有针对性地进行管理和指导。\n通过运用深度学习算法中的全连接神经网络，异常行为回归预测模块能够有效地分析学生课堂上的行为，并对其进行准确的分类。这有助于提高教学质量，促进学生课堂上的良好行为。\n6.1.5 可视化模块 可视化模块是一个重要的组成部分，它负责将异常行为回归预测模块所分析的结果进行可视化展示。该模块对每个学生的异常状态进行抓拍，并记录异常行为发生的时间。然后，根据异常行为发生的时间、种类和数量，绘制异常行为时间曲线。最后，将异常行为状态抓拍的图片、异常行为的记录和异常行为时间曲线传到前端客户端进行展示。\n这个模块会对每个学生的异常状态进行抓拍，并记录下异常行为发生的时间。这样一来，教师就可以直观地了解学生在课堂上的异常行为情况。\n接着，可视化模块会根据异常行为发生的时间、种类和数量，绘制异常行为时间曲线。这条曲线有助于教师进一步了解学生异常行为的分布情况，以便有针对性地进行干预和辅导。\n最后，可视化模块会将异常行为状态抓拍的图片、异常行为的记录和异常行为时间曲线传到前端客户端进行展示。在前端客户端上，教师可以通过浏览器或其他设备查看学生的异常行为情况。这样的展示方式既方便又直观，有助于教师更好地关注学生的行为变化，提高教学质量。\n总之，可视化模块通过抓拍异常行为、记录异常行为发生时间和绘制异常行为时间曲线等方式，将异常行为回归预测模块的分析结果呈现出来，为教师提供直观、便捷的异常行为查看和分析工具。这有助于提高教学质量，促进学生课堂上的良好行为。\n6.2 课堂专注度分析 该部分通过对学生的姿态检测，可以有效的辅助老师有效监督学生的学习上课情况，对学生的上课行为进行分析及评分，避免出现课堂不认真听讲、考试作弊等不良的行为。课堂专注度分析模块有群体专注曲线，头部姿态专注度评分曲线，情绪专注度评分曲线，行为专注度评分曲线，通过头背部姿态估计、传递动作识别等综合统计，抉出最佳行为。\n6.2.1 视频源读取模块 该模块负责从本地视频源或摄像头视频源中读取视频序列，并将其转换为图像帧序列，速度为12fps。这个模块使用OpenCV这个计算机视觉库来实现。\n6.2.2 目标检测模块 该模块使用Yolo算法对图像帧进行目标检测，并检测出图像中的所有人。然后，为每个人打上锚框，并将他们送往下一个模块。Yolo是一种基于深度学习的目标检测算法，可以在实时视频处理中快速准确地检测出目标。\n6.2.3 多人体姿态估计模块 该模块使用 alphapose 模型对多人的姿态进行估计。alphapose 是一种基于深度学习的人体姿态估计算法，可以准确地估计人体关节的位置和姿态，将估计好的姿态送往下一个模块。\n6.2.4 注意力评估模块 根据行为识别、头背部姿态估计、面部遮挡、面部表情分类上述这几项数据进行模糊综合分析，最后得到注意力是否集中的评估结果。\n行为识别：我们设置了19个标签分别对应不同的学生行为，如正常坐姿不动、正常低头写字、正常伸懒腰、举右手低、举左手低、举右手高、举左手高、起立、抬手、右伸手、左伸手、右伸手、左伸手、右转身、左转身、右转头、左转头、上课睡觉和严重低头。\n将其重新分类，得到第一类：正常坐姿不动、正常低头写字；第二类：举右手低、举左手低、举右手高、举左手高、抬手；第三类：正常伸懒腰、起立、；第四类：上课睡觉、严重低头；第五类：右伸手、左伸手、右伸手、左伸手、右转身、左转身、右转头、左转头。根据输入的关键点坐标输入模型，提取预测结果中的最大概率类别，预测行为动作类别。\n头背部姿态估计：通过PnPPoseEstimator中的Facial landmarks包括眼睛、鼻子、嘴巴、耳朵等部位的几何中心或关键点进行头背部姿态估计，获得头背部姿态：包括头背部的位置、方向、旋转角度等信息，通常用三维坐标系中的旋转矩阵表示。这是一个用于头背部姿态估计的工具，它使用深度学习技术对图像或视频中的人物头背部姿态进行分析和估计。该工具基于卷积神经网络和循环神经网络的模型，能够识别和区分不同的头背部姿态，包括颈部、肩部、背部等部位。通过使用 PnPPoseEstimator，可以对人物头背部姿态进行精确的估计和分析。\n面部遮挡：从人体关键点数据中提取面部关键点得分。通过切片操作，提取了面部关键点部分得分，然后，通过求轴向最大值，并判断其是否小于预设的遮挡阈值，来判断面部是否被遮挡。我们还需判断判断嘴巴是否被遮挡，同样地，通过求轴向最大值，并判断其是否小于预设的遮挡阈值，来判断嘴巴是否被遮挡。\n面部表情分析：从人体关键点数据中提取面部关键点坐标。通过切片操作，提取了面部关键点坐标部分，使用面部预测模型获取面部表情，该模型的预测函数，它接收面部关键点坐标作为输入，并返回预测的面部表情。该模型通过脸的宽度、嘴巴张开程度、眼睛睁开程度、头部倾斜程度、两嘴角中间位置占据上下唇高度比例，最后分情况讨论，张嘴，可能是开心或者惊讶，没有张嘴，可能是正常和疑惑，得到“开心”、“惊讶”、“正常”、“疑惑”四种面部表情。\n模糊综合评：将得到的行为识别、头背部姿态估计、面部遮挡、面部表情分类上述这几项数据进行模糊综合分析。对动作预测进行重新分类，并计算动作预测中的等级。对面部表情预测进行重新分类，并计算面部表情预测中的等级。如果 面部遮挡存在，还需将其考虑在内。对头部姿势预测进行重新分类，并计算头部姿势预测中的等级。同样，如果头部遮挡存在，还需将其考虑在内。\n通过处理过的动作、面部表情和头部姿势预测结果计算出二级评价因素、一级评价因素，将两级因素相结合，得到最终的评价结果。这个评价结果可以用于对预测结果的准确性和可靠性进行评估。\n6.2.5 可视化模块 可视化模块是一个重要的组成部分，使用了OpenCV库中的 Image 和 ImageDraw 类来实现图像的绘制。它负责将注意力评估模块所分析的结果进行可视化展示。在显示屏上绘制骨骼关键点、绘制目标检测框和动作分类，在屏幕上显示学生的目标检测框和注意力评估结果，包括群体专注曲线，头部姿态专注度评分曲线，情绪专注度评分曲线，行为专注度评分曲线和评价因素。若显示结果冲突，会提示请正视摄像头。这样一来，教师就可以直观地了解学生在课堂上的课堂专注度情况。\n6.3 人脸注册 人脸注册功能分为以下五个部分\n6.3.1 人脸检测 该部分负责从屏幕上识别出镜头中的人脸，并对镜头中出现的人脸进行比较，选择离镜头最近最大的人脸。该部分使用face_recognition中的FaceBoxesLocation人脸检测器实现。\n人脸检测部分是人脸注册功能的核心第一部分，FaceBoxes模型对人脸进行识别并选取最近的人脸。FaceBoxes是一个足够轻量的人脸检测器，由中国科学院自动化研究所和中国科学院大学的研究者提出，旨在实现CPU下的实时人脸检测。该模型的创新点在于提出了Rapidly Digested Convolutional Layers (RDCL)实现快速的特征提取，极大提高了模型的运行速度；提出了Multiple Scale Convolutional Layers (MSCL)来获取多尺度的特征，主要是参考了GoogleNet中的inception模块来实现；提出了anchor densification strategy（anchor box稠密化策略），改善人脸检测的查全率。\n该部分会检测视频中的所有人脸并返回一个人脸位置信息列表。在人脸检测中，通常需要使用一个矩形框框来表示人脸的位置和大小，这个矩形框的位置和大小信息就是通过 FaceBoxesLocation 对象来表示的。进行人脸检测时，通常会返回一个包含多个 FaceBoxesLocation 对象的列表，每个 FaceBoxesLocation 对象都代表了一个检测到的人脸的框框位置信息。通过这个列表，可以获取每个检测到的人脸的位置和大小信息，并进行后续的处理，例如人脸识别、人脸对比等操作。\n6.3.2 静默活体检测 该部分对人脸检测中检测到的每张人脸进行静态活体检测，并且根据静态活体识别结果和人脸位置信息来显示相应的提示文本。该部分使用face_recognition中的SilentFaceDetector静态活体检测实现。\n静态活体检测部分的主要用途是检测图像中的人脸，并提取人脸的关键点坐标。人脸静态活体检测是一种利用计算机视觉技术，对人脸图像进行分析和比对，以检测人脸图像是否为活人的技术。与动态检测相比，静态检测可以在不运行被检测软件的情况下进行，因此可以检测到更深层次的漏洞和错误，但是需要耗费更多的时间和精力。静态检测技术可以应用于软件开发过程中的代码审查、质量控制和安全漏洞检测等方面。FaceRecognition 库中的 SilentFaceDetector 是一个基于深度学习的人脸检测器，它使用预训练的卷积神经网络来检测图像中的人脸。与传统的人脸检测器（如 Haar 特征分类器）相比，SilentFaceDetector 具有更高的准确性和鲁棒性。\n在该部分中，SilentFaceDetector类进行的操作是对人脸位置信息进行静默活体识别，并将识别结果存储到列表中，结果包含检测到的人脸在图像中的位置和大小。\n该部分采用的技术来自小视科技团队开源的活体检测模型MiniFASNetV1和MiniFASNetV2。该模型采用自研的剪枝轻量级网络作为 backbone 训练模型，使用 Softmax + CrossEntropy Loss 作为训练分类的监督。使用不同尺度的图片作为网络的输入训练数据，增加模型间的互补性，从而进行模型融合。\n6.3.4 姿态估计 该部分通过求解人脸的关键点坐标数组的姿态（旋转和平移矩阵），在屏幕上输出人脸姿态对应的坐标轴，并定义一个容忍误差，用于判断人脸在视频帧中的边界范围是否超出一定范围，以此对人脸进行识别和处理，判断人脸的位置和姿态是否合理。该部分使用face_recognition中的PnPPoseEstimator头部姿态估计实现。\n头部姿态估计是人脸识别的关键，用于对人脸进行识别和处理，判断人脸的位置和姿态是否合理。在该部分中使用的PnPPoseEstimator 是 FaceRecognition 库中的一个面部姿态估计器，它用于估计人脸图像中面部特征点的位置和姿态。这些特征点包括眼睛、鼻子、嘴巴、耳朵等，通过估计这些特征点的位置和姿态，可以得到人脸的精确几何形状，从而用于人脸识别、人脸比对等任务。\nPnPPoseEstimator 使用深度学习模型进行训练，并使用优化算法来最小化模型损失函数。在训练过程中，它使用了大量的人脸图像数据集，如 LFW、CelebA 等，以学习面部特征点的位置和姿态的先验概率分布。通过最大化模型对训练数据的似然性，它可以得到最佳的面部姿态估计结果。\n6.3.5 人脸数据库管理 用户打开人脸注册功能时初始化人脸数据库并加载已有的人脸数据库数据信息。人脸数据库中存储的信息包括学生姓名、编码及学生照片。人脸编码通过dlib库中的人脸检测模型获取。根据用户操作，可以对人脸数据库中的数据信息进行增加或者修改。\n6.3.6 可视化模块 人脸注册功能通过cv2打开摄像头进行注册。该部分通过将视频拆分成每一帧，设置人脸框对人脸进行识别，并截取注册成功的人脸图像保存到人脸数据库中。\n可视化模块是人脸注册的重要组成部分，该部分将摄像头所拍到的画面显示在屏幕上，并设置一个人形框，用户需要在保证自己的脸在框中来进行人脸的识别及处理。接着可视化模块会将一帧一帧的图像返回到模型中进行人脸的识别及处理，也就是人脸注册的过程，在注册的过程中，屏幕上会有相应的文字提示来帮助用户进行人脸注册。注册完成后，用户输入名字完成注册，注册结果会保存在人脸数据库中并在人脸数据库列表中显示注册的人像及名字。\n6.4 动态点名 动态点名功能由五个顺序处理部分组成：\n6.4.1 视频源读取模块 该模块负责从本地视频源或摄像头视频源中读取视频序列，并将其转换为图像帧序列，速度为12fps。这个模块使用OpenCV这个计算机视觉库来实现。\n6.4.2 人脸检测模块 该模块借助基于C++开源库 dlib中的深度学习模型实现的人脸识别项目face_recognition，首先检测出人脸，并框出人脸面部轮廓的位置，识别出人脸关键点，接着采用头部姿态估计更准确地定位人脸的位置和方向，然后将进入到下一个模块。\n人脸检测模块可以说是动态点名部分最开始也是最重要的一个部分，通过对每一帧图像进行检测，识别出人脸位置等信息。\ndlib 是一个功能强大的 C++ 库，主要用于计算机视觉、机器学习和数据处理等领域。它提供了许多实用的工具和算法，以便开发人员能够快速实现各种图像处理任务。dlib 库的主要功能包括：\n图像处理：dlib 提供了丰富的图像处理功能，如图像缩放、裁剪、旋转、滤波等。这些功能可以方便地对图像进行预处理，提高后续算法的性能。\n特征提取：dlib 库包含了许多常见的特征提取算法，如 SIFT、SURF、HOG、LBP 等。这些算法可以帮助开发人员从图像中提取出有用的特征信息，用于分类、匹配和识别等任务。\n机器学习：dlib 提供了一些基本的机器学习算法，如分类、回归、聚类等。此外，它还支持使用支持向量机 (SVM) 和决策树等技术进行分类和回归。\n人脸识别：dlib 库内置了人脸检测、人脸关键点检测和人脸识别等算法。这些算法可以帮助开发人员实现人脸识别、人脸对比等任务。\n姿态估计：dlib 提供了头部姿态估计算法，可以估计人脸图像中的旋转角度和倾斜程度，从而更精确地定位人脸在图像中的位置。\n数据库和文件处理：dlib 库支持各种常见的数据存储格式，如 JSON、XML、CSV 等。此外，它还提供了数据库接口，方便开发人员进行数据存储和管理。\n跨平台支持：dlib 库可以在多种操作系统上运行，包括 Windows、Linux 和 macOS 等。这使得开发人员可以在不同环境下方便地使用 dlib 库实现图像处理任务。\n总之，dlib 库为开发人员提供了一个便捷、高效的图像处理工具集，有助于快速实现各种计算机视觉任务。\n在本模块主要借助dlib库提供的人脸识别功能，首先进行人脸位置的识别，然后对检测到人脸的图像进行68个人脸关键点的提取，同时，为了提高人脸识别的准确性和稳定性，采用头部姿态估计算法更准确地定位人脸的位置和方向，头部姿态估计是指通过计算机视觉技术对人头部的姿态进行估计和分析，通常包括对人脸、眼睛、嘴巴等特征点的定位和分析，从而减少人脸识别的错误率和误判率。\n6.4.3 人脸编码模块 该模块主要就是实现对人脸面部特征的编码，将其转为特征向量，然后将编码好的人脸特征向量输入到下一个模块。\n该模块也是基于dlib提供的人脸识别功能进行人脸特征点的编码，借助face_encodings函数，将关于人脸的68个关键点输入到函数中输出一个128维的人脸特征向量，便于进行之后的人脸匹配模块。\n该模块相对来说也较为简单，但是也是人脸检测与人脸匹配模块之间的一个重要步骤，人脸编码模块将提取出的人脸特征编码为一个唯一的数字代码，以便计算机能够将它们与已知的人脸图像进行比较。\n6.4.4 人脸匹配模块 人脸匹配算法是指将一张人脸图像与另一张人脸图像进行比较，以确定它们是否属于同一个人的过程。人脸匹配算法是人脸识别技术的重要组成部分，可以用于身份验证、安全控制、人脸搜索等领域。常用的人脸匹配算法包括：几何特征匹配算法、基于神经网络的匹配算法、基于谱聚类的匹配算法、基于图像相似度的匹配算法。这里我们通过计算欧氏距离来进行人脸匹配。\n导入face_recog 模块作为实现人脸识别的框架。在这个库中，包含了多种人脸识别算法和模型，如卷积神经网络 (CNN) 等。基于神经网络的匹配算法通过训练神经网络模型，将人脸图像转化为高维向量，然后计算这两个向量之间的相似度来确定是否匹配。我们根据已知的人脸编码，对输入数据中的人脸编码进行比较和匹配，计算它们之间的距离，并返回匹配的标签并对匹配度进行排序，以便后续进行人脸识别等操作。\n人脸匹配算法的性能受到多种因素的影响，如人脸图像的质量、光照条件、角度、表情等。因此，在项目的实现中，需要挑选合适的视频数据集来进行测试保证算法的实现度较好，并进行相应的调整和优化。\n6.4.5 可视化模块 这个模块负责将动态点名的结果进行可视化展示。这个模块会对每个学生的的人脸进行抓拍，并于人脸数据库进行匹配，若匹配成功则代表这个学生出席，点名成功显示已签到，否则不显示。这样一来，教师就可以直观地了解学生在课堂上的出席情况。\n动态点名可视化模块用于处理和分析摄像头捕捉到的帧数据，在初始化时，我们设置了已知的人员名字，并在后续处理中对跳过的数据进行了处理，以增加抖动效果。通过实现视频画面可视化，在视频画面中绘制人脸的位置和标签，并且可以根据设定的阈值来过滤掉概率较低的人脸，并在画面上绘制人脸的位置和标签。最后，将动态点名的结果传到前端客户端进行展示。\n动态点名可视化模块通过绘制人脸的位置和标签可以直观地展示已签到的学生姓名，可以直观找到未签到的学生，对教师考察课堂出勤情况具有重要作用。\n最后，可视化模块会将点名时抓拍到的学生照片进行展示，方便教师了解到学生的状态，这样的展示方式既方便又直观，有助于教师更好地了解学生现状，提高教学质量。动态点名可视化模块通过抓拍学生人脸并进行匹配显示出席情况等方式，将学生出勤情况呈现出来，为教师提供直观、便捷的查看出席情况的工具，这有助于提高学生课堂出勤率，避免逃课等行为。\n6.5 界面设计 界面设计使用python的QT框架实现，主要分为三大模块：\n菜单栏，提供不同的功能供用户选择，如课堂作弊检测、人脸注册等； 数据上传功能区，提供用户上传视频功能，并根据用户需求可以选择不同教室上传视频，实现分类管理； 可视化展示区域，展示用户上传的视频、分析结果、文字记录等。 6.5.1 使用方法 导入 PyQt5.QtCore 模块中的 QSize 类，主要作用是获取或设置一个矩形区域的大小。QSize 类通常用于设置控件的大小，例如按钮、文本框等控件的大小。通过导入 QSize 类，可以使用其构造函数和成员函数来创建和操作一个 QSize 对象。构造函数可以创建一个 QSize 对象，并指定其宽度和高度。可以为程序提供一种方便的方式来获取和设置控件的大小，从而实现图形用户界面的构建。\n从 PyQt5.QtGui 模块中导入 QImage、QPixmap 和 QIcon 包，主要作用是提供图像处理和图标绘制功能。这三个类分别提供了不同的图像处理和图标绘制功能，如下所述：\nQImage 类：提供了对图像文件的读取、保存和处理功能。可以通过 QImage 类的构造函数读取不同格式的图像文件，可以使用 QImage 类的成员函数进行图像处理。\nQPixmap 类：提供了对位图图像的处理功能。QPixmap 类类似于 QImage 类，但是它使用的是 QPixmap 类型的像素数据，而不是 QImage 类型的像素数据。通过 QPixmap 类的构造函数，可以创建一个 QPixmap 对象，可以使用 QPixmap 类的成员函数进行位图处理。\nQIcon 类：提供了图标绘制功能。通过 QIcon 类的构造函数，可以创建一个 QIcon 对象，并指定其图标的文件名，可以使用 QIcon 类的成员函数进行图标操作。\n总结起来，从 PyQt5.QtGui 模块中导入 QImage、QPixmap 和 QIcon 包，可以为程序提供强大的图像处理和图标绘制功能，从而实现丰富的图形用户界面。\n从 PyQt5.QtWidgets 模块中导入的几个类和函数主要用于构建和管理图形用户界面（GUI）的各个组件。以下是每个导入项的作用描述：\nQListWidget 类：是一个用于显示列表项的控件。通过 QListWidget 类，可以创建和管理一个列表，并在列表中添加、删除和修改列表项。与 QComboBox 和 QTreeView 相比，QListWidget 的列表项是平面布局的，没有嵌套关系。QListWidget 控件通常用于需要显示大量简单列表项的场景，比如文件列表、程序菜单等。\nQListWidgetItem 类：用于表示 QListWidget 中的每个列表项。通过此类，可以设置和获取列表项的文本、图标、背景色等属性。它是 QListWidget 控件中常用的子类，提供了许多方法和属性，用于设置和获取列表项的文本、图标、背景色等属性，以及检查和设置列表项的选中状态。这些方法和属性使得 QListWidget 控件更加灵活和功能丰富，可以满足各种复杂的界面需求。\nQWidget 类：它是 PyQt5 中的一个基础窗口部件，是所有窗口部件的父类。它提供了一个矩形的绘制区域，可以在屏幕上绘制，并接收鼠标、键盘和其它事件。每一个 QWidget 部件都是矩形的，并且它们按垂直轴顺序排列。一个 QWidget 部件可以被它的父窗口部件或者它前面的窗口部件盖住一部分。\nQInputDialog 类：它用于向用户显示一个输入对话框，以便用户输入一些信息。它继承自 QDialog 类，因此它具有与 QDialog 类相同的基本特性，如对话框的标题、大小、位置等。与 QDialog 类不同的是，QInputDialog 类还包含一个输入框和一个确认按钮，用户可以在输入框中输入信息，然后通过确认按钮将输入的信息传递给父窗口。\nQLineEdit 类：QLineEdit 是 PyQt5 中的一种常用控件，用于输入单行文本。它可以在运行时动态获取，也可以添加图片、输入密码等功能。\nQMessageBox 类：用于创建一个消息对话框。通过 QMessageBox 类，可以设置对话框的类型（如信息、警告、确认等）、标题、文本等属性，并根据用户的回应执行相应的操作。它是 Qt 应用程序开发框架中的一个常用组件，是一种弹出式对话框，用于显示消息和允许用户对消息进行反馈。QMessageBox 可以显示不同类型的消息，例如提示、警告、错误和询问等，每种类型的对话框都有不同的图标和默认操作。用户可以通过单击不同的标准按钮对消息进行反馈，每个标准按钮都有一个预定义的文本、角色和十六进制数。\n综上，从 PyQt5.QtWidgets 模块中导入的这些类和函数，提供了构建和管理图形用户界面所需的基本组件和功能。这些组件和功能可以帮助开发者创建丰富多样的界面，实现与用户的交互。\n6.5.2 界面布局 客户端界面采用主窗口和多个子窗口组成。主窗口包含菜单栏、数据上传功能区和可视化展示区域。\n菜单栏 菜单栏位于主窗口顶部，包括课堂作弊检测、人脸注册、课堂动态点名模块、课堂专注度分析模块等菜单项。\n数据上传功能区 数据上传功能区位于主窗口左下部，有视频上传按钮。\n可视化展示区域 可视化展示区域位于主窗口中部，用于展示用户上传的视频、分析结果、文字记录等。\n6.5.3 功能实现 菜单栏功能实现 当用户点击菜单栏中的不同功能时，对应功能的实现代码会被调用。例如，点击课堂作弊检测菜单项时，会调用相应的检测算法并对结果进行展示。\n数据上传功能区功能实现 用户点击视频上传按钮时，触发视频上传功能。上传成功后，根据用户选择的视频，实现对应的功能。\n可视化展示区域功能实现 可视化展示区域根据用户上传的视频、分析结果、文字记录等信息进行展示。例如，上传视频后，可视化展示区域会显示视频的预览图、分析结果和相关文字记录。\n6.5.4 界面交互 菜单栏交互 用户点击菜单栏中的不同功能时，会触发相应的功能实现。例如，点击课堂作弊检测菜单项时，会弹出课堂作弊检测对话框，让用户选择要检测的视频。\n数据上传功能区交互 用户点击视频上传按钮时，会弹出文件选择对话框，让用户选择要上传的视频文件，方便用户选择。\n可视化展示区域交互 用户可以在可视化展示区域查看上传的视频、分析结果和文字记录等信息。\n6.5.5 用户体验优化 界面美观度优化 主界面采用简约风格，组件样式统一，保持界面美观。\n界面响应速度优化 优化代码实现，提高界面的响应速度，使操作流畅。\n用户操作友好度优化 对话框和提示信息使用友好的语言，让用户容易理解。\n6.5.5 具体实现界面 作弊检测： 课堂专注度分析： 人脸注册： 动态点名： 7. 标准规范设计 7.1管理流程标准 系统规划与立项：\n确定系统建设的目标和需求。 制定项目实施计划，包括时间表、人员分工、资金预算等。 成立项目领导小组，负责项目的监督和管理。 系统开发与测试：\n确定系统的功能和技术需求。 开发系统软件，并进行内部测试。 邀请专业人士和用户代表进行外部测试。 系统维护与升级：\n对系统进行定期的维护和检查，确保系统的稳定性和安全性。 根据用户需求和实际情况，对系统进行升级和改进。 记录系统运行日志，便于追踪和分析。 数据安全与保护：\n制定数据安全保护策略，确保数据的安全性和隐私性。 进行定期的数据备份，以防止数据丢失。 控制数据访问权限，防止数据泄露和滥用。 系统培训与指导：\n组织系统的培训活动，帮助教育工作者掌握系统的使用方法。 提供在线帮助和操作指南，方便用户随时查阅。 设立技术支持热线，提供及时的技术支持和指导。 7.2研发代码标准 7.2.1开发流程 需求分析：\n收集教育工作者和管理者的需求，明确系统的功能和特点。 研究学生的行为特点和教育管理理论，确保系统的科学性和实用性 制定需求文档，明确系统的功能、性能、安全等要求。 方案设计：\n设计系统的架构和模块，确定模块间的接口和协议。 选择合适的技术和开发工具，确保系统的稳定性和可维护性。 制定详细的开发计划，包括时间表、人员分工等。 系统开发：\n根据需求文档和设计方案进行编码和开发。 进行单元测试和集成测试，确保系统的稳定性和可靠性。 进行系统测试和性能测试，确保系统的性能和安全性。 系统集成与部署：\n集成各个模块，确保系统的完整性和稳定性。 安装和部署系统，确保系统的可用性和安全性。 进行系统验收，确保系统满足需求和标准。 系统维护与升级：\n对系统进行定期的维护和检查，确保系统的稳定性和安全性。 根据用户需求和实际情况，对系统进行升级和改进。 记录系统运行日志，便于追踪和分析。 7.2.2代码规范 命名规范：\n变量、函数、类、模块等命名应符合命名规范，使用有意义的名称。 尽量避免使用单个字符或缩写作为变量名。 命名要体现代码的功能和业务，便于他人理解。 代码缩进：\n使用统一的缩进风格，如 tabs 或 spaces。 缩进要保持一致，避免出现缩进不一致的情况。 代码注释：\n代码注释应简洁明了，阐述代码的功能、实现方法和注意事项。 注释应与代码同步更新，确保注释的准确性和有效性。 在关键位置添加注释，便于他人理解代码。 代码风格：\n代码应保持一致的风格，遵循一定的代码规范。 尽量避免使用过多的花括号和过长的代码行。 使用空格和换行符，使代码易于阅读。 代码安全性：\n遵循安全编程规范，防止代码注入、SQL 注入等安全问题。 对输入数据进行验证和过滤，确保数据的合法性和安全性。 使用安全的加密算法，保护敏感数据的隐私。 代码可维护性：\n编写易于维护的代码，提高代码的可读性和可理解性。 遵循模块化、组件化的设计理念，提高代码的复用性。 写入清晰的文档和注释，便于他人了解代码的功能和实现方法。 代码性能优化：\n优化代码性能，提高系统的响应速度和处理能力。 减少不必要的计算和内存占用，提高系统的资源利用率。 遵循性能优化的原则，如代码缓存、算法选择等。 7.3 服务接口标准 7.3.1接口分类 学生行为数据接口：用于获取学生行为数据，如学生在线学习记录、答题情况、学习习惯等。\n学生档案接口：用于获取学生基本信息，如学生姓名、年龄、性别、班级等。\n行为分析接口：用于对学生行为数据进行分析，生成分析报告，如学生学习情况分析、学科表现分析等。\n数据查询接口：用于查询学生行为数据和分析报告，支持多种查询条件，如时间、学科、学生等。\n7.3.2 接口参数 请求参数：描述请求的参数，如学生 ID、时间范围等。\n回复参数：描述接口返回的结果，如学生行为数据、分析报告等。\n7.3.3 接口返回格式 JSON 格式：使用 JSON 格式返回数据，支持数据的快速解析和处理。\n7.3.4 接口安全 身份认证：接口需要进行身份认证，确保只有授权的用户可以访问。\n数据加密：对敏感数据进行加密处理，如学生行为数据、分析报告等。\n7.3.5接口性能 响应时间：接口响应时间应尽量短，确保系统的高效性。\n吞吐量：接口应支持高并发请求，确保系统的稳定性和承受能力。\n7.3.6接口文档 为每个接口提供详细的文档，包括接口说明、请求参数、回复参数、示例代码等，便于开发者理解和使用。\n8项目实施方案 8.1 项目工期及其他说明 中小学学生行为跟踪与分析系统项目的研究进度计划分为三个阶段，共计 20天。在每个阶段，研究团队需要完成相应的任务，确保项目按计划进行。同时，在项目进行过程中，需要不断收集反馈，对系统进行改进和优化，以满足项目的实际需求。以下是具体设计进度计划：\n第一阶段学习语音识别与视频检测相关领域知识，完成环境部署任务。该阶段主要确定研究的目标、研究内容、研究方法、数据来源、样本选择、数据收集和数据处理等内容。该阶段的工作重点是确定研究的具体方案和实施计划，以及确定数据收集和处理的方法和工具；\n第二阶段完成概要设计与详细设计。该阶段主要负责收集和处理研究所需的数据。数据收集可以通过网络查找，视频监控等方式进行。数据处理可以通过数据清洗、数据转换、数据整合等方式进行。该阶段的工作重点是确保数据的准确性和可靠性，以及保证数据的完整性和一致性。对收集到的数据进行分析和处理，并建立基于大数据和机器学习的学生行为预测模型。该阶段的工作重点是选择合适的算法和模型；\n第三阶段完成项目总体工作，进一步完善项目框架布局，优化界面，完成项目最终模型，整理项目全部内容。该阶段的工作重点是对模型进行优化和验证，确保预测模型的准确性和可靠性。确保预测模型的实际应用效果，并评估项目的效果和可行性。总结研究的结果和发现，并撰写技术文档，确定研究结论和建议，以及对研究过程和结果进行评估和总结。\n8.2 项目质量保证期 本项目的质量保证期为项目进行时的20天。在此期间，研究团队需要对项目成果进行持续改进和优化，以确保项目的稳定性和可靠性。\n8.3 实施计划方案 8.3.1 项目实施进度计划 项目阶段 及里程碑 阶段划分 计划开始时间 计划结束时间 A-项目准备阶段 7.18 7.20 B-需求设计阶段 7.21 7.25 C-项目建设阶段 7.26 8.1 D-系统测试阶段 8.2 8.11 E-正式环境搭建阶段 7.26 8.11 F- 试运行阶段 8.2 8.11 F- 上线运行阶段 8.2 8.11 G- 项目验收阶段 8.11 8.11 8.3.2 项目实施策略 本项目实施策略主要包括以下几个方面：\n明确项目目标和任务分工：在项目启动阶段，研究团队需明确项目的具体目标、任务分工和时间进度，确保每个成员对项目的了解一致，便于项目按计划进行。 密切沟通与协作：在项目实施过程中，研究团队成员间要保持密切的沟通与协作，及时解决问题，确保项目顺利推进。 数据收集与处理：在项目进行过程中，需保证数据的准确性和可靠性，以及数据的完整性和一致性。对收集到的数据进行分析和处理，并建立基于大数据和机器学习的学生行为预测模型。 项目进度监控与调整：在项目实施过程中，需定期对项目进度进行监控，及时发现并解决问题。根据实际情况，对项目进度和计划进行调整，确保项目按计划进行。 持续优化与改进：在项目实施过程中，根据反馈对系统进行持续改进和优化，以满足项目的实际需求。 8.3.3 项目实施原则 本项目实施原则主要包括以下几个方面：\n目标导向原则：项目实施过程中，始终以项目目标为导向，确保项目进度、质量和效果的达成。 协作共享原则：研究团队成员间要密切协作，共享资源和信息，提高项目实施效率。 问题导向原则：针对项目实施过程中出现的问题，及时进行沟通解决，确保项目顺利推进。 持续改进原则：在项目实施过程中，根据反馈对系统进行持续改进和优化，以满足项目的实际需求。 8.3.4项目实施责任矩阵 在项目实施过程中，各团队成员需承担以下责任：\n项目整体管理，协调资源，确保项目按计划进行。 项目技术实施，确保项目质量。 根据设计文档进行开发工作，完成项目功能模块。 对开发完成的功能模块进行测试，确保项目稳定性和可靠性。 收集、处理和分析项目所需数据，为模型建立提供支持。 8.4 运维保障方案 8.4.1 运维概述 在项目实施过程中，为确保项目系统正常运行，对本项目所涉及的软硬件资源、网络环境等进行维护、管理和优化。运维工作贯穿项目实施的整个生命周期，包括项目启动、运行、维护和终结阶段。\n8.4.2 运维内容 根据项目的特点和需求，运维内容包括以下几个方面：\n环境部署与维护：确保项目所需的软硬件资源、网络环境等按照设计要求进行部署，并保持稳定运行。 数据收集与处理：负责收集、处理和分析项目所需数据，为模型建立提供支持。 系统监控与调优：对项目系统进行实时监控，发现并解决系统故障，确保系统稳定运行。根据系统运行情况，对系统进行性能调优，提高系统运行效率。 应急响应：建立应急响应机制，及时应对项目实施过程中可能出现的突发事件，确保项目顺利进行。 系统升级与优化：根据项目需求和反馈，对系统进行升级和优化，提高系统的功能性和用户体验。 8.4.3 应急响应策略 在项目实施过程中，可能遇到各种突发事件，如系统故障、网络中断、数据泄露等。为确保项目顺利进行，需建立应急响应策略，包括以下几个方面：\n事件发现与报告：建立项目紧急事件发现与报告机制，确保事件能够及时被发现并上报。 事件分类与评估：对上报的事件进行分类和评估，确定事件的紧急程度和影响范围，为事件响应提供参考。 应急响应与处置：根据事件的紧急程度和影响范围，制定相应的应急响应和处置方案，确保事件能够得到及时、有效的解决。 事件总结与反思：对事件进行总结和反思，分析事件原因，提出改进措施，避免类似事件的再次发生。 ","date":1709091390,"headings":[{"anchor":"1-项目概述","title":"1. 项目概述"},{"anchor":"11-项目名称","title":"1.1 项目名称"},{"anchor":"12-项目背景","title":"1.2 项目背景"},{"anchor":"2-项目总体建设思路","title":"2. 项目总体建设思路"},{"anchor":"3-建设目标与建设内容","title":"3. 建设目标与建设内容"},{"anchor":"31-建设目标","title":"3.1 建设目标"},{"anchor":"32-建设内容","title":"3.2 建设内容"},{"anchor":"4-项目需求分析","title":"4. 项目需求分析"},{"anchor":"41-功能需求分析","title":"4.1 功能需求分析"},{"anchor":"411-视频异常监测","title":"4.1.1 视频异常监测"},{"anchor":"412-人脸注册","title":"4.1.2 人脸注册"},{"anchor":"413-动态点名","title":"4.1.3 动态点名"},{"anchor":"414-课堂专注度分析","title":"4.1.4 课堂专注度分析"},{"anchor":"5-系统总体设计","title":"5. 系统总体设计"},{"anchor":"51-建设原则","title":"5.1 建设原则"},{"anchor":"52-建设思路","title":"5.2 建设思路"},{"anchor":"53-系统总体架构","title":"5.3 系统总体架构"},{"anchor":"531-总体架构","title":"5.3.1 总体架构"},{"anchor":"532-技术架构","title":"5.3.2 技术架构"},{"anchor":"54-关键技术","title":"5.4 关键技术"},{"anchor":"541-yolo目标检测算法","title":"5.4.1 Yolo目标检测算法"},{"anchor":"542-mot--多目标跟踪算法","title":"5.4.2 MOT\u0026ndash;多目标跟踪算法"},{"anchor":"543-deepsort--目标跟踪初探算法","title":"5.4.3 DeepSORT\u0026ndash;目标跟踪初探算法"},{"anchor":"6-详细功能设计","title":"6. 详细功能设计"},{"anchor":"61-作弊检测","title":"6.1 作弊检测"},{"anchor":"611-视频源读取模块","title":"6.1.1 视频源读取模块"},{"anchor":"612-目标检测模块","title":"6.1.2 目标检测模块"},{"anchor":"613-多人体姿态估计模块","title":"6.1.3 多人体姿态估计模块"},{"anchor":"614-异常行为回归预测模块","title":"6.1.4 异常行为回归预测模块"},{"anchor":"615-可视化模块","title":"6.1.5 可视化模块"},{"anchor":"62-课堂专注度分析","title":"6.2 课堂专注度分析"},{"anchor":"621-视频源读取模块","title":"6.2.1 视频源读取模块"},{"anchor":"622-目标检测模块","title":"6.2.2 目标检测模块"},{"anchor":"623-多人体姿态估计模块","title":"6.2.3 多人体姿态估计模块"},{"anchor":"624-注意力评估模块","title":"6.2.4 注意力评估模块"},{"anchor":"625-可视化模块","title":"6.2.5 可视化模块"},{"anchor":"63-人脸注册","title":"6.3 人脸注册"},{"anchor":"631-人脸检测","title":"6.3.1 人脸检测"},{"anchor":"632-静默活体检测","title":"6.3.2 静默活体检测"},{"anchor":"634-姿态估计","title":"6.3.4 姿态估计"},{"anchor":"635-人脸数据库管理","title":"6.3.5 人脸数据库管理"},{"anchor":"636-可视化模块","title":"6.3.6 可视化模块"},{"anchor":"64-动态点名","title":"6.4 动态点名"},{"anchor":"641-视频源读取模块","title":"6.4.1 视频源读取模块"},{"anchor":"642-人脸检测模块","title":"6.4.2 人脸检测模块"},{"anchor":"643-人脸编码模块","title":"6.4.3 人脸编码模块"},{"anchor":"644-人脸匹配模块","title":"6.4.4 人脸匹配模块"},{"anchor":"645-可视化模块","title":"6.4.5 可视化模块"},{"anchor":"65-界面设计","title":"6.5 界面设计"},{"anchor":"651-使用方法","title":"6.5.1 使用方法"},{"anchor":"652-界面布局","title":"6.5.2 界面布局"},{"anchor":"653-功能实现","title":"6.5.3 功能实现"},{"anchor":"654-界面交互","title":"6.5.4 界面交互"},{"anchor":"655-具体实现界面","title":"6.5.5 具体实现界面"},{"anchor":"655-用户体验优化","title":"6.5.5 用户体验优化"},{"anchor":"7-标准规范设计","title":"7. 标准规范设计"},{"anchor":"71管理流程标准","title":"7.1管理流程标准"},{"anchor":"721开发流程","title":"7.2.1开发流程"},{"anchor":"722代码规范","title":"7.2.2代码规范"},{"anchor":"72研发代码标准","title":"7.2研发代码标准"},{"anchor":"73-服务接口标准","title":"7.3 服务接口标准"},{"anchor":"731接口分类","title":"7.3.1接口分类"},{"anchor":"732-接口参数","title":"7.3.2 接口参数"},{"anchor":"733-接口返回格式","title":"7.3.3 接口返回格式"},{"anchor":"734-接口安全","title":"7.3.4 接口安全"},{"anchor":"735接口性能","title":"7.3.5接口性能"},{"anchor":"736接口文档","title":"7.3.6接口文档"},{"anchor":"81-项目工期及其他说明","title":"8.1 项目工期及其他说明"},{"anchor":"82-项目质量保证期","title":"8.2 项目质量保证期"},{"anchor":"83-实施计划方案","title":"8.3 实施计划方案"},{"anchor":"831-项目实施进度计划","title":"8.3.1 项目实施进度计划"},{"anchor":"832-项目实施策略","title":"8.3.2 项目实施策略"},{"anchor":"833-项目实施原则","title":"8.3.3 项目实施原则"},{"anchor":"834项目实施责任矩阵","title":"8.3.4项目实施责任矩阵"},{"anchor":"84-运维保障方案","title":"8.4 运维保障方案"},{"anchor":"841-运维概述","title":"8.4.1 运维概述"},{"anchor":"842-运维内容","title":"8.4.2 运维内容"},{"anchor":"843-应急响应策略","title":"8.4.3 应急响应策略"},{"anchor":"8项目实施方案","title":"8项目实施方案"}],"kind":"page","lang":"zh-hans","summary":"","title":"项目详细方案","url":"/%E6%99%BA%E6%85%A7%E8%AF%BE%E5%A0%82/%E9%A1%B9%E7%9B%AE%E8%AF%A6%E7%BB%86%E6%96%B9%E6%A1%88/","year":"2024"},{"content":"1. 作弊检测： 该应用通过抓拍异常行为、记录异常行为发生时间和绘制异常行为时间曲线等方式，将异常行为回归预测模块的分析结果呈现出来，为教师提供直观、便捷的异常行为查看和分析工具。这有助于提高教学质量，促进学生课堂上的良好行为。\n界面正中心的实时抓拍会对每个学生的异常状态进行抓拍，并记录下异常行为发生的时间。这样一来，教师就可以直观地了解学生在课堂上的异常行为情况。\n界面左下角的本地视频功能可以进行本地视频上传进行异常行为分析，左上角可以选择摄像头进行分析。\n界面右侧的可视化模块会根据异常行为发生的时间、种类和数量，绘制异常行为时间曲线。这条曲线有助于教师进一步了解学生异常行为的分布情况，以便有针对性地进行干预和辅导。\n在前端客户端上，教师可以通过浏览器或其他设备查看学生的异常行为情况。这样的展示方式既方便又直观，有助于教师更好地关注学生的行为变化，提高教学质量。\n2. 课堂专注度分析： 该部分通过对学生的姿态检测，可以有效的辅助老师有效监督学生的学习上课情况，对学生的上课行为进行分析及评分，避免出现课堂不认真听讲、考试作弊等不良的行为。\n界面正中心的课堂专注度会显示实时的画面，它在显示屏上绘制骨骼关键点、绘制目标检测框和动作分类。\n界面四周是注意力评估结果，包括群体专注曲线，头部姿态专注度评分曲线，情绪专注度评分曲线，行为专注度评分曲线和评价因素。若显示结果冲突，会提示请正视摄像头。这样一来，教师就可以直观地了解学生在课堂上的课堂专注度情况。\n界面的左侧可以选择摄像头，可以上传本地视频进行分析。\n3. 人脸注册： 用户使用人脸注册功能时初始化人脸数据库并加载已有的人脸数据库数据信息。人脸数据库中存储的信息包括学生姓名、编码及学生照片。根据用户操作，可以对人脸数据库中的数据信息进行增加或者修改。\n界面左侧是人脸数据库，用来保存注册成功的人脸图像，左上方还可增添删除班级过滤条件和学生过滤条件。\n界面右侧会显示摄像头实时的画面，并设置一个人形框，用户需要在保证自己的脸在框中来进行人脸的识别及处理。在注册的过程中，屏幕上会有相应的文字提示来帮助用户进行人脸注册。注册完成后，用户输入名字完成注册，注册结果会保存在人脸数据库中并在人脸数据库列表中显示注册的人像及名字。右侧上方可勾选人脸注册的细小功能，如注册、居中提示、人形边框和处理最近人脸。右侧下方显示人脸注册过程的完成率。\n4. 动态点名： 这个模块负责将动态点名的结果进行可视化展示，它会对每个学生的的人脸进行抓拍，并与人脸数据库进行匹配，若匹配成功则代表这个学生出席，点名成功显示已签到，否则不显示。这样一来，教师就可以直观地了解学生在课堂上的出席情况。\n界面中部上方可勾选人脸注册的细小功能，如显示标注，显示原始注册和自动提前截止。中部显示本地视频画面或者摄像头抓拍的实时画面，画面上绘制人脸的位置和标签，人脸的位置和标签可以直观地展示已签到的学生姓名，可以直观找到未签到的学生。\n界面右侧上方可选择人脸匹配的阈值，阈值越高，匹配难度越大。右侧上方还显示了正脸误差。右侧下方显示已签到和未签到学生姓名。\n该功能可选择使用本地视频或者摄像头抓拍的实时画面。左侧上方可查看各个摄像头抓拍的实时画面，左侧下方可选择上传的本地视频。\n","date":1709090409,"headings":[{"anchor":"1-作弊检测","title":"1. 作弊检测："},{"anchor":"2-课堂专注度分析","title":"2. 课堂专注度分析："},{"anchor":"3-人脸注册","title":"3. 人脸注册："},{"anchor":"4-动态点名","title":"4. 动态点名："}],"kind":"page","lang":"zh-hans","summary":"","title":"中小学学生行为跟踪与分析系统用户手册","url":"/%E6%99%BA%E6%85%A7%E8%AF%BE%E5%A0%82/%E4%B8%AD%E5%B0%8F%E5%AD%A6%E5%AD%A6%E7%94%9F%E8%A1%8C%E4%B8%BA%E8%B7%9F%E8%B8%AA%E4%B8%8E%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F%E7%95%8C%E9%9D%A2%E5%B1%95%E7%A4%BA/","year":"2024"},{"content":"由于隐私原因，视频只展示了课堂行为分析模块，没有展示人脸注册，动态签到模块\n","date":1709088396,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"系统模拟视频","url":"/%E6%99%BA%E6%85%A7%E8%AF%BE%E5%A0%82/%E7%B3%BB%E7%BB%9F%E6%A8%A1%E6%8B%9F%E8%A7%86%E9%A2%91/","year":"2024"},{"content":"修订历史\n版本号 作者 内容提要 发布日期 V1.0 姚艺峰、牟钟庆、杨燕怡、单怡婧、查懿珈、钟莹滢 首次成稿 2023-7-24 1. 名词解释 名称 说明 视频通道 提供用户使用摄像头或不同教室场景实现课堂行为分析 异常行为检测 对学生上课存在的交头接耳、低头、转头等进行目标检测，实现异常行为的标记 课堂专注度分析 通过目标检测，进行注意力评估，分析学生上课专注度，实现数据的可视化，直接展现学生课堂的上课状态 人脸注册 将课堂上所有学生的人脸数据都进行注册，存储在数据库中，便于课堂的管理 动态点名 进行人脸识别与人脸匹配，可以对具体上课人数进行统计，计算课堂出勤率 2. 项目概述 研究课堂中小学学生行为跟踪与分析系统的目的是深入了解学生在课堂教学中的行为表现，通过数据分析和可视化工具识别和解决学生行为问题，以帮助学生更好地参与课堂活动，提高学习成绩和课堂表现，研究课堂学生行为数据的收集、存储、处理和分析方法，评估不同方法的优缺点，为开发有效的课堂学生行为跟踪与分析系统提供技术支持。\n开发课堂中小学学生行为跟踪与分析系统，建立学生行为数据的可视化平台，帮助教师更好地了解学生在课堂中的行为问题，为学生提供个性化的干预和支持服务。\n3. 项目功能及用户范围 图1 学生行为检测系统功能图\n功能 用户类型 描述 本地视频上传 教师 通过视频或摄像头接口直接上传视频流 异常行为检测 教师 对学生上课存在的交头接耳、低头、转头等进行目标检测，实现异常行为的标记 课堂专注度分析 教师 通过目标检测，进行注意力评估，分析学生上课专注度，实现数据的可视化，直接展现学生课堂的上课状态 人脸注册 教师 将课堂上所有学生的人脸数据都进行注册，存储在数据库中，便于课堂的管理 动态点名 教师 进行人脸识别与人脸匹配，可以对具体上课人数进行统计，计算课堂出勤率 异常行为图像抓拍 教师 实现截取图片和保存的功能 人脸数据库管理 教师 通过人脸注册的学生数据添加到人脸数据库中，教师可根据需要添加/删除学生信息 4. 项目功能详细说明 4.1 视频异常检测 课堂异常行为检测是指通过人工智能技术对学生课堂行为进行实时监测和分析，发现学生出现异常行为时及时报警，以便教师及时干预和纠正，提高课堂管理效率和学生学习效果。\n该功能包括以下详细介绍：\n（1）监测和分析学生课堂行为：通过人工智能技术，对学生课堂行为进行监测和分析，包括坐姿、注意力等方面；\n（2）异常行为类型：将动作自主规定为正常、传纸条、低头偷看、东张西望等四种类型，其中后三种行为均属于异常行为；\n（3）异常行为记录与统计：系统可以记录学生的异常行为情况，并进行统计分析，以便教师更好地了解学生的课堂表现；\n（4）异常行为干预和纠正：教师可以根据系统标记的异常行为，及时干预和纠正学生的异常行为，提高管理效率。。\n4.2 人脸注册 人脸注册功能模块主要是通过摄像头获取视频流，采用静默活体检测技术，借助开源模型，对视频流的单帧图片进行人脸检测，对检测到的人脸进行活体检测，若大于阈值，则判定为活体，否则为非活体，并检测到的活体存储在人脸数据库中，实现人脸注册功能。教师可以在系统中对学生进行人脸注册。在注册过程中，系统会要求学生面对摄像头进行人脸采集。采集完成后，系统会自动进行人脸检测和活体检测。如果检测结果为活体，学生的人脸信息将被存储在人脸数据库中，完成注册。\n该功能包括以下详细介绍：\n（1）人脸检测\n人脸检测是基于视频流进行的。摄像头采集的视频流会经过人脸检测算法的处理，以便在视频中识别出人脸。常用的人脸检测算法包括基于深度学习的卷积神经网络（CNN）等。这些算法可以识别出人脸的位置、大小和关键点，为后续的活体检测做好准备。\n（2） 活体检测\n在识别出人脸后，需要对检测到的人脸进行活体检测，以确保获取到的人脸信息是真实的。活体检测通常基于深度学习技术，如卷积神经网络（CNN）等。在检测过程中，系统会分析人脸图像的纹理、颜色、形状等特征，并与预设的活体检测阈值进行比较。如果特征值大于阈值，则判定为活体；否则为非活体。\n（3）人脸数据存储\n经过人脸检测和活体检测后，检测到的活体人脸信息会被存储在人脸数据库中，以便教师在后续的教学管理中进行身份核实。\n（4）人脸信息管理\n教师可以在系统中对学生的人脸信息进行管理，包括添加、删除和查询学生人脸信息。当学生信息发生变化时，如转学、退学等，教师可以在系统中对学生的人脸信息进行相应操作。此外，教师还可以通过系统查询学生的人脸信息，了解学生身份是否真实有效。\n（5）安全保护\n为了保护学生隐私，系统需要采取一定的安全措施。在人脸采集和识别过程中，系统应遵循相关法律法规，确保学生的人脸信息不被泄露。\n（6）异常处理\n在人脸注册过程中，可能会出现一些异常情况，如学生人脸信息无法识别、学生拒绝参加人脸采集等。针对这些异常情况，系统需提供相应的处理措施，如重新采集人脸信息、手动输入学生信息等，以确保学生身份真实有效。\n4.3 动态点名 动态点名功能模块为学生通过摄像头完成签到，可多人同时签到，主要借助dlib库实现人脸识别功能，对人脸特征进行提取，在视频流中抓取人脸特征，然后将要识别的对象与人脸数据库中的图片进行距离计算，实现人脸识别，完成动态点名功能。\n该功能包括以下详细介绍：\n（1）对视频流进行人脸检测，以识别出参与签到的学生。人脸检测可以基于 dlib 库等开源工具，通过卷积神经网络（CNN）等算法实现。在检测过程中，系统会分析视频流中的每一帧图像，找出其中的人脸，并记录人脸的位置、大小、关键点等信息。\n（2）人脸识别。在提取人脸特征后，系统会将要识别的对象与人脸数据库中的图片进行距离计算，实现人脸识别。常用的距离计算方法包括欧几里得距离、余弦相似度等。如果计算得到的距离小于预设的阈值，则判定为匹配成功，表示学生已签到；否则为匹配失败，表示学生未签到。\n4.4 课堂专注度分析 课堂专注度分析是指通过人工智能技术对学生上课情况进行实时监测和分析，以便教师及时干预和纠正，提高课堂管理效率和学生学习效果。\n该功能包括以下详细介绍：\n（1）监测和分析学生课堂行为：通过人工智能技术，对学生课堂专注度进行监测和分析，包括行为、情绪、头部姿态等方面；\n（2）专注度分析报告：系统可以根据学生课堂专注度的监测和分析结果，生成专注度分析报告，供教师参考；\n（3）专注度记录和统计：系统可以记录每个学生课堂专注度的情况，并进行统计分析，以便教师更好地了解学生的学习状况；\n（4）课堂行为干预和纠正：教师可以根据系统专注度记录情况，及时干预和纠正学生的上课状态，提高管理效率。\n","date":1709087640,"headings":[{"anchor":"1-名词解释","title":"1. 名词解释"},{"anchor":"2-项目概述","title":"2. 项目概述"},{"anchor":"3-项目功能及用户范围","title":"3. 项目功能及用户范围"},{"anchor":"4-项目功能详细说明","title":"4. 项目功能详细说明"},{"anchor":"41-视频异常检测","title":"4.1 视频异常检测"},{"anchor":"42-人脸注册","title":"4.2 人脸注册"},{"anchor":"43-动态点名","title":"4.3 动态点名"},{"anchor":"44-课堂专注度分析","title":"4.4 课堂专注度分析"}],"kind":"page","lang":"zh-hans","summary":"","title":"中小学学生课堂行为跟踪与分析系统需求说明书","url":"/%E6%99%BA%E6%85%A7%E8%AF%BE%E5%A0%82/%E4%B8%AD%E5%B0%8F%E5%AD%A6%E5%AD%A6%E7%94%9F%E8%AF%BE%E5%A0%82%E8%A1%8C%E4%B8%BA%E8%B7%9F%E8%B8%AA%E4%B8%8E%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F%E9%9C%80%E6%B1%82%E8%AF%B4%E6%98%8E%E4%B9%A6/","year":"2024"},{"content":"","date":1709052539,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"卷积神经网络（CNN）","url":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Ccnn/","year":"2024"},{"content":" ","date":1709043108,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"ConALAE 代码解读代码解读","url":"/%E6%9D%90%E6%96%99%E7%94%9F%E6%88%90/conalae-%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/","year":"2024"},{"content":" ","date":1709038786,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"专利证书《基于GAN和VAE的材料成分生成方法及评价方法》","url":"/%E6%9D%90%E6%96%99%E7%94%9F%E6%88%90/%E4%B8%93%E5%88%A9%E8%AF%81%E4%B9%A6/","year":"2024"},{"content":"Aggregation fastreid架构图中聚合层（Aggregation）的目的是将主干网产生的特征图聚合成一个全局特征图。\n主要采取上图中的四种池化操作。\nHead Head：获取网络输出内容，利用之前提取的特征，做出预测。\n如上图所示，一共提供了三种head：\nLinear head、BN head和Reduction head可供选择。\n配置方法 ","date":1709037668,"headings":[{"anchor":"aggregation","title":"Aggregation"},{"anchor":"head","title":"Head"},{"anchor":"配置方法","title":"配置方法"}],"kind":"page","lang":"zh-hans","summary":"","title":"Aggregation\u0026Head","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/fastreid%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/aggregationhead/","year":"2024"},{"content":" 在Meta_arch文件夹下添加模型结构蓝图\n定义第三方模块时记得在类前加上@META_ARCH_REGISTRY.register() 修改config配置文件\n重写train.py/test.py\n","date":1709037439,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"添加第三方模型","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/fastreid%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/%E6%B7%BB%E5%8A%A0%E7%AC%AC%E4%B8%89%E6%96%B9%E6%A8%A1%E5%9E%8B/","year":"2024"},{"content":"1class Baseline(nn.Module): 2 \u0026#34;\u0026#34;\u0026#34; 3 Baseline architecture. Any models that contains the following two components: 4 1. Per-image feature extraction (aka backbone) 5 2. Per-image feature aggregation and loss computation 6 \u0026#34;\u0026#34;\u0026#34; fastreid不仅具有系统配置可管理（Manageable system configuration）的优点，同时其还有模块化和可扩展性的特性（Modular and extensible design），这也使得该项目的灵活性大大增强。\n类型： 如图所示，fastreid提供了丰富的backbone可供选择，如：resnet、vit等等。\n该部分用于对上一阶段经过预处理后的图片进行特征提取，得到对应的特征图。\n配置方法 更改backbone需要在最底层的配置文件Base-bagtricks.yml中更改对应的Backbone name，如下如所示：\n","date":1709036938,"headings":[{"anchor":"类型","title":"类型："},{"anchor":"配置方法","title":"配置方法"}],"kind":"page","lang":"zh-hans","summary":"","title":"更改backbone","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/fastreid%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/%E6%A8%A1%E5%9E%8B%E6%9B%B4%E6%94%B9backbone/","year":"2024"},{"content":"Modeling 文件包含了fastreid主要的模块设计和结构蓝图。同时Fast_reid 设计了两个重要的中间件，通过这两个中间件实现了配置文件中的name到object的映射变换，将config中的字符串变换为实际的模型组件以调用结构蓝图。这两个中间件分别是fastreid文件夹下的engine和utils下的registry.py文件。\n结构蓝图 1.Meta_arch就是模型的结构蓝图，将backbone,hesds,losses不同的积木组件拼接起来\n引擎engine 2.Engine 作为中间件，设置了Trainerbase, Simpletrainer, DefaultTrainer三个类相互继承，使用DefaultTrainer可以使用特定的config加载特定的模型。\n1 class TrainerBase: 2 \u0026#34;\u0026#34;\u0026#34; 3 Base class for iterative trainer with hooks. 4 The only assumption we made here is: the training runs in a loop. 5 A subclass can implement what the loop is. 6 We made no assumptions about the existence of dataloader, optimizer, model, etc. 7 Attributes: 8 iter(int): the current iteration. 9 epoch(int): the current epoch. 10 start_iter(int): The iteration to start with. 11 By convention the minimum possible value is 0. 12 max_epoch (int): The epoch to end training. 13 storage(EventStorage): An EventStorage that\u0026#39;s opened during the course of training. 14 \u0026#34;\u0026#34;\u0026#34; 1class SimpleTrainer(TrainerBase): 2 \u0026#34;\u0026#34;\u0026#34; 3 A simple trainer for the most common type of task: 4 single-cost single-optimizer single-data-source iterative optimization. 5 It assumes that every step, you: 6 1. Compute the loss with a data from the data_loader. 7 2. Compute the gradients with the above loss. 8 3. Update the model with the optimizer. 9 If you want to do anything fancier than this, 10 either subclass TrainerBase and implement your own `run_step`, 11 or write your own training loop. 12 \u0026#34;\u0026#34;\u0026#34; 1class DefaultTrainer(TrainerBase): 2 \u0026#34;\u0026#34;\u0026#34; 3 A trainer with default training logic. Compared to `SimpleTrainer`, it 4 contains the following logic in addition: 5 1. Create model, optimizer, scheduler, dataloader from the given config. 6 2. Load a checkpoint or `cfg.MODEL.WEIGHTS`, if exists. 7 3. Register a few common hooks. 8 It is created to simplify the **standard model training workflow** and reduce code boilerplate 9 for users who only need the standard training workflow, with standard features. 10 It means this class makes *many assumptions* about your training logic that 11 may easily become invalid in a new research. In fact, any assumptions beyond those made in the 12 :class:`SimpleTrainer` are too much for research. 13 The code of this class has been annotated about restrictive assumptions it mades. 14 When they do not work for you, you\u0026#39;re encouraged to: 15 1. Overwrite methods of this class, OR: 16 2. Use :class:`SimpleTrainer`, which only does minimal SGD training and 17 nothing else. You can then add your own hooks if needed. OR: 18 3. Write your own training loop similar to `tools/plain_train_net.py`. 19 Also note that the behavior of this class, like other functions/classes in 20 this file, is not stable, since it is meant to represent the \u0026#34;common default behavior\u0026#34;. 21 It is only guaranteed to work well with the standard models and training workflow in fastreid. 22 To obtain more stable behavior, write your own training logic with other public APIs. 23 Attributes: 24 scheduler: 25 checkpointer: 26 cfg (CfgNode): 27 Examples: 28 .. code-block:: python 29 trainer = DefaultTrainer(cfg) 30 trainer.resume_or_load() # load last checkpoint or MODEL.WEIGHTS 31 trainer.train() 32 \u0026#34;\u0026#34;\u0026#34; registry登记仓库 3.registry是模型结构的登记仓库（也可以理解为不同结构模型的时使用接口），将模型的name映射为实际的module,通过registry实现了第三方模块的注册与创建\n1class Registry(object): 2 \u0026#34;\u0026#34;\u0026#34; 3 The registry that provides name -\u0026gt; object mapping, to support third-party 4 users\u0026#39; custom modules. 5 To create a registry (e.g. a backbone registry): 6 .. code-block:: python 7 BACKBONE_REGISTRY = Registry(\u0026#39;BACKBONE\u0026#39;) 8 To register an object: 9 .. code-block:: python 10 @BACKBONE_REGISTRY.register() 11 class MyBackbone(): 12 ... 13 Or: 14 .. code-block:: python 15 BACKBONE_REGISTRY.register(MyBackbone) 16 \u0026#34;\u0026#34;\u0026#34; ","date":1709036558,"headings":[{"anchor":"registry登记仓库","title":"registry登记仓库"},{"anchor":"引擎engine","title":"引擎engine"},{"anchor":"结构蓝图","title":"结构蓝图"}],"kind":"page","lang":"zh-hans","summary":"","title":"模型结构解读","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/fastreid%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E8%A7%A3%E8%AF%BB/","year":"2024"},{"content":"这里我的示例代码结构如下所示，个人习惯为了方便调试和后续接口使用，和官方仓库不一样。\n1　├── configs（配置文件路径） 2　├── Market1501 3　├── bagtricks_R50.yml 4　├── Base-bagtricks.yml 5　├── datasets（数据集目录） 6　├── Market-1501-v15.09.15 （这个数据集名不要改） 7　├── bounding_box_test (750人的19732张图像用于测试) 8　├── bounding_box_train (751人的12936张图像用于训练) 9　├── query (750人的3368张图像用于查询) 10　├── fastreid 11　├── model（预训练模型目录），下载好的预训练模型存放在这 12　├── demo.py（提取图像的特征，并保存），来自原来的demo目录 13　├── predictor.py （模型加载文件），来自原来的demo目录 14　├── train_net.py （模型训练与测试封装版代码），来自原来的tools目录 15　├── visualize_result.py （可视化特征提取结果），来自原来的demo目录 重点关注几个py文件，我直接挪到根目录下了。还有模型文件的保存路径，config预训练模型地址，数据集的名字也要注意的。各个文件具体使用可以看看下面介绍，都有代码注释。\n特别注意，py文件为了方便调试，我直接在代码里面设置了*args的参数，实际使用要特别注意。\ndemo.py 这个代码就是加载模型（调用predictor.py），提取查询图像的特征，并保存为npy文件。保存在demo_output文件夹下，一张图像对一个npy文件。这些包含特征向量的npy文件可供后续向量检索使用。\n1# encoding: utf-8 2\u0026#34;\u0026#34;\u0026#34; 3@author: liaoxingyu 4@contact: sherlockliao01@gmail.com 5提取图像的特征，并保存 6\u0026#34;\u0026#34;\u0026#34; 7 8import argparse 9import glob 10import os 11import sys 12 13import torch.nn.functional as F 14import cv2 15import numpy as np 16import tqdm 17from torch.backends import cudnn 18 19sys.path.append(\u0026#39;.\u0026#39;) 20 21from fastreid.config import get_cfg 22from fastreid.utils.logger import setup_logger 23from fastreid.utils.file_io import PathManager 24 25from predictor import FeatureExtractionDemo 26 27# import some modules added in project like this below 28# sys.path.append(\u0026#34;projects/PartialReID\u0026#34;) 29# from partialreid import * 30 31cudnn.benchmark = True 32setup_logger(name=\u0026#34;fastreid\u0026#34;) 33 34 35# 读取配置文件 36def setup_cfg(args): 37 # load config from file and command-line arguments 38 cfg = get_cfg() 39 # add_partialreid_config(cfg) 40 cfg.merge_from_file(args.config_file) 41 cfg.merge_from_list(args.opts) 42 cfg.freeze() 43 return cfg 44 45 46def get_parser(): 47 parser = argparse.ArgumentParser(description=\u0026#34;Feature extraction with reid models\u0026#34;) 48 parser.add_argument( 49 \u0026#34;--config-file\u0026#34;, # config路径，通常包含模型配置文件 50 metavar=\u0026#34;FILE\u0026#34;, 51 help=\u0026#34;path to config file\u0026#34;, 52 ) 53 parser.add_argument( 54 \u0026#34;--parallel\u0026#34;, # 是否并行 55 action=\u0026#39;store_true\u0026#39;, 56 help=\u0026#39;If use multiprocess for feature extraction.\u0026#39; 57 ) 58 parser.add_argument( 59 \u0026#34;--input\u0026#34;, # 输入图像路径 60 nargs=\u0026#34;+\u0026#34;, 61 help=\u0026#34;A list of space separated input images; \u0026#34; 62 \u0026#34;or a single glob pattern such as \u0026#39;directory/*.webp\u0026#39;\u0026#34;, 63 ) 64 parser.add_argument( 65 \u0026#34;--output\u0026#34;, # 输出结果路径 66 default=\u0026#39;demo_output\u0026#39;, 67 help=\u0026#39;path to save features\u0026#39; 68 ) 69 parser.add_argument( 70 \u0026#34;--opts\u0026#34;, 71 help=\u0026#34;Modify config options using the command-line \u0026#39;KEY VALUE\u0026#39; pairs\u0026#34;, 72 default=[], 73 nargs=argparse.REMAINDER, 74 ) 75 return parser 76 77 78def postprocess(features): 79 # Normalize feature to compute cosine distance 80 features = F.normalize(features) # 特征归一化 81 features = features.cpu().data.numpy() 82 return features 83 84 85if __name__ == \u0026#39;__main__\u0026#39;: 86 args = get_parser().parse_args() # 解析输入参数 87 # 调试使用，使用的时候删除下面代码 88 # --- 89 args.config_file = \u0026#34;./configs/Market1501/bagtricks_R50.yml\u0026#34; # config路径 90 args.input = \u0026#34;./datasets/Market-1501-v15.09.15/query/*.webp\u0026#34; # 图像路径 91 # --- 92 93 cfg = setup_cfg(args) # 读取cfg文件 94 demo = FeatureExtractionDemo(cfg, parallel=args.parallel) # 加载特征提取器，也就是加载模型 95 96 PathManager.mkdirs(args.output) # 创建输出路径 97 if args.input: 98 if PathManager.isdir(args.input[0]): # 判断输入的是否为路径 99 # args.input = glob.glob(os.path.expanduser(args.input[0])) # 原来的代码有问题 100 args.input = glob.glob(os.path.expanduser(args.input)) # 获取输入路径下所有的文件路径 101 assert args.input, \u0026#34;The input path(s) was not found\u0026#34; 102 for path in tqdm.tqdm(args.input): # 逐张处理 103 img = cv2.imread(path) 104 feat = demo.run_on_image(img) # 提取图像特征 105 feat = postprocess(feat) # 后处理主要是特征归一化 106 np.save(os.path.join(args.output, os.path.basename(path).split(\u0026#39;.\u0026#39;)[0] + \u0026#39;.npy\u0026#39;), feat) # 保存图像对应的特征，以便下次使用 visualize_result.py 这个代码就是加载模型（调用predictor.py），提取查询图像的特征，计算模型的各个精度指标。输出模型的ROC结果图，以及某张图像的匹配结果图像。输出目录为vis_rank_list。\nROC结果图如下图所示，ROC曲线下的面积AUC越大，表示模型效果越好。top1精度93.37左右。\n某张图像的匹配结果图像如下所示。每张图有1张查询图和5张查询结果图，左1为查询图像，其他为查询结果图。蓝色框表示查询结果错误，红色框表示查询结果正确。在查询结果图上有标题，比如0.976/false/cam1，表示当前查询结果图像和查询图像特征距离为0.976，查询结果为false(查询错误)，该查询结果来自cam1摄像头。查询图像上的标题，如0.9967/cam2，这里0.9967表示查询图像的查询结果精度指标，cam2表示查询图像来自cam2摄像头。\n1# encoding: utf-8 2\u0026#34;\u0026#34;\u0026#34; 3@author: xingyu liao 4@contact: sherlockliao01@gmail.com 5可视化特征提取结果 6\u0026#34;\u0026#34;\u0026#34; 7 8import argparse 9import logging 10import sys 11 12import numpy as np 13import torch 14import tqdm 15from torch.backends import cudnn 16 17sys.path.append(\u0026#39;.\u0026#39;) 18 19import torch.nn.functional as F 20from fastreid.evaluation.rank import evaluate_rank 21from fastreid.config import get_cfg 22from fastreid.utils.logger import setup_logger 23from fastreid.data import build_reid_test_loader 24from predictor import FeatureExtractionDemo 25from fastreid.utils.visualizer import Visualizer 26 27# import some modules added in project 28# for example, add partial reid like this below 29# sys.path.append(\u0026#34;projects/PartialReID\u0026#34;) 30# from partialreid import * 31 32cudnn.benchmark = True 33setup_logger(name=\u0026#34;fastreid\u0026#34;) 34 35logger = logging.getLogger(\u0026#39;fastreid.visualize_result\u0026#39;) 36 37 38# 读取配置文件 39def setup_cfg(args): 40 # load config from file and command-line arguments 41 cfg = get_cfg() 42 # add_partialreid_config(cfg) 43 cfg.merge_from_file(args.config_file) 44 cfg.merge_from_list(args.opts) 45 cfg.freeze() 46 return cfg 47 48 49def get_parser(): 50 parser = argparse.ArgumentParser(description=\u0026#34;Feature extraction with reid models\u0026#34;) 51 parser.add_argument( 52 \u0026#34;--config-file\u0026#34;, # config路径，通常包含模型配置文件 53 metavar=\u0026#34;FILE\u0026#34;, 54 help=\u0026#34;path to config file\u0026#34;, 55 ) 56 parser.add_argument( 57 \u0026#39;--parallel\u0026#39;, # 是否并行 58 action=\u0026#39;store_true\u0026#39;, 59 help=\u0026#39;if use multiprocess for feature extraction.\u0026#39; 60 ) 61 parser.add_argument( 62 \u0026#34;--dataset-name\u0026#34;, # 数据集名字 63 help=\u0026#34;a test dataset name for visualizing ranking list.\u0026#34; 64 ) 65 parser.add_argument( 66 \u0026#34;--output\u0026#34;, # 输出结果路径 67 default=\u0026#34;./vis_rank_list\u0026#34;, 68 help=\u0026#34;a file or directory to save rankling list result.\u0026#34;, 69 70 ) 71 parser.add_argument( 72 \u0026#34;--vis-label\u0026#34;, # 输出结果是否查看 73 action=\u0026#39;store_true\u0026#39;, 74 help=\u0026#34;if visualize label of query instance\u0026#34; 75 ) 76 parser.add_argument( 77 \u0026#34;--num-vis\u0026#34;, # 挑选多少张图像用于结果展示 78 default=1000, 79 help=\u0026#34;number of query images to be visualized\u0026#34;, 80 ) 81 parser.add_argument( 82 \u0026#34;--rank-sort\u0026#34;, # 结果展示是相似度排序方式，默认从小到大排序 83 default=\u0026#34;ascending\u0026#34;, 84 help=\u0026#34;rank order of visualization images by AP metric\u0026#34;, 85 ) 86 parser.add_argument( 87 \u0026#34;--label-sort\u0026#34;, # label结果展示是相似度排序方式，默认从小到大排序 88 default=\u0026#34;ascending\u0026#34;, 89 help=\u0026#34;label order of visualization images by cosine similarity metric\u0026#34;, 90 ) 91 parser.add_argument( 92 \u0026#34;--max-rank\u0026#34;, # 显示topk的结果，默认显示前10个结果 93 default=5, 94 help=\u0026#34;maximum number of rank list to be visualized\u0026#34;, 95 ) 96 parser.add_argument( 97 \u0026#34;--opts\u0026#34;, 98 help=\u0026#34;Modify config options using the command-line \u0026#39;KEY VALUE\u0026#39; pairs\u0026#34;, 99 default=[], 100 nargs=argparse.REMAINDER, 101 ) 102 return parser 103 104 105if __name__ == \u0026#39;__main__\u0026#39;: 106 args = get_parser().parse_args() 107 # 调试使用，使用的时候删除下面代码 108 # --- 109 args.config_file = \u0026#34;./configs/Market1501/bagtricks_R50.yml\u0026#34; # config路径 110 args.dataset_name = \u0026#39;Market1501\u0026#39; # 数据集名字 111 args.vis_label = False # 是否显示正确label结果 112 args.rank_sort = \u0026#39;descending\u0026#39; # 从大到小显示关联结果 113 args.label_sort = \u0026#39;descending\u0026#39; # 从大到小显示关联结果 114 # --- 115 116 cfg = setup_cfg(args) 117 # 可以直接在代码中设置cfg中设置模型路径 118 # cfg[\u0026#34;MODEL\u0026#34;][\u0026#34;WEIGHTS\u0026#34;] = \u0026#39;./configs/Market1501/bagtricks_R50.yml\u0026#39; 119 test_loader, num_query = build_reid_test_loader(cfg, dataset_name=args.dataset_name) # 创建测试数据集 120 demo = FeatureExtractionDemo(cfg, parallel=args.parallel) # 加载特征提取器，也就是加载模型 121 122 logger.info(\u0026#34;Start extracting image features\u0026#34;) 123 feats = [] # 图像特征，用于保存每个行人的图像特征 124 pids = [] # 行人id，用于保存每个行人的id 125 camids = [] # 拍摄的摄像头，行人出现的摄像头id 126 # 逐张保存读入行人图像，并保存相关信息 127 for (feat, pid, camid) in tqdm.tqdm(demo.run_on_loader(test_loader), total=len(test_loader)): 128 feats.append(feat) 129 pids.extend(pid) 130 camids.extend(camid) 131 132 feats = torch.cat(feats, dim=0) # 将feats转换为tensor的二维向量，向量维度为[图像数，特征维度] 133 # 这里把query和gallery数据放在一起了，需要切分query和gallery的数据 134 q_feat = feats[:num_query] 135 g_feat = feats[num_query:] 136 q_pids = np.asarray(pids[:num_query]) 137 g_pids = np.asarray(pids[num_query:]) 138 q_camids = np.asarray(camids[:num_query]) 139 g_camids = np.asarray(camids[num_query:]) 140 141 # compute cosine distance 计算余弦距离 142 q_feat = F.normalize(q_feat, p=2, dim=1) 143 g_feat = F.normalize(g_feat, p=2, dim=1) 144 distmat = 1 - torch.mm(q_feat, g_feat.t()) # 这里distmat表示两张图像的距离，越小越接近 145 distmat = distmat.numpy() 146 147 # 计算各种评价指标 cmc[0]就是top1精度，应该是93%左右，这里精度会有波动 148 logger.info(\u0026#34;Computing APs for all query images ...\u0026#34;) 149 cmc, all_ap, all_inp = evaluate_rank(distmat, q_pids, g_pids, q_camids, g_camids) 150 logger.info(\u0026#34;Finish computing APs for all query images!\u0026#34;) 151 152 visualizer = Visualizer(test_loader.dataset) # 创建Visualizer类 153 visualizer.get_model_output(all_ap, distmat, q_pids, g_pids, q_camids, g_camids) # 保存结果 154 155 logger.info(\u0026#34;Start saving ROC curve ...\u0026#34;) # 保存ROC曲线 156 fpr, tpr, pos, neg = visualizer.vis_roc_curve(args.output) 157 visualizer.save_roc_info(args.output, fpr, tpr, pos, neg) 158 logger.info(\u0026#34;Finish saving ROC curve!\u0026#34;) 159 160 logger.info(\u0026#34;Saving rank list result ...\u0026#34;) # 保存部分查询图像的关联结果，按照顺序排列 161 query_indices = visualizer.vis_rank_list(args.output, args.vis_label, args.num_vis, 162 args.rank_sort, args.label_sort, args.max_rank) 163 logger.info(\u0026#34;Finish saving rank list results!\u0026#34;) train_net.py 这段代码调用config文件，训练或者测试模型。训练模型设置args.eval_only = False，反之为测试模型。测试模型结果如下图所示。代码封装的很不错，把该有的测试指标都贴上去了。\n另外这是封装过多的代码，如果想知道清晰的训练代码查看fast-reid/tools/plain_train_net.py，这个文件提供了详细没有封装过多的训练代码。\n1#!/usr/bin/env python 2# encoding: utf-8 3\u0026#34;\u0026#34;\u0026#34; 4@author: sherlock 5@contact: sherlockliao01@gmail.com 6模型训练与测试封装版代码 7\u0026#34;\u0026#34;\u0026#34; 8 9import sys 10 11sys.path.append(\u0026#39;.\u0026#39;) 12 13from fastreid.config import get_cfg 14from fastreid.engine import DefaultTrainer, default_argument_parser, default_setup, launch 15from fastreid.utils.checkpoint import Checkpointer 16 17 18# 读取配置文件 19def setup(args): 20 \u0026#34;\u0026#34;\u0026#34; 21 Create configs and perform basic setups. 22 \u0026#34;\u0026#34;\u0026#34; 23 cfg = get_cfg() 24 cfg.merge_from_file(args.config_file) 25 cfg.merge_from_list(args.opts) 26 cfg.freeze() 27 default_setup(cfg, args) 28 return cfg 29 30 31def main(args): 32 cfg = setup(args) 33 # 模型测试 34 if args.eval_only: 35 cfg.defrost() 36 cfg.MODEL.BACKBONE.PRETRAIN = False 37 model = DefaultTrainer.build_model(cfg) 38 # 加载预训练模型 39 Checkpointer(model).load(cfg.MODEL.WEIGHTS) # load trained model 40 41 res = DefaultTrainer.test(cfg, model) 42 return res 43 # 模型训练 44 trainer = DefaultTrainer(cfg) 45 46 trainer.resume_or_load(resume=args.resume) 47 return trainer.train() 48 49 50if __name__ == \u0026#34;__main__\u0026#34;: 51 args = default_argument_parser().parse_args() 52 # 调试使用，使用的时候删除下面代码 53 # --- 54 args.config_file = \u0026#34;./configs/Market1501/bagtricks_R50.yml\u0026#34; # config路径 55 args.eval_only = True # 是否测试模型,False表示训练模型，True表示测试模型 56 # --- 57 58 print(\u0026#34;Command Line Args:\u0026#34;, args) 59 launch( 60 main, 61 args.num_gpus, 62 num_machines=args.num_machines, 63 machine_rank=args.machine_rank, 64 dist_url=args.dist_url, 65 args=(args,), 66 ) ","date":1709036154,"headings":[{"anchor":"demopy","title":"demo.py"},{"anchor":"train_netpy","title":"train_net.py"},{"anchor":"visualize_resultpy","title":"visualize_result.py"}],"kind":"page","lang":"zh-hans","summary":"","title":"Fastreid使用","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/fastreid%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/fastreid%E4%BD%BF%E7%94%A8/","year":"2024"},{"content":"数据集介绍 在fast-reid/datasets/目录提供了不同数据集的信息。可以自行下载。这里介绍其中最常用的Market-1501数据集。\nMarket-1501是用于行人重识别的大规模公共基准数据集。它包含由6个不同的摄像机捕获的1501个行人，以及32,668个行人图像边界框。数据集分为两部分：其中750人的图像用于训练，其余751人的图像用于测试。在官方测试协议中，选择3,368个查询图像作为查询集query，以在包含19,732张参考图像的gallery图像集中找到正确匹配。\n1Market-1501 2　├── bounding_box_test (750人的19732张图像用于测试) 3　├── -1_c1s1_000401_03.jpg 4　├── 0071_c6s2_072893_01.jpg 5　├── 0071_c6s2_072918_02.jpg 6　├── bounding_box_train (751人的12936张图像用于训练) 7　├── 0002_c1s1_000451_03.jpg 8　├── 0002_c1s1_000801_01.jpg 9　├── 0430_c5s1_109673_01.jpg 10　├── gt_bbox (25259张图像手动标注） 11　├── 0001_c1s1_001051_00.jpg 12　├── 0001_c1s2_041171_00.jpg 13　├── 0933_c6s2_110943_00.jpg 14　├── gt_query (matlab格式，用于判断一个query的哪些图片是好的匹配和不好的匹配) 15　├── 0001_c1s1_001051_00_good.mat 16　├── 0794_c2s2_086182_00_good.mat 17　├── 0001_c1s1_001051_00_junk.mat 18　├── query (750人的3368张图像用于查询) 19　├── 0001_c1s1_001051_00.jpg 20　├── 0001_c2s1_000301_00.jpg 21　├── 0001_c3s1_000551_00.jpg 22　└── readme.txt 图像命名规则\n以0071_c6s2_072893_01.jpg 为例\n0071 表示当前行人的编号，编号范围为-1到1501，-1表示不包含在这1501人中的行人，0000表示背景； c6 表示当前摄像机的编号，共有6个摄像机； s2 表示当前摄像机的第几个片段，每个摄像机都有多个录像片段； 072893 表示c6s2的第072893帧图片，视频帧率为25fps； 01 表示0071_c6s2_072893这一帧上的第1个检测框，00表示手工标注框。 数据集使用\n通常都是用度量学习的方式来使用Market-1501数据集。一般使用bounding_box_train，bounding_box_tes和query数据集中的图像进行模型训练和测试。\nbounding_box_train：用来训练模型，使模型能够学习该集合的图像特征。 bounding_box_test：用来提供度量学习中的gallery数据。 query：与gallery中的数据进行距离匹配以测试模型的好坏。 预训练模型 在fast-reid/MODEL_ZOO.md文件下提供了不同数据集下不同方法得到的sota模型。以最简单的Bot在Market1501中训练ResNet50模型为例。点击Method下的链接会转到模型配置文件路径，点击download会下载对应的预训练模型（大概300MB）。\n对于对应的config路径位于fast-reid/configs目录下，所用到的文件有两个：\n1configs 2　├── Market1501 3　├── bagtricks_R50.yml 4　├── Base-bagtricks.yml 代码运行时会把Base-bagtricks.yml和bagtricks_R50.yml合并在一起。模型训练测试推理就是靠这两个文件，当然你可以手动把这两个文件并在一起。具体文件修改可以后续看看不同的config文件和官方代码，自己摸索摸索就可以入手。\nBase-bagtricks.yml\n1MODEL: 2 META_ARCHITECTURE: Baseline 3 4 BACKBONE: # 模型骨干结构 5 NAME: build_resnet_backbone 6 NORM: BN 7 DEPTH: 50x 8 LAST_STRIDE: 1 9 FEAT_DIM: 2048 10 WITH_IBN: False 11 PRETRAIN: True 12 13 HEADS: # 模型头 14 NAME: EmbeddingHead 15 NORM: BN 16 WITH_BNNECK: True 17 POOL_LAYER: GlobalAvgPool 18 NECK_FEAT: before 19 CLS_LAYER: Linear 20 21 LOSSES: # 训练loss 22 NAME: (\u0026#34;CrossEntropyLoss\u0026#34;, \u0026#34;TripletLoss\u0026#34;,) 23 24 CE: 25 EPSILON: 0.1 26 SCALE: 1. 27 28 TRI: 29 MARGIN: 0.3 30 HARD_MINING: True 31 NORM_FEAT: False 32 SCALE: 1. 33 34INPUT: # 模型输入图像处理方式 35 SIZE_TRAIN: [ 256, 128 ] 36 SIZE_TEST: [ 256, 128 ] 37 38 REA: 39 ENABLED: True 40 PROB: 0.5 41 42 FLIP: 43 ENABLED: True 44 45 PADDING: 46 ENABLED: True 47 48DATALOADER: # 模型读取图像方式 49 SAMPLER_TRAIN: NaiveIdentitySampler 50 NUM_INSTANCE: 4 51 NUM_WORKERS: 8 52 53SOLVER: # 模型训练配置文件 54 AMP: 55 ENABLED: True 56 OPT: Adam 57 MAX_EPOCH: 120 58 BASE_LR: 0.00035 59 WEIGHT_DECAY: 0.0005 60 WEIGHT_DECAY_NORM: 0.0005 61 IMS_PER_BATCH: 64 62 63 SCHED: MultiStepLR 64 STEPS: [ 40, 90 ] 65 GAMMA: 0.1 66 67 WARMUP_FACTOR: 0.1 68 WARMUP_ITERS: 2000 69 70 CHECKPOINT_PERIOD: 30 71 72TEST: # 模型测试配置 73 EVAL_PERIOD: 30 74 IMS_PER_BATCH: 128 75 76CUDNN_BENCHMARK: True 77MODEL: 78 META_ARCHITECTURE: Baseline 79 80 BACKBONE: # 模型骨干结构 81 NAME: build_resnet_backbone 82 NORM: BN 83 DEPTH: 50x 84 LAST_STRIDE: 1 85 FEAT_DIM: 2048 86 WITH_IBN: False 87 PRETRAIN: True 88 89 HEADS: # 模型头 90 NAME: EmbeddingHead 91 NORM: BN 92 WITH_BNNECK: True 93 POOL_LAYER: GlobalAvgPool 94 NECK_FEAT: before 95 CLS_LAYER: Linear 96 97 LOSSES: # 训练loss 98 NAME: (\u0026#34;CrossEntropyLoss\u0026#34;, \u0026#34;TripletLoss\u0026#34;,) 99 100 CE: 101 EPSILON: 0.1 102 SCALE: 1. 103 104 TRI: 105 MARGIN: 0.3 106 HARD_MINING: True 107 NORM_FEAT: False 108 SCALE: 1. 109 110INPUT: # 模型输入图像处理方式 111 SIZE_TRAIN: [ 256, 128 ] 112 SIZE_TEST: [ 256, 128 ] 113 114 REA: 115 ENABLED: True 116 PROB: 0.5 117 118 FLIP: 119 ENABLED: True 120 121 PADDING: 122 ENABLED: True 123 124DATALOADER: # 模型读取图像方式 125 SAMPLER_TRAIN: NaiveIdentitySampler 126 NUM_INSTANCE: 4 127 NUM_WORKERS: 8 128 129SOLVER: # 模型训练配置文件 130 AMP: 131 ENABLED: True 132 OPT: Adam 133 MAX_EPOCH: 120 134 BASE_LR: 0.00035 135 WEIGHT_DECAY: 0.0005 136 WEIGHT_DECAY_NORM: 0.0005 137 IMS_PER_BATCH: 64 138 139 SCHED: MultiStepLR 140 STEPS: [ 40, 90 ] 141 GAMMA: 0.1 142 143 WARMUP_FACTOR: 0.1 144 WARMUP_ITERS: 2000 145 146 CHECKPOINT_PERIOD: 30 147 148TEST: # 模型测试配置 149 EVAL_PERIOD: 30 150 IMS_PER_BATCH: 128 151 152CUDNN_BENCHMARK: True bagtricks_R50.yml\n注意我加了预训练模型路径。\n1_BASE_: ../Base-bagtricks.yml # 链接父目录下的Base-bagtricks.yml 2 3DATASETS: 4 NAMES: (\u0026#34;Market1501\u0026#34;,) # 数据集路径 5 TESTS: (\u0026#34;Market1501\u0026#34;,) # 测试集路径 6 7OUTPUT_DIR: logs/market1501/bagtricks_R50 # 输出结果路径 8 9MODEL: 10 WEIGHTS: model/market_bot_R50.pth # 预训练模型路径，这句是我自己加的 ","date":1709035927,"headings":[{"anchor":"数据集介绍","title":"数据集介绍"},{"anchor":"预训练模型","title":"预训练模型"}],"kind":"page","lang":"zh-hans","summary":"","title":"数据集和预训练模型","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/fastreid%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/","year":"2024"},{"content":" fastreid项目整合了一系列模型，模型的更改依赖于不同的项目配置文件； 同时为方便更改，配置是分级继承的关系。 configs.yaml配置文件详细写了模型的数据处理，模型框架，训练方法等这些超参，训练调参都可以通过此修改，以./configs/Market1501目录下的AGW_R50-ibn.yml为例（下文的介绍中均以此为基础），其继承了Base-AGW.yml的配置，而Base-AGW.yml又继承了Base-bagtricks.yml：\n代码如下（示例）：\n1_BASE_: \u0026#34;../Base-AGW.yml\u0026#34; # AGW_R50-ibn的上一级配置文件 2 3MODEL: 4 BACKBONE: 5 WITH_IBN: True 模型是否使用IBN module 6 7DATASETS: 8 NAMES: (\u0026#34;Market1501\u0026#34;,) 数据集 9 TESTS: (\u0026#34;Market1501\u0026#34;,) 10 11OUTPUT_DIR: \u0026#34;logs/market1501/agw_R50-ibn\u0026#34; # 日志输出目录 接下来看AGW_R50-ibn的上一级配置文件Base-AGW.yml（示例）：\n1_BASE_: \u0026#34;Base-bagtricks.yml\u0026#34; # Base-AGW的上一级配置文件 2 3MODEL: 4 BACKBONE: 5 WITH_NL: True # 模型是否使用No_local module 6 7 HEADS: 8 POOL_LAYER: \u0026#34;gempool\u0026#34; # HEADS POOL_LAYER 9 10 LOSSES: 11 NAME: (\u0026#34;CrossEntropyLoss\u0026#34;, \u0026#34;TripletLoss\u0026#34;) # 使用loss 12 CE: 13 EPSILON: 0.1 # CrossEntropyLoss 超参 14 SCALE: 1.0 15 16 TRI: 17 MARGIN: 0.0 # TripletLoss 超参 18 HARD_MINING: False 19 SCALE: 1.0 接下来看Base-AGW的上一级配置文件Base-bagtricks.yml（示例）：\n1MODEL: 2 META_ARCHITECTURE: \u0026#34;Baseline\u0026#34; 3 4 BACKBONE: 5 NAME: \u0026#34;build_resnet_backbone\u0026#34; 6 NORM: \u0026#34;BN\u0026#34; **# 模型NORM 如果是多卡需设置为syncBN 多卡同步BN** 7 DEPTH: \u0026#34;50x\u0026#34; 8 LAST_STRIDE: 1 9 FEAT_DIM: 2048 # 输出特征维度 10 WITH_IBN: True 11 PRETRAIN: True 12 PRETRAIN_PATH: \u0026#34;/media/zengwb/PC/baseline/ReID/resnet50_ibn_a-d9d0bb7b.pth\u0026#34; 13 14 HEADS: 15 NAME: \u0026#34;EmbeddingHead\u0026#34; 16 NORM: \u0026#34;BN\u0026#34; **# 模型NORM 如果是多卡需设置为syncBN 多卡同步BN** 17 WITH_BNNECK: True 18 POOL_LAYER: \u0026#34;avgpool\u0026#34; 19 NECK_FEAT: \u0026#34;before\u0026#34; 20 CLS_LAYER: \u0026#34;linear\u0026#34; 21 22 LOSSES: 23 NAME: (\u0026#34;CrossEntropyLoss\u0026#34;, \u0026#34;TripletLoss\u0026#34;,) 24 25 CE: 26 EPSILON: 0.1 27 SCALE: 1. 28 29 TRI: 30 MARGIN: 0.3 31 HARD_MINING: True 32 NORM_FEAT: False 33 SCALE: 1. 34 35INPUT: 36 SIZE_TRAIN: [256, 128] 37 SIZE_TEST: [256, 128] 38 REA: 39 ENABLED: True 40 PROB: 0.5 41 MEAN: [123.675, 116.28, 103.53] 42 DO_PAD: True 43 44DATALOADER: 45 PK_SAMPLER: True 46 NAIVE_WAY: True 47 NUM_INSTANCE: 4 48 NUM_WORKERS: 8 49 50SOLVER: 51 OPT: \u0026#34;Adam\u0026#34; 52 MAX_ITER: 120 53 BASE_LR: 0.00035 54 BIAS_LR_FACTOR: 2. 55 WEIGHT_DECAY: 0.0005 56 WEIGHT_DECAY_BIAS: 0.0005 57 IMS_PER_BATCH: 64 # 设置batch size 58 59 SCHED: \u0026#34;WarmupMultiStepLR\u0026#34; 60 STEPS: [40, 90] 61 GAMMA: 0.1 62 63 WARMUP_FACTOR: 0.01 64 WARMUP_ITERS: 10 65 66 CHECKPOINT_PERIOD: 60 # epoxh 67 68TEST: 69 EVAL_PERIOD: 30 70 IMS_PER_BATCH: 128 71 72CUDNN_BENCHMARK: True 可以看到整个配置文件为三个configs文件Base-bagtricks，Base-AGW，AGW_R50-ibn组成，一级一级细化，结合./fastreid/config/default.py 可以很容易理解整个项目的配置文件结构。\n可以看到整个配置文件为三个configs文件Base-bagtricks，Base-AGW，AGW_R50-ibn组成，一级一级细化，结合./fastreid/config/default.py 可以很容易理解整个项目的配置文件结构。\n","date":1709035724,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"配置文件解读","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/fastreid%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%A7%A3%E8%AF%BB/","year":"2024"},{"content":"总结构 configs: 存储各级配置文件 datasets 存储各种数据集 Domo 存储模型的调用文件 Docker docker安装文件 Docs 项目文档 Fastreid fastreid源代码 Projects 基于fastreid的其他项目 Tests 测试文件 Tools 训练和部署代码 Something else ","date":1709035080,"headings":[{"anchor":"configs","title":"configs:"},{"anchor":"datasets","title":"datasets"},{"anchor":"docker","title":"Docker"},{"anchor":"docs","title":"Docs"},{"anchor":"domo","title":"Domo"},{"anchor":"fastreid","title":"Fastreid"},{"anchor":"projects","title":"Projects"},{"anchor":"tests","title":"Tests"},{"anchor":"tools","title":"Tools"},{"anchor":"总结构","title":"总结构"}],"kind":"page","lang":"zh-hans","summary":"","title":"项目结构","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/fastreid%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84/","year":"2024"},{"content":" 本文主要介绍fast-reid的基础使用，度量学习和ReID最新技术建议学习相关论文。本文的项目运行环境为Ubuntu18.04.5 LTS，Python3.8，Pytorch1.8.1+cu111。 对于fast-reid首先去官方仓库下载对应的代码到本地，仓库地址：https://github.com/JDAI-CV/fast-reid 。 然后安装对应的Python库。具体代码如下： git clone https://github.com/JDAI-CV/fast-reid cd fast-reid python3 -m pip install -r docs/requirements.txt 此外为了加速索引速度，进入fast-reid/fastreid/evaluation/rank_cylib/目录，输入make all编译文件以加速查询。如果发现编译所使用的python版本不是系统默认版本，比如我用的是python3.8，需要修改Makefile文件。如下所示：\n1all: 2 # python3 setup.py build_ext --inplace 3 python3.8 setup.py build_ext --inplace 4 rm -rf build 5clean: 6 rm -rf build 7 rm -f rank_cy.c *.so fast-reid开源项目结构如下图所示： 其中最主要的是configs文件夹，fastreid文件夹，projects文件夹，tools文件夹和MODEL_ZOO.md。configs文件夹提供了不同模型的结构和训练实现脚本。fastreid文件夹提供了fast-reid的源代码实现。projects提供了一些基于fast-reid的项目代码，里面所有的项目代码非常有用，建议都跑跑。tools文件夹提供了模型训练和部署代码。MODEL_ZOO.md提供了不同数据集下的预训练模型，可以down下来跑一跑。\n","date":1709034466,"headings":[{"anchor":"fast-reid开源项目结构如下图所示","title":"fast-reid开源项目结构如下图所示："}],"kind":"page","lang":"zh-hans","summary":"","title":"Fast-Reid环境配置及入门","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/fastreid%E9%A1%B9%E7%9B%AE%E7%AE%80%E4%BB%8B/fast-reid%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%85%A5%E9%97%A8/","year":"2024"},{"content":"ReID，全拼为Re-identification，目的是利用各种智能算法在图像数据库中找到与要搜索的目标相似的对象。ReID本质上是做图像的检索。\nfast-reid是一个强悍的目标重识别Reid开源库，由京东开源管理。本文主要是介绍fast-reid的使用及相关代码介绍，随着技术的发展，对于cv从业人员有必要了解不同智能算法技术的应用。而且ReID是相对下游的任务，了解ReID的相关技术应用能学到很多东西。\n以行人重识别Person re-identification为例，行人重识别主要目的是针对出现在监控摄像头内的某个目标行人，准确快速地从监控网络其他摄像头内的大量行人中将这个目标行人标识出来。如下图所示（图片来自网络）。\n工程上，最简单的行人重识别的技术流程如下所示。\n行人检测（目标识别） --\u0026gt; 特征提取 --\u0026gt; 行人跟踪（目标跟踪）--\u0026gt; 跨镜头行人跟踪 --\u0026gt; 向量存储与检索 简单的一个技术解决方案为：\n行人检测：通过Yolov5这类目标模型提取当前帧的行人图像。 特征提取：基于特征提取模型，如通过faster-reid基于度量学习训练得到的模型提取行人区域图片的特征向量。 目标跟踪：结合行人区域特征，通过deepsort进行行人跟踪 跨镜头行人跟踪：基于深度学习的全局特征和数据关联实现跨镜头行人目标跟踪。 向量存储与检索：对于给定的行人查询向量，与行人特征库中所有的待查询向量进行向量检索，即计算特征向量间的相似度。通常我们可以通过faiss处理这部分的操作。 在以上步骤中，特征提取是最关键的一环，它的作用是将输入的行人图片转化为固定维度的特征向量，以用于后续的目标跟踪和向量检索。好的特征需要具备良好的相似度保持性，即在特征空间中，相似度高的图片之间的向量距离比较近，而相似度低的图片对的向量距离比较远。通常用于训练这种模型的方式叫做度量学习，度量学习很简单可以自己查查。\nfast-reid是一个面向学术界和工业界的ReID工具箱，是京东的开源项目之一。如果想要了解更多关于fast-reid的信息，可以直接去看作者的论文FastReID: A Pytorch Toolbox for Real-world Person Re-identification。fast-reid基于python和pytorch实现各种模型，同时提供一些脚本将pytorch训练的模型转到caffe和TensorRT上。所以非常推荐使用fast-reid进行学习。\nfast-reid是一个很不错的ReID工具箱，提供了丰富的代码接口，但是代码有许多小bug，使用的时候要多注意。本文只介绍了fast-reid的基础使用，没有进一步的介绍fast-red的工程项目，以及相关的理论知识。关于fast-reid的使用，最好多单步调试进入源代码，可以学到很多的东西。fast-reid项目中提供的工程示例代码也是值得一看的。\n","date":1709033906,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"背景知识介绍","url":"/%E9%87%8D%E8%AF%86%E5%88%AB/fastreid%E9%A1%B9%E7%9B%AE%E7%AE%80%E4%BB%8B/%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86%E4%BB%8B%E7%BB%8D/","year":"2024"},{"content":" ","date":1709030788,"headings":[],"kind":"page","lang":"zh-hans","summary":"","title":"视频简介","url":"/%E8%99%9A%E6%8B%9F%E8%AF%95%E8%A1%A3/%E8%A7%86%E9%A2%91%E7%AE%80%E4%BB%8B/","year":"2024"},{"content":" 1 引言 随着元宇宙概念的火爆以及虚拟数字技术的大迸发，在人们购买力逐步上升的今天，世界看到了“虚拟试衣”技术未来巨大的发展空间。根据 CB Insights 的预测，全球虚拟试衣间的市场规模将从 2020 年的 34 亿美元，增长至 2030 年的 193 亿美元。\n虚拟试衣技术在不断地发展中和突破中，在电子商业普及和移动端用户迅速增长的阶段，如果虚拟试衣系统能提高其真实性以及对不同衣物的贴合度，将在网络时代获得巨大的市场。基于赛题方要求，我们团队开发了符合要求的虚拟试衣系统。下文中，我们将会从项目概述，系统设计，模型构建，工程化实现，项目部署，测试效果等多个维度对于相关成果进行阐述。\n项目概述：介绍了当前虚拟试衣技术出现的背景与市场需求，强调了我们的虚拟试衣系统的主要功能和特点，给出了赛题方要求的技术指标。\n系统设计：介绍了我们的系统架构和技术选择。\n模型构建：详细介绍了我们使用的算法和模型，以及如何进行训练和调优。\n工程化实现：详细介绍了如何将深度学习算法转化为实际可用的系统，并通过推理引擎将PyTorch深度学习模型进行工程化。\n项目部署：详细介绍了我们们如何将系统部署到实际的生产环境中（web服务器端部署和本地化可执行程序exe部署）。\n测试效果：展示了我们模型的生成效果图，与其他SOTA模型的对比，同时分析了我们模型的大小和推导速度\n2 项目概述 2.1 项目背景 随着互联网和移动互联网的飞速发展，电子商务已成为消费者购买商品的主要方式之一。然而，网络购物的一个主要难题是消费者无法亲身试穿商品，往往需要通过图片和文字描述来评估商品的适合度。这会导致消费者难以确定最终购买的商品是否符合自己的需求，从而增加了商品退换货的风险和成本，也降低了购物的满意度。\n虚拟试衣技术的出现，为解决这一难题提供了一种新的解决方案。虚拟试衣技术可以通过图像生成和人体建模技术，利用计算机生成的模型将服装或配饰实时渲染到用户的图像或视频中，让用户可以在不离开家的情况下进行试穿。这不仅提高了用户体验，还减少了用户试穿时的不便和时间成本，为消费者带来更加便利的购物体验。同时，虚拟试衣技术还可以为品牌商和零售商提供一种更直观的方式来展示其商品，增强品牌的吸引力和销售力。虚拟试衣技术已经成为了时尚行业数字化的重要一步，它将为时尚品牌和电商平台带来更多的机会和创新可能性，也将为用户提供更好的购物体验和更加便利的服务。随着技术的不断进步和应用场景的不断拓展，相信虚拟试衣技术将在未来继续发挥着重要的作用，并成为时尚行业数字化发展的重要驱动力。\n经过团队的实际调研，可以将虚拟试衣应用出现的原因归结如下：\n顾客需求的提升：随着消费者对服装试穿的体验要求不断提升，虚拟试衣技术能够满足消费者更高的购物体验需求。此外，随着在线购物市场的迅速发展，虚拟试衣技术的应用越来越广泛。\n技术突破的加速：随着深度学习、计算机视觉的不断发展，虚拟试衣技术在真实性、贴合度、逼真度等方面得到了极大提升，也推动了虚拟试衣技术的广泛应用。\n环保和可持续性：虚拟试衣技术可以避免过多的实体试衣，减少了物流和生产环节的能耗和浪费，符合现代社会对于环保和可持续发展的要求。\n降低成本和提高效率：虚拟试衣技术可以降低实体试衣的成本，同时提高试衣效率，为服装企业和消费者带来了实际效益和收益。\n同时，我们团队还对虚拟试衣项目市场规模进行了调研。根据多个市场研究报告显示，预计到2024年，全球虚拟试衣市场规模将超过100亿美元。随着虚拟试衣技术的不断提升和推广，虚拟试衣方案的普及将越来越广泛，吸引不断增长的消费者需求。特别是在线购物日益成为主流趋势，虚拟试衣的需求将会不断增加。下图展示了近几年虚拟试衣市场规模的统计数据：\n图 2-1 近年全球虚拟试衣市场规模\n2.2 项目目标 虚拟试衣项目的目标是为消费者提供一种更加方便和快捷的购物体验，使其能够在不实际去实体店试穿的情况下，轻松地预览和比较不同的服装款式，颜色和尺寸。虚拟试衣旨在改善在线购物的用户体验，同时减少物流和退货的成本，促进线上消费的增长。此外，虚拟试衣也有助于品牌提高消费者对其产品的信任度和忠诚度，改善品牌形象和增加销售量。\n为了实现以上目标，团队根据万兴科技关于选题和项目说明对项目需求和系统的规格说明进行了详细的分析，我们认为该项目应该满足以下几点功能：\n上传用户照片：系统应该允许用户上传自己的照片以进行试衣。\n选择服装：系统中应该有可供用户选择的多种服装选项。\n尺寸适配：系统应该根据用户的身形和尺寸来对所选的服装进行适配，确保合适的紧度和长度。\n预览和变更：用户应该能够根据自己的需求预览和变更服装。\n此外，考虑到项目在现实中的实际应用，除了基本功能外，还应满足以下的用户需求：\n可视化体验：用户能够在虚拟试衣系统中看到自己穿着不同款式、不同颜色的衣服，从而更好地理解服装的搭配和效果。\n真实感：虚拟试衣系统应具有尽可能真实的材质、光影等元素，从而给用户带来真实的试衣体验。\n多样性：系统应提供丰富多样的衣服选择，包括各种品牌、风格、颜色等，以满足不同用户的需求。此外，还应提供个性化定制服装的功能。\n操作简单：虚拟试衣系统应该操作简单、易懂，不需要太多的学习成本，以便吸引更多用户使用。\n交互性：系统应该便于用户进行交互，例如可以在系统中分享图片、保存购物清单等等。\n安全性：虚拟试衣系统应该提供足够的保密措施，以保护用户的隐私。\n精确性：虚拟试衣系统应该提供准确的尺寸和尺寸建议，以帮助用户选择合适的衣服。\n灵活性：虚拟试衣系统应该提供灵活的体验方式，例如可以在家中进行试衣、在商店中进行试衣等等，以满足不同用户的需求。\n2.3 项目价值 虚拟试衣项目是近年来发展迅速的一项技术，它将人工智能、计算机视觉和虚拟现实等多种技术有机结合，在传统试衣的基础上实现了更加快速、准确和便捷的试衣体验。下文将从市场，社会，国家三个层面对项目价值进行具体分析：\n市场层面：\n虚拟试衣技术为时尚、服装、珠宝等行业提供了一种全新的销售方式，可以为企业吸引更广泛、更具有世界性的客户群体，从而提高企业的市场份额和竞争力。通过应用虚拟试衣技术，消费者可以在不离开家的情况下进行试衣。这意味着公司的客户群可能会变得更广泛、更有世界性。虚拟试衣技术有助于增强品牌形象，提高客户对品牌的信赖度和忠诚度。\n社会层面：\n虚拟试衣技术有助于推动时尚行业的数字化转型，减少人们购买衣物时的误解和失望，让购物变得更加智能化、更加精准化。同时，虚拟试衣技术可以减少生产与销售过程中的资源浪费，从而有助于推动可持续发展和环境保护。\n国家层面： 虚拟试衣技术可以为国家的制造业、资讯科技方向带来经济利益。这种技术有帮助推动产业升级，从而增加了经济增长的可能性，并且在工业4.0时代，虚拟试衣技术有助于技术创新，促进了数字经济的发展。同时，虚拟试衣技术和智能制造技术结合，将产生更广泛的商业机遇，缓解人力资源短缺问题，更好地推进制造业转型升级。\n2.4 作品简介 团队使用开源数据集VITON及在此基础上进行预处理得到的VITON_plus数据集，建立虚拟试衣算法模型，并完成模型训练、优化、工程化、部署等工作，最终产出一个本地可执行程序以及部署在服务器支持试用的Web界面(可通过此链接访问我们的网页：无忧工作室)，同时测试了模型性能以及对模型的试穿效果进行了评估。值得关注的是，基于赛题方的要求，我们的模型是端到端的，只需要将人的图像和衣服的图像作为输入，而不需要人体解析图或人体姿态图等任何额外的辅助信息就可以完成虚拟试衣，具有轻量化且快速的特点，且生成效果良好。\n以下是Web页面展示图：\n图 2-2 项目前端首页面展示\n图 2-3 项目前端试衣页面展示\n以下是本地化可执行程序的展示图（本地化可执行程序可以在web网页的软件下载获取）：\n图 2-4 项目本地化可执行程序展示\n模型大小（MB） 计算量（FLOPs） 参数量（MB） FID 34.75 2.02*10^9 18.22 8.75 表 2-1 赛题方所需模型数据（模型精度格式为fp16）\n此外我们的在项目开发的过程中尤其注重文档工作，构建了语雀知识库来进行开发过程的跟踪，通过知识库协作来进行团队合作与任务分配，完成了需求分析，算法调研，工程化探索，web开发的代码文档等工作。\n图 2-5 团队语雀知识库截图展示\n2.5 创新点与优势 模型主要是基于PF-AFN（Parser Free Appearence Flow Network）与SDAFN（Single Deformable Attention Flows Network）实现。\n对于PF-AFN，我们借鉴了其中知识蒸馏的思想\n对于SDAFN，我们使用SDAFN作为我们的教师模型 其中，对于PF-AFN，我们借鉴了其中知识蒸馏的思想，将教师模型（Teacher Model）的输出作为一种指导信息（tutorial），让学生模型自行选择哪部分应该使用。将最初的人的图像作为真值，而将教师输出作为学生的输入，而非用教师的结果约束学生，实现教师指导学生（Teacher tutor Student）的知识蒸馏架构。教师模型使用到了人体掩码和人体姿态信息，结果会更准确，为了把这些信息传授给学生，教师+学生串联起来，实现了端到端的自监督。这样就将一个大型、复杂的神经网络模型（教师模型）中的知识迁移到一个小型、简单的神经网络模型（学生模型），减小了模型参数，同时实现了学生模型的输入只需要人物和衣服的图片，而不需要依赖任何人体解析图或者人体姿态图等任何辅助信息，且学生模型的效果不受限于教师模型；\n对于SDAFN，我们使用SDAFN作为我们的教师模型。同时我们利用其One-Stage框架的创新性构想，借鉴了其外观估计流Appearance Flow的思想（DAFlow），使用了可形变transformer（deformable transformer）做为外观估计流的主要架构，同时改进了深层特征提取器和输入输出模块，提出了SDAFN_plus作为我们学生模型的架构。值得一提的是，DAFlow是利用人和服装图像的自形变和交叉形变注意力流获得输出结果，以端到端的方式达到逼真的拟合结果。\n模型创新点如下：\n我们的模型为端到端单任务模型，避免了多任务模型计算开销大的缺点，加快了推导速度。\n我们的模型不需要依赖人体解析图，人体姿态估计图等任何辅助信息，只需要将人的图片和衣服的图片作为输入。\n（3）使用知识蒸馏的方法，我们的模型在保持高质量虚拟试衣图像生成的同时，减少了模型计算量和参数量，实现了模型轻量化。\n（4）团队通过数据增强的方式，扩充了模型训练的数据集，提高了模型的鲁棒性。\n（5）模型性能优异，在FID等关键指标中取得领先得分，并在衣物细节保留、人物身体拟合和边缘识别等传统虚拟试衣难点取得较好表现。\n3 系统设计 项目主要分为三部分，分别是深度虚拟试衣模型的构建与训练，pytorch深度学习模型的工程化，模型的生产部署。下面是我们的系统整体架构图。\n图 3-1 系统总体架构图\n项目系统架构分析：\n深度虚拟试衣模型的构建：使用pytorch作为我们深度虚拟试衣模型的开发框架，使用开源的SDAFN模型（Single Deformable Attention Flows Network）作为我们的教师模型，重新设计构建SDAFN_plus作为我们的学生模型。\n训练教师模型：使用开源的VITON数据集作为我们的主要训练数据，对VITON数据集进行预处理得到人像掩码图和人体姿势图，再加上试穿衣服图片作为教师模型的输入。\n训练学生模型：将教师模型的输出作为我们学生模型的输入，将最初的人的图像作为真值，这样就将一个无监督的模型的训练巧妙地转换成了一个有监督的训练，且学生模型的生成效果不会受限于教师模型。\n学生模型训练完成后，将学生模型的权重保存为.pth。\n将.pth格式的模型转换成onnx格式。\n使用onnxruntime推理引擎进行推导，实现推导程序。\nWeb前后端部署：使用Flask作为后端框架，将Python推导程序部署到Web应用程序中。前端使用Vue框架实现用户交互和页面展示。后端使用Gunicorn容器，前端使用Nginx容器来提高Web应用程序的性能和稳定性。\n本地化可执行程序exe部署：使用Thinker这个Python的可视化库，将Python推导程序封装为本地可执行程序。用户可以通过双击可执行文件来打开程序，不需要安装Python环境和其他依赖库。\n4 模型架构 4.1 相关工作 我们团队在项目开展初期对虚拟试衣技术进行了充分的调研，阅读了大量的技术综述与参考文献，对虚拟试衣技术的发展路径有了详细的了解，并对当前效果出众或者在虚拟试衣技术上具有里程碑意义的论文进行了阅读和讨论，下面是我们早期技术调研、论文阅读的任务分配截图和论文阅读笔记截图。\n图 4-1\n图 4-2\n图 4-3\n4.1.1 虚拟试衣技术的发展历史 在线时装行业已经受到诸如增强现实，虚拟现实，可穿戴技术和互联试衣间等最新技术创新的影响。无论是用于创建新产品目录还是为购物者提供沉浸式环境，它都可能影响电子商店并为新的易于图像编辑的可能性打开大门。\n在早期，相关工作的处理主要使用三维测量和基于模型的方法，例如2012年的DRAPE: DRessing Any PErson ，2014年的Subspace Clothing Simulation Using Adaptive Bases，2017年的。然而，它们本质上是计算密集型的并且需要昂贵的成本，这对于购物者而言通常是不可接受的。而利用图像合成技术则可以降低零售商的成本。在计算机视觉中，图像生成模型（例如2014年的GAN，2016 年的PixelDTGAN等）能够生成高质量的真实感图像，已成功应用于众多应用中。\n近年来，二维方法由于数据容易获取和结果逼真而受到越来越多的关注。例如2017年的有条件的类比GAN：在人像上时尚换装（CAGAN），2018年的VITON：基于映像的虚拟试穿网络，VITON使用了一个两阶段的从粗到细的策略来产生一个穿衣服的人。它首先估计粗糙的人体形状，然后用形状上下文匹配算法扭曲衣服，并根据形状细化穿衣服的人的细节。VITON同年提出来的的改进版Toward Characteristic-Preserving Image-based Virtual Try-On Network（CP-VTON），引入了卷积几何匹配器（用于几何匹配的卷积神经网络架构，2017）。2019年的Towards Multi-pose Guided Virtual Try-on Network（MG-VTON ），扩展到多姿势试穿系统，该系统需要修改人的姿势以及上身的衣服。CAGAN （有条件的类比GAN：在人像上时尚换装）提出了一种基于U-Net的GAN 方法。但是，由于这些网络无法处理较大的空间变形，因此这些方法无法产生实际的结果。大多数的试穿方法都是基于单个图像的，不过也有基于视频的虚拟试穿，例如2019年的FW-GAN: Flow-navigated Warping GAN for Video Virtual Try-on。ACGPN引入了一个额外的阶段来预测参考图像的语义布局。DCTON和ZFlow添加了更准确的描述符号，如变性或UV投影。VITON-HD提高了条件GAN结构在高分辨率图像上的性能。虽然生成的图像质量更好，但管道正变得越来越复杂，并依赖于更多的外部信息，导致了效率的降低和由不准确的中间标签造成的明显的伪影。\n传统的基于深度学习的2d虚拟试衣的算法，例如鼻祖VITON，以及后续的CPVITON，ACGPN等，大多依赖于人体解析（human parsing），也就是算法不仅仅需要待穿着的人的图像，还需要对该人进行各个部位的语义分割或者关键点提取的结果，ACGPN就是其中一个典型的例子。我们最希望的是，一个模型只需要输入目标衣服和候选人，直接输出换装结果，或者说，我们希望得到一个无需人体解析（Parser- Free，下文中使用）的模型。WUTON是Parser-Free模型中的一个经典案例，该模型使用了知识蒸馏（knowledge distillation）的方法，知识蒸馏实际上就是用教师模型（teacher model）的结果监督学生模型（student model）的过程，可以实现教师模型的知识复制到学生模型上的功能。WUTON的教师模型的输入包含目标衣服，待换装的人以及人的解析结果，而学生模型的输入只有目标衣服和待换装的人，用教师模型的输出作为真值约束学生模型的训练过程，就是WUTON的主要思想。2021年的PF-AFN则认为教师模型的输出是不适合作为真值的，因为这只是一个生成的虚拟的结果，可能存在局部的偏差或不自然，因此，更换了思路，将教师模型的输出作为一种指导信息（tutorial），自行选择哪部分应该使用。将最初的人的图像作为真值，而将教师输出作为学生的输入，而非用教师的结果约束学生，实现教师指导学生（teacher tutor student）的知识蒸馏架构，这样学生模型的生成效果不会受限于教师模型，大大提高了学生模型的性能。\n4.1.2 空间变换模块 空间变换模块广泛地应用于光流估计、图像变换和目标识别任务中。在虚拟试衣中，空间转换模块主要用于使衣服匹配人的姿势。\nVITON 利用基于薄板样条（TPS）的翘曲方法，使店内服装的变形达到更为精细的效果；\nCP-VTON使用一个神经网络来学习TPS扭曲的变换参数，而不是使用图像描述符；\nClothFlow通过级联的方式引入了更密集的流预测，这使得变形的自由度更高。然而，密集流往往不够平滑。为了避免这个问题，ClothFlow使用正则化来强制平滑；\nPFAPN则增加了一个二阶光滑约束，以实现相邻外观流的共线性，尽管提出这些约束条件是为了使服装在变形后更平滑，但模型当目标衣服与原来的衣服存在较大差异时，模型性能仍有待提高。\n4.1.3 注意力机制 注意力机制是一种计算机视觉和自然语言处理中广泛应用的机制，在词句预测，机器翻译，图像分割、目标检测和图像生成等方面都取得了良好的性能，它可以在输入序列中寻找与输出相关的部分，以便更好地进行特征提取。在深度学习模型中，常常使用自注意力机制来建模序列间或像素点间的长距离依赖关系，其中每个输入元素都被视为其他元素的参考点。\n然而在图像领域中，随着分辨率的提高，计算量爆炸性增加，密集的注意力机制变得难以实现。为了解决这个问题，研究人员通常使用预定义的局部注意力模式或稀疏注意力模式。在像素级图像变换中，团队在模型设计时结合了流操作对保留细节的有效性和注意力机制对精确结构估计的能力，自然而然地将稀疏注意力模式扩展到像素级图像变换中。\n4.2 模型总体架构 图 4-4 模型总体架构图\n现有的的虚拟试衣模型在生成真实的结果和细节方面取得了较大进展。然而，这仍是一项具有挑战性的任务，特别是在人体姿态复杂以及生成的图像与原有图像存在较大变形的情况下，大多数现有方法仍然存在错位或明显的生成痕迹，并且高质量虚拟试衣图像的生成相当多的依赖于人体解析图或者人体姿势图，如果人体解析图或者人体姿态图有误，生成质量会大大折扣，并且由于人体解析图或人体姿势图的引入，解析人体的预处理时间也会给生成速度带来不小挑战，多阶段的生成也会加大工程部署的难度，为虚拟试衣技术的真正应用带来挑战。为解决以上问题，我们团队设计了基于SDAFN与PF-AFN的虚拟试衣系统。\n我们借鉴PF-AFN中中知识蒸馏的思想，将教师模型（Teacher Model）的输出作为一种指导信息（tutorial），让学生模型自行选择哪部分应该使用。将最初的人的图像作为真值，而将教师输出作为学生的输入，而非用教师的结果约束学生，实现教师指导学生（teacher tutor student）的知识蒸馏架构。教师模型使用到了人体掩码和人体姿态信息，结果会更准确，为了把这些信息传授给学生，教师+学生串联起来，实现了端到端的自监督。这样就将一个大型、复杂的神经网络模型（教师模型）中的知识迁移到一个小型、简单的神经网络模型（学生模型），减小了模型参数，同时实现了学生模型的输入只需要人物和衣服的图片，而不需要依赖任何人体解析图或者人体姿态图等任何辅助信息，且学生模型的效果不受限于教师模型；\n对于SDAFN，我们使用SDAFN作为我们的教师模型。同时我们利用其One-Stage框架的创新性构想，借鉴了其外观估计流appearance flow的思想（DAFlow），使用了可形变transformer（deformable transformer）做为外观估计流的主要架构，同时改进了深层特征提取器和输入输出模块，重新设计并提出了SDAFN_plus作为我们学生模型的架构。值得一提的是，DAFlow是利用人和服装图像的自形变和交叉形变注意力流获得输出结果，以端到端的方式达到逼真的拟合结果。\n需要指出的是，我们的教师网络采用的是开源的SDAFN模型，而学生网络则采用的是我们在SDAFN基础上改进优化而重新构建的SDAFN_Plus模型。\n4.3 学生模型SDAFN_plus分析 图 4-5 子网络SDAFN_plus架构图\n如图所示，我们改进的学生网络SDAF_plus主要有三个模块构成，分别是特征金字塔提取器，级联流估计和浅编码器与解码器。其中，服装与待试穿的人的图像首先被输入到非共享的特征金字塔提取器中；然后，在级联流估计模块中，对自形变和交叉形变注意力流进行估计；最后，利用浅编码器和解码器以及学习到的数据流，得到了最终的试穿结果。\n下面分别具体介绍特征金字塔提取器，级联流估计和浅编码器与解码器这三个模块。\n4.3.1 金字塔特征提取器 金字塔特征提取器是一种多尺度特征提取方法，用于解决物体尺度变化问题。在计算机视觉领域中，物体的尺度往往是不确定的，而且同一个物体在不同的尺度下有不同的表现。金字塔特征提取器通过在不同的尺度下提取特征来解决这个问题，从而可以更好地进行物体检测和识别。\n图 4-6 特征金字塔提取器\n金字塔特征提取器通常采用自底向上或自顶向下的方式生成多个尺度的特征图。自底向上的方法是通过在输入图像上应用一个低通滤波器来减小尺度，并对结果进行下采样来生成一系列尺度较小的图像，然后在每个尺度上提取特征。自顶向下的方法是从原始图像开始，通过上采样或插值将其尺度增加，然后在每个尺度上提取特征。两种方法都可以生成多个尺度的特征图，但自顶向下的方法通常更精细，因为它可以利用原始图像的细节信息来生成高分辨率的特征图。\n金字塔特征提取器已被广泛应用于计算机视觉任务，如物体检测、语义分割和行人重识别等。\n在金字塔特征提取器模块，我们的模型有两个自顶向下的金字塔特征提取器，包括一个参考分支和一个源分支,均采用自顶向下的方式生成多个尺度的特征图。其中参考分支将待试穿的人作为输入，源分支将服装图像作为输入。这两个特征提取器具有相同的特征金字塔网络（FPN）结构而且非共享参数。在特征提取器选取方面，团队分别尝试了VGG17和resnet网络，最终选取resnet网络，特征提取器的层数我们做了实验，分别选取3，4，5。最终，在模型大小，模型推导速度，生成效果等因素的综合考量下，将特征提取层层数取为3层。\n我们同时做了对比实验，比较了特征提取层层数分别是3，4，5的模型测试效果。\n特征提取层层数 3 4 5 FID 9.05 8.75 9.054 表 4-1 特征提取此器的对比试验\n4.3.2 级联流估计 在虚拟试衣模型中，我们可以知道的是，对于较大的变形是难以预测的，因为目标域与源域的图像往往是不统一的，为解决这个问题，我们采用了由粗到细的级联流估计，具体操作在下文展开。\n根据金字塔特征提取器提取的hierarchical reference和源特征，估计了两种类型的流和注意力图。其中，第一种是来自参考分支的Self-Flows Fields和Self-Attention Maps；第二种是来自两个分支相互作用的Cross-Flows Fields和Cross-Attention Maps。最低分辨率的特征被输入到DAFN中以预测初始Flow Field和Attention Map。\n然后，它们将被级联地细化和更新。具体来说，参考特征图和源特征图首先由前一个Self- and Cross-DAFlows进行转换，这个操作称为DAWarp；然后，利用变换后的特征来预测剩余流，并得到了具有更精细的新注意力图（上述过程一直持续到n=N）。在模型的实现中，N被设置为3。\n需要说明的是，对于DAWarp操作，如下图所示，DAFlow学习了各种可能的流，将Flow Fields和Attention操作同时应用于特征和图像。在特性方面，源或参考特性被有效地集成到期望的目标位置：\n公式中为参考位置p的第k个采样位置， 表示DAFlow的弯曲特征。在图像层面上，合并多个扭曲的图像丰富了生成的可能性，并被重新组合成具有合理结构和真实纹理的新图像。其中，颈部和手臂的部分是真实生成的，并不在原始图像中。此外，Warp操作应用双线性插值操作，使估计的偏差得以优化与反向传播。\n4.3.3 浅编码器与解码器 浅编码器将图像从RGB图像投影到高维空间，并且利用最终估计的流和注意力图，将高维特征空间中的参考人和服装图像与DAWarp进行变换和合并（变换操作与上文提到的DAWarp操作类似）；然后将合并后的结果输入到一个浅解码器中，得到最终的试穿结果。浅编码器和解码器都有两个卷积层，没有下采样操作。值得说明的是，服装图像和参考人图像共享相同的编码器和解码器。实验验证，浅编码器-解码器结构可以有效提高像素级表示能力与流生成质量。\n4.4 模型训练 4.4.1 训练平台 模型训练环境如下表所示：\n训练平台 模型框架 显存 显卡 Ubuntu pytorch 24G*2 3080Ti*2 表4-2 训练环境参数\n在训练时，初始学习率设为0.00005，每迭代30轮变为之前的0.2倍。在模型优化器方面，我们选择adamw,该优化器在机器视觉问题有较好的泛化性能。相比于l2优化器，Adamw在相同迭代轮数下有着更好的准确率。\n图 4-7\n4.4.2 数据集 模型训练采用virtual-tryon领域公认的viton公开数据集，并使用了翻转 (flip)、旋转 (rotation)、缩放 (scale)、裁剪 (crop)、移位 (translation)等方法增强数据集。数据增强有助于增强模型泛化能力，并且可以大幅降低过拟合程度。\n图 4-8 数据增强示例图，第一列为原图，后四列由对第一列随机裁剪，旋转得到\n对于教师模型SDAFN的训练，需要额外的人体掩码图和人体姿态估计图，所以我们首先对VITON数据集进行预处理，得到VITON_plus数据集，其中包含了所有人像的掩码图和人像的姿势图，以及对衣服进行预处理得到的分理出衣服背景的衣服前景分割图。\n图 4-9 数据集文件目录\n图 4-10 人像掩码图\n图 4-11 人体姿态图\n图 4-12 服装前景分割图\n对于学生模型的训练，只需要将VITON原始人像和原始衣服作为输入，不需要任何额外的辅助信息。\n图 4-13 原始人像和衣服\n4.4.3 训练过程 知识蒸馏 知识蒸馏与迁移学习在模型优化中有很重要的应用。一般地，大模型往往是单个复杂网络或者是若干网络的集合，拥有良好的性能和泛化能力，而小模型因为网络规模较小，表达能力有限。因此，可以利用大模型学习到的知识去指导小模型训练，使得小模型具有与大模型相当的性能，参数数量大幅降低，从而实现模型压缩与加速。\n原理介绍如下图所示：\n图 4-14 知识蒸馏原理图\n训练过程 （1）教师模型训练\n首先，我们使用开源的SDAFN作为教师模型，用预处理后的VITON_plus数据集对教师模型进行训练，使其能够在各种任务上表现出色。在训练过程中，使用了翻转，剪切数据增强，正则化等方法提高模型生成效果。\n（2）学生模型训练\n项目主要采用模型蒸馏训练学生模型。在蒸馏的过程中，我们将原始大模型称为教师模型（teacher），新的小模型称为学生模型（student）。\n学生模型的架构采用我们改进优化后提出的SDAFN_plus,其只需要人物图像和衣服图像作为输入，而不要任何其他的辅助信息。\n与传统的蒸馏方法不同的是，我们将最初的人的图像作为真值，而将教师输出作为学生的输入，而非用教师的结果约束学生，实现教师指导学生（teacher tutor student）的知识蒸馏架构。教师模型使用到了人体掩码和人体姿态信息，结果会更准确，为了把这些信息传授给学生，教师+学生串联起来，实现了端到端的自监督。这样就将一个大型、复杂的神经网络模型（教师模型）中的知识迁移到一个小型、简单的神经网络模型（学生模型），减小了模型参数，同时实现了学生模型的输入只需要人物和衣服的图片，而不需要依赖任何人体解析图或者人体姿态图等任何辅助信息，且学生模型的效果不受限于教师模型。\n值得注意的是学生模型训练时教师模型的参数不再进行更新。我们在训练学生模型时同样采用了三个阶段：\n在第一阶段，我们使用分割出衣服前景的衣服图进行训练，使模型可以获得一定的衣服分割的知识。\n在第二阶段，我们在原始的衣服图上进行训练以进行调优，原始的衣服图像为白色背景。\n第三阶段，由于我们将教师模型的输出作为学生模型的输入，所以我们可以使教师模型生成不同图片来作为学生模型的输入，我们以此来改变和扩大学生模型训练的数据集\n实验表明我们采用三个阶段训练的学生模型相比一阶段训练的模型鲁棒性更强，抗干扰能力更强，拥有更好的性能指标和生成效果。\n模型效果对比 从表格4-3可以看出，我们的模型使用基于知识蒸馏的训练方法，可以大幅减少模型体积，同时保留教师模型高性能表现。\n模型名称 模型大小 模型评价指标（FID）on VITON数据集 传统多任务模型（CP- VTON） 200MB 30.50 SDAFN(教师模型） 356MB 10.97 SDAFN_plus（学生模型） 64MB（fp32） 8.74 表 4-3\n5 工程化实现 5.1 工程化实现的整体框架 对于深度学习模型来说，模型部署指让训练好的模型在特定环境中运行的过程。相比于软件部署，模型部署会面临更多的难题。运行模型所需的环境难以配置。深度学习模型通常是由一些框架编写，比如 PyTorch、TensorFlow。由于框架规模、依赖环境的限制，这些框架不适用于生产环境。深度学习模型的结构通常比较庞大，需要大量的算力才能满足实时运行的需求。模型的运行效率需要优化。因为这些难题的存在，模型部署不能靠简单的环境配置与安装完成。经过工业界和学术界数年的探索，模型部署有了一条流行的流水线，即先在深度学习框架中训练原始模型，再转换为中间表示，经过优化后部署在推理引擎运行。这一流水线能解决部署中的两大问题，一是使用框架和推理引擎中间表示，二是通过中间表示的网络结构优化和推理引擎对运算的底层优化，提高模型运算效率。\n下图为我们工程化实现的整体框架图：\n图 5-1 工程化整体框架图\n首先对保存下来的pth模型进行处理，剔除梯度，只保存模型的权重，得到后处理过后的pth，然后使用pytorch内置函数导出为onnx格式，将精度格式为fp32的onnx模型分别截断为fp16，量化为int8格式，最后使用onnxruntime推理引擎推导模型。\n5.2 模型转换 5.2.1 pth模型的后处理 为了训练过程的方便，在训练过程中保存chekpoints时我们将模型的权重和梯度，当前的学习率，训练轮数一并保存下来了，模型参数的梯度和学习率，当前的训练轮数在模型断点训练时十分有用，但在模型推导时并不会发挥作用，而且还会增加模型存储空间的占用，延长推理时模型的加载时间，所以我们首先对pth模型进行后处理，剔除了对于推理无作用的梯度，只保留模型的权重，以方便后面对pth模型的转换。\n5.2.2模型的导出 图 5-2 模型转换示意图\n在模型导出过程中，我们选用ONNX来进行模型中间表示。ONNX （Open Neural Network Exchange）是 Facebook 和微软在2017年共同发布的，用于标准描述计算图的一种格式。目前，在数家机构的共同维护下，ONNX 已经对接了多种深度学习框架和多种推理引擎。因此，如图4-4所示，ONNX 被当成了深度学习框架到推理引擎的桥梁。就像编译器的中间语言一样，由于各框架兼容性不一，我们通常用ONNX来作为便于在各个主流深度学习框架中迁移模型的中间表达格式。\n从Pytorch到ONNX在本质上是一种语言的翻译，但ONNX只记录不考虑控制流的静态图，通过使用trace方法，给定一组输入，再实际执行一遍模型，即把这组输入对应的计算图记录下来，保存为 ONNX 格式。在转换完成后，可使用Netron来可视化ONNX模型，查看包括输入输出和每个算子的信息。每个算子记录的信息包括算子属性、图结构、权重。算子属性信息即图中 attributes 里的信息，对于卷积来说，算子属性包括了卷积核大小(kernel_shape)、卷积步长(strides)等内容。这些算子属性最终会用来生成一个具体的算子。图结构信息指算子节点在计算图中的名称、邻边的信息。根据每个算子节点的图结构信息，就能完整地复原出网络的计算图。权重信息指的是网络经过训练后，算子存储的权重信息。对于卷积来说，权重信息包括卷积核的权重值和卷积后的偏差值。\n5.2.3 导出代码 我们使用pytoch自带的torch.onnx.export函数将pth模型导出为onnx格式。\n1torch.onnx.export(sdafnet_plus, (person_input, clothes_input), 2saved_model_path, 3do_constant_folding=True, # 是否执行常量折叠优化 4opset_version=16, 5verbose=True, input_names=[\u0026#39;person\u0026#39;, \u0026#39;clothes\u0026#39;], 6output_names=[\u0026#39;outcome\u0026#39;]) torch.onnx.export: 这是调用torch.onnx模块的export函数将PyTorch模型转换为ONNX格式的函数。 sdafnet_plus: 这是要转换为ONNX格式的PyTorch模型。 saved_model_path: 这是导出的ONNX模型的保存路径。 do_constant_folding: 这个参数控制是否在导出时执行常量折叠优化，将模型中的常量计算成一个常量，以减少计算的开销。 opset_version: 这个参数指定所使用的ONNX版本号。 verbose: 这个参数控制导出过程中是否打印输出。 input_names: 这个参数是模型输入的名称，用于在导出模型时标识模型的输入。 output_names: 这个参数是模型输出的名称，用于在导出模型时标识模型的输出。 用torch导出的模型有时候参数过多，不利于查看。查找资料onnxsim可以简化模型，让显示更加自然。\n如，reshap层的导出，红框中细节参数被显示出现。默认导出：\n图 5-3 简化前示意图\n使用onnxsim 可以让结构更加简洁，具体执行方式如下：\n安装onnxsim包 pip install onnx-simplifier 加载onnx文件，simplify处理后重新保存，代码如下： from onnxsim import simplify onnx_model = onnx.load(output_path) # load onnx model model_simp, check = simplify(onnx_model) assert check, \u0026ldquo;Simplified ONNX model could not be validated\u0026rdquo; onnx.save(model_simp, output_path) print(\u0026lsquo;finished exporting onnx\u0026rsquo;) 使用netron对模型进行可视化查看，结果导出如下： 图 5-4 简化后示意图\n使用onnxsim工具对导出的onnx模型进行简化，不仅能使onnx模型的结构更加清晰明了，也可以使减少模型大小，对于我们的学生模型而言，经过onnxsim的处理后大概减少了4MB。\n5.2.4 Bug修复 在模型转换阶段，我们遇到了pytorch内部torch.repeat_interleave()函数bug，该bug 导致模型导出后某一具体节点维度不匹配，但在模型导出阶段并未提示错误（该bug已由pytorch开发社区解决，预计于之后版本修复）。\n我们成功使用上述转换代码将pth模型转换为了onnx 格式，但我们在后续推理中发现onnx模型存在错误，推理时显示multi_add（19）这个节点的输入和输出维度不匹配，经过debug，我们使用netron这个可视化工具可视化导出的onnx模型，找到了出问题的节点，然后与代码中的操作进行匹配，发现是pytoch中torch.repeat_interleave()这个函数的导出出了问题，经过不懈的查找，我们发现这是pytoch发行版中一个仍未解决的bug，这个函数的导出对onnx算子的映射出现了错误，我们在pytorch社区中找到了解决的方法，此bug 2022年12月已被社区解决，但我们当时使用的时候最新的pytorch发行版仍未修正此bug，我们尝试了从github社区的最新pytorch源码重新编译安装以解决此bug，同时我们发现使用tensor.shape，tensor.view与tensor.repeat这几个函数组合以实现和torch.repeat.interleave这个函数一样的功能。\n为解决该bug，我们重写了该函数torch.repeat_interleave（），以实现其基本功能。\ntorch.repeat_interleave()是PyTorch中用于重复张量元素的一个函数。它的输入参数包括：input（类型：torch.Tensor）- 输入张量，repeats（类型：int或torch.Tensor）- 每个元素的重复次数，以及可选参数dim（类型：int）- 重复的维度。\n1att_maps = torch.repeat_interleave(att_maps, out_ch, 1) 具体代码修改如下：\n1att_maps_1c = att_maps.shape[0] 2# 计算变量att_maps的第一维大小，即att_maps_1c 3 att_maps_2c = att_maps.shape[1] 4# 计算变量att_maps的第二维大小，即att_maps_2c 5att_maps_3c = att_maps.shape[2] 6# 计算变量att_maps的第三维大小，即att_maps_3c 7att_maps_4c = att_maps.shape[3] 8# 计算变量att_maps的第四维大小，即att_maps_4c 9att_maps =att_maps.view(-1, 1, att_maps_3c, att_maps_4c) 10# 将变量att_maps的形状改为(-1, 1, att_maps_3c, att_maps_4c) 11att_maps= att_maps.repeat(1, out_ch, 1, 1).view(att_maps_1c,-1, att_maps_3c, att_maps_4c) 12# 将变量att_maps重复out_ch次，然后改变形状为(att_maps_1c, -1, att_maps_3c, att_maps_4c) 经过测试，我们发现使用tensor.shape，tensor.view与tensor.repeat这几个函数组合实现torch.repeat_interleave()的功能，可以使模型的推导速度加快，此节点的运算速度可以提升约20%。\n5.3 模型量化 量化(Quantization)是指将高精度浮点数(如float32)表示为低精度整数(如int8)的过程，从而提高神经网络的效率和性能。\n图 5-5 量化示意图\n5.3.1 Fp16量化 FP16量化是一种对浮点数进行压缩的技术，将32位浮点数压缩为16位.如图4-4所示，FP16比FP32表示位数减少一半，对模型进行fp16量化可以在不牺牲模型性能的情况下，显著减少模型的存储和计算成本。fp16量化可以将模型中的权重和激活值从32位浮点数减少到16位浮点数，从而减少了模型的内存占用和计算复杂度。此外，fp16量化还可以提高模型的运行速度和功耗效率，特别是在移动设备和嵌入式设备上。\nOnnxMlTools是一个用于处理ONNX模型的Python库，它提供了一组工具和API，使用户能够读取、创建、转换、优化和运行ONNX模型。该库支持多种深度学习框架（如TensorFlow、PyTorch、Caffe2等）和多种硬件平台（如CPU、GPU、TPU等），并且可以将ONNX模型转换为其他格式（如TensorFlow、PyTorch、CoreML等）。此外，OnnxMlTools还支持模型的可视化、优化和解析，并且可以在不同的编程语言（如C++、Java、python等）中使用。总之，OnnxMlTools是一个非常强大的工具，可以帮助深度学习开发人员更好地管理和使用ONNX模型。\n我们使用OnnxMITools这个库进行fp16量化，实现截断的核心代码：\n1import onnxmltools 2from onnxmltools.utils.float16_converter import convert_float_to_float16onnx_model = onnxmltools.utils.load_model(input_onnx_model) 3onnx_model = convert_float_to_float16(onnx_model) 4onnxmltools.utils.save_model(onnx_model, output_onnx_model) 这段代码使用了onnxmltools库中的float16_converter模块，用于将输入的ONNX模型中的浮点数类型转换为半精度浮点数类型。\n第1行导入了onnxmltools库。 第2行从onnxmltools.utils.float16_converter模块中导入了convert_float_to_float16函数，用于将浮点数类型转换为半精度浮点数类型，并使用load_model函数加载输入的ONNX模型。 第3行使用convert_float_to_float16函数将ONNX模型中的浮点数类型转换为半精度浮点数类型。 最后使用onnxmltools.utils.save_model函数将转换后的ONNX模型保存到指定的输出路径。 5.3.2 Int8量化 我们在模型量化阶段尝试了FP16和int8两种量化形式，最终比较选择了FP16量化后的模型，这里简短介绍一下我们所做的int8量化工作。Int8量化分为动态量化与静态量化。\nONNXRuntime 中的量化是指 ONNX 模型的 8 bit 线性量化。在量化过程中，浮点实数值映射到 8 bit 量化空间，其形式为：\nVAL_fp32 = Scale * （VAL_quantized - Zero_point）\nScale 是一个正实数，用于将浮点数映射到量化空间，计算方法如下：\n对于非对称量化： 1scale = (data_range_max - data_range_min) / (quantization_range_max - quantization_range_min) 对于对称量化： 1scale = abs(data_range_max, data_range_min) * 2 / (quantization_range_max - quantization_range_min) Zero_point 表示量化空间中的零。重要的是，浮点零值在量化空间中可以精确地表示。这是因为许多 CNN 都使用零填充。如果在量化后无法唯一地表示 0，则会导致精度误差。\nONNXRuntime 支持两种模型量化方式：\n动态量化：对于动态量化，缩放因子（Scale）和零点（Zero Point）是在推理时计算的，并且特定用于每次激活。因此它们更准确，但引入了额外的计算开销 静态量化：对于静态量化，它们使用校准数据集离线计算。所有激活都具有相同的缩放因子（Scale）和零点（Zero Point） 以下是我们进行动态量化的核心代码：\n1**import** onnxruntime as ort 2**from** onnxruntime.quantization **import** QuantizationMode, QuantizationParameters 3model_path = \u0026#34;path/to/your/model.onnx\u0026#34; 4sess = ort.InferenceSession(model_path) 5qparams = QuantizationParameters( 6force_fusions=True, 7use_external_data_format=False, 8symmetric_weight=True, 9symmetric_activation=True, 10weight_scale=0.5, 11activation_scale=0.2, 12quantization_mode=QuantizationMode.IntegerOps 13) 首先通过指定模型路径来创建一个推理会话，然后设置QuantizationParameters的各个参数，包括force_fusions（是否强制融合操作）、use_external_data_format（是否使用外部数据格式）、symmetric_weight（是否对权重进行对称量化）、symmetric_activation（是否对激活进行对称量化）、weight_scale（权重量化的缩放因子）、activation_scale（激活量化的缩放因子）和quantization_mode（量化模式）。最后，这些参数可以用于对模型进行量化。\n下面是我们进行静态量化的核心代码：\n1input_model_path = \u0026#39;../onnx/epoch129-batch-1-fp32.onnx\u0026#39; # 输入onnx模型 2output_model_path = \u0026#39;../onnx/epoch129-batch-1-int8.onnx\u0026#39; # 输出模型名 3calibration_dataset_path = \u0026#39;../data/VITON/VITON_test/test_img\u0026#39; # 校准人像数据集图像地址 4cloth_dataset_path = \u0026#39;../data/VITON/VITON_test/clothes\u0026#39; # 校准衣服数据集图像地址 5# 用于校准数据加载,注意这个方法里面需要做图像一些操作,与pytorch训练的时候加载数据操作一致 6dr = DataReader(calibration_dataset_path, cloth_dataset_path, input_model_path) 7# 开始量化 8quantize_static(input_model_path, 9output_model_path, 10dr, 11quant_format=QuantFormat.QDQ, 12per_channel=False, 13weight_type=QuantType.QInt8) 5.4 模型推断 推理引擎是一种软件工具，用于运行机器学习模型的推理（预测）过程。它可以将训练好的模型输入到系统中进行推理，通过计算得出模型的预测结果。推理引擎通常具有高效、可扩展、低延迟等特点，能够满足大规模、高并发的推理需求。\nONNX Runtime 是一种高性能、跨平台的推理引擎，它支持多种硬件平台，包括 CPU、GPU 和 FPGA 等，并且可以与多种编程语言和框架（如 C++、Python、TensorFlow、PyTorch 等）进行集成。ONNX Runtime 还支持多种模型格式，包括 ONNX、TensorFlow、Keras、MXNet 等，可以方便地加载和运行各种机器学习模型。\n我们选择 ONNX Runtime 作为我们模型推理引擎的主要原因是它具有以下优势：\n高性能：ONNX Runtime 采用了多种优化技术，包括 JIT 编译、自动调度、张量融合等，可以在多种硬件平台上获得高效的推理性能。 跨平台：ONNX Runtime 支持多种硬件平台和操作系统，可以方便地在不同的环境中部署和运行。 多框架支持：ONNX Runtime 支持多种机器学习框架和模型格式，可以方便地与不同的工具和库进行集成。 社区支持：ONNX Runtime 是一个开源项目，拥有庞大的社区支持和贡献者，可以获得及时的技术支持和更新。 综上所述，选择 ONNX Runtime 作为推理引擎可以帮助开发者实现高效、跨平台、多框架的机器学习模型部署和推理，所以我们选择onnxruntime作为我们的推理引擎。\n图 5-6 ONNXRuntime 总览\n为了使模型实现真正的端到端处理，我们先使用opencv处理输入的图片，使其可以被模型处理。\n具体处理逻辑如下,通过调研得知，cv2.dnn.blobFromImage函数可很方便的对图像进行预处理，包括减均值，比例缩放，裁剪，交换通道等，并返回一个4通道的blob，用于神经网络的输入。\n1person_img = cv2.imread(args.input_person) 2# cv2.imshow(\u0026#39;image\u0026#39;, person_img) 3cloth_img = cv2.imread(args.input_cloth) 4# 读到的是BGR数据，该方法不能读取带中文路径的图像数据。 5# 对读入的图片裁剪到指定比例 6ratio = 256.0 / 192.0 7inp_h, inp_w, _ = person_img.shape 8current_ratio = inp_h / inp_w 9**if** current_ratio \u0026gt; ratio: 10center_h = inp_h // 2 11out_h = inp_w * ratio 12start = int(center_h - out_h // 2) 13end = int(center_h + out_h // 2) 14person_img = person_img[start:end, ...] 15**else**: 16center_w = inp_w // 2 17out_w = inp_h / ratio 18start = int(center_w - out_w // 2) 19end = int(center_w + out_w // 2) 20person_img = person_img[:, start:end, :] 21person_img = cv2.dnn.blobFromImage(person_img, 1.0 / 127.5, (192, 256), mean=(127.5, 127.5, 127.5), swapRB=True) 22cloth_img = cv2.dnn.blobFromImage(cloth_img, 1.0 / 127.5, (192, 256), mean=(127.5, 127.5, 127.5), swapRB=True) ONNX Runtime是直接对接ONNX的跨平台机器学习推理加速器，基于ONNX的模型推断非常方便和高效，ONNXRuntime可以直接读取并运行.onnx文件, 而不需要再把 .onnx 格式的文件转换成其他格式的文件。只需要加载数据和模型，调用runtime进行推理即可。\n1sess_options = onnxruntime.SessionOptions() 2sess_options.intra_op_num_threads = 4 3sess_options.execution_mode = onnxruntime.ExecutionMode.ORT_SEQUENTIAL 4sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL 5onnx_session = onnxruntime.InferenceSession(model_path) 6inputs = (person_img, cloth_img) 7output_name = onnx_session.get_outputs()[0].name 8input_name1 = onnx_session.get_inputs()[0].name 9input_name2 = onnx_session.get_inputs()[1].name 10outputs = onnx_session.run(None, {input_name1: inputs[0], input_name2: inputs[1]}) 6 模型部署 我们的模型分别采用了服务器端的Web部署和本地化的可执行程序exe部署两种部署方式，其中服务器端的Web部署我们采用了前后端分离的开发策略，前端使用Vue框架，后端使用Flask框架。同时后端使用Gunicorn容器，前端使用Nginx容器来提高Web应用程序的性能和稳定性。\nWeb端模型部署在http://47.92.51.188:81/（(可通过此链接访问我们的网页：无忧工作室)），本地化的可执行程序也可以从Web页面上获取下载链接。\n6.1 web部署整体框架图 图 6-1 Web流程图\n6.2 web前端部署 为了更好的展现模型效果，前端页面包括四个部分：首页，试衣体验，视频介绍和软件下载。\n在首页，我们将展示自主设计的团队logo及virtual-tryon介绍动画,展示虚拟试衣的技术背景和我们的模型特色。\n在试衣体验部分，我们提供现成的测试集供用户体验虚拟试衣，并为用户上传测试数据提供参考，用户可自己选择人物和衣物图进行上传，后台推理程序会返回推理结果并展示给用户。\n在视频介绍部分，我们将通过视频的方式介绍虚拟试衣的背景，我们模型的算法以及网页和本地化可执行程序的使用方法，在软件下载部分我们提供可执行的exe程序供用户本地运行。\n6.2.1 目录结构与文件 前端部署项目目录结构如下：\n图 6-2 前端项目目录结构图\n在上图目录结构中：\nidea目录储存IntelliJ IDEA项目的配置信息。 dist目录是打包后的文件，用于服务器端上传部署。 jsconfig.json用于配置VS Code的JavaScript语言服务。 node_modules：包含项目依赖的所有npm包。 public：包含静态资源，如HTML文件、图标和CSS文件。 src：包含项目源代码，如Vue组件、JavaScript文件和CSS文件。 static：包含静态资源，如图片和视频。 vue.config.js：用于配置Vue CLI。 6.2.2 项目构建与打包 （1） 环境配置\n安装Node.js，作为前端工程化项目运行的基础环境；安装Vue和Vue CLI，用于快速构建Vue工程项目；安装nrm 镜像管理工具切换镜像并安装npm。\n（2） 项目开发\n网页基于Vue.js框架进行开发。Vue.js是一款流行的JavaScript前端框架，旨在更好地组织与简化Web开发。Vue所关注的核心是MVC模式中的视图层，同时，它也能方便地获取数据更新，并通过组件内部特定的方法实现视图与模型的交互。\n我们通过使用Vue.js的模板用于创建虚拟试衣网站，需要指明的是：\nTryOn.vue主要定义试衣体验界面展示逻辑与用户交互； WelcomeTo.vue主要定义首页展示与交互； TryOn.vue和WelcomeTo.vue两个文件都存compoents路径下。 在public目录下：编写使用flexBox布局的HTML页面，创建一个垂直滚动的图像列表。创建CSS 文件，定义HTML元素的样式，例如定义元素周围空间，控制元素外观和布局，控制元素背景颜色，显示方式等。 在stitic目录下：存放静态文件，包括示例虚拟试衣数据集，展示视频等。 6.3 web后端部署 后端项目目录如下：\n图 6-3 后端项目目录图\n在上图目录中：\nMain.py 为主程序，提供了后端程序的调用，并定义了后端的接口，获取用户上传的图片，经过调用处理后返回给用户生成的试衣图片 Process.py 处理文件储存逻辑，返回文件名去除扩展名的部分。 onnx目录下储存部署在onnxruntime推理中的FP16量化模型 Virtual_TryON.py对输入图片进行裁剪至指定比例，随后设置onnx对话的参数，调用run方法，得到模型的输出结果 6.4 项目服务器环境部署 图 6-4 服务器环境部署\n团队选用阿里云centos作为服务器部署端，在配置规则中开放81端口用于服务访问。\n在技术选型方面，由于nginx服务器性能优秀，运行稳定，故选择nginx作为前端框架。\n（1）环境配置\n首先安装nginx前置环境，并上传nginx，修改对应路径名称即可。\n（2）配置文件修改\n修改nginx.conf配置文件，将监听端口改为81，并将 root和index改为virtual-tryon项目所在dist目录。使用后台启动命令再次启动Nginx，即可完成前端web页面部署。\n7 模型测试 7.1 实际效果图展示 在生成图中，可以看到模型对人物和衣服的拟合效果较好，衣物细节得以保留，且能很好的贴合人物身形，在下图中可以发现，我们的模型甚至能对孕妇做出较好的试衣效果，与此同时，我们相较之其他模型，我们的实际效果也极为出色。\n需要指出的是，效果展示图中，左一是输入人像，左二是试穿服装，右一是试穿结果。\n图 7-1 效果展示\n下面是我们的模型与目前比较出名的backbone（CP-VTON，PFAFN，SDAFN）的效果对比：\n图 7-2a 模型对比图\n图 7-2b 模型对比图\n7.2 评价指标 根据赛题方的要求，项目采用FID作为模型的评价指标。\n需要指明的是，FID指的是Fréchet Inception Distance。其基本思想是直接考虑生成数据和真实数据在feature层次的距离，不再额外的借助分类器，因此来衡量生成图片和真实图片的距离。FID 从原始图像的计算机视觉特征的统计方面的相似度来衡量两组图像的相似度，这种视觉特征是使用 Inception v3 图像分类模型计算的得到的。分数越低代表两组图像越相似，或者说二者的统计量越相似，FID 在最佳情况下的得分为 0.0，表示两组图像相同。\n下图为图像失真程度提高与FID分数之间关系：\n图 7-3 FID与图像失真程度关系\nFID的计算公式如下：\n下面的表格为模型的FID指标与一些SOTA模型的比较：\nmethods CP-VTON Cloth-Flow ACGPN SDAFN PF-AFN ours VITON(FID) 24.43 14.43 15.67 12.05 10.09 8.75 表 7-1 FID测试指标\n可以看出的是，我们的模型的FID较之目前先进的虚拟试衣模型，数据指标都是处于领先地位。\n7.3 模型大小分析 我们采用知识蒸馏的方法训练学生模型，在保留高质量生成效果的同时大大减少了模型的参数量，同时通过改变学生模型金字塔特征提取层的层数来调节模型大小，并且我们的模型不依赖于人体解析图等任何辅助信息，不需要其他模型作为辅助，工程化部署的大小只有我们自己一个模型的大小，大大减少了参数量，以下是我们不同精度格式模型的大小以及生成效果的FID指标：\n特征提取层为五时，pytorch模型原始大小为143MB，FID指标为9.084 特征提取层为四时，pytorch模型原始大小为104MB，FID指标为8.749，经过我们工程化处理，模型大小控制为53MB（精度格式fp16） 特征提取层为三时，pytorch模型原始大小为64MB，FID指标为9.05，经过我们的工程化处理后，模型大小控制为34.75MB（精度格式为fp16） 在工程化时我们同样进行了模型的int8静态量化，但int8静态量化后的模型生成效果失真较为严重，而特征提取层为三的fp16模型在控制模型大小的同时，仍然保留了高质量的生成效果，所以我们选用34.75MB的fp16模型作为我们最后部署的对象。\n7.4 推理速度分析 我们采用了一系列策略来加速我们的推导速度\n图 7-4 推理加速策略分析\n我们的模型为端到端单任务模型，避免了多任务模型计算开销大的缺点，加快了推导速度，推理时间只相当于PF-AFN一阶段的推理时间。\n我们的模型只需要将原始的衣服图像和人的图像作为输入，对数据进行预处理简单，数据预处理只需要将图片进行裁剪和均值归一化，模型推导的预处理时间几乎可以忽略不计，大大加快了我们的推理速度。\n我们使用onnxruntime推理引擎推导onnx模型，工程化后也大大加快了我们的推导速度，实现了推理不等待，效果立即出。\n推导程序使用多线程编程，最大化的利用cpu硬件条件，提高推理速度。\n我们部属的云服务器使用的是阿里云，其使用因特尔至强处理器，openvino推理框架对因特尔至强处理器有特殊的优化，相比onnxruntime推理引擎可以将推导时间缩短20%左右，我们尝试使用openvino推理框架重写推导程序部署在云服务器上，改善我们网页的使用体验（无忧工作室）\n8 项目总结 8.1 团队简介与团队文化 8.1.1 团队简介 团队五名成员皆是重点大学本科生，团队成员深知，团队分工情况与团队合作能力直接决定了一个项目或者一项工作的成功或者失败。 每一个成员可以根据自己能力的突出点去承担一部分工作。在每个责任块中，模糊上下级的概念，不存在领导与被领导的关系，而是集思广益、汇聚智慧的新团队合作模式。每个人都有责任义务去完成分内工作，并且在团队成员需要帮助时及时援助，也欢迎每个人提出自己的想法，大家对于不同的想法进行集中讨论，综合实践最后采用最优解法。 在整个工作开展过程中，我们团队自 2022 年 12 月至 2023 年 4 月始终坚持短期，中期，长期多种形式的组内交流会。确保贯穿项目始终能够全体成员进度步调统一，有新思想涌入并发生碰撞，不停审视反思团队近期执行状况，调整团队前进的方向。\n8.1.2 团队文化 团队给队伍取名为无忧工作室，首先是我们希望团队所研究的虚拟试衣实验能够切实地为未来虚拟试衣行业做出一定贡献，改善用户的在线购衣体验，让网上购衣不再困难忧心。其次，我们的团队是一个团结友爱的大家庭，不同专业的同学在团队中扮演着不同的角色，有不同的分工，我们共同面对困难，不放弃不退缩，想尽一切办法克服困难完成目标，正是这种团队协作精神，让我们的项目顺利进展，没有后顾之忧。\n团队LOGO以无忧工作室开头两个首字母的大写结合而成，寓意无忧工作室是一个紧密结合的整体，团队的成功离不开每个成员的辛苦付出，LOGO右侧以黄底衬出“无忧工作室”五个字，简洁明了，与开头字母相呼应。\n8.2 项目规划 8.2.1 进度计划 本项目在2022年12底立项组队，至2023年4月15日提交项目材料，总计约四个月时间。无忧工作室团队的具体进度安排如下表所示：\n项目阶段 起止时间 任务安排 项目选题阶段 2022.12.20-2022.1.5 赛题调研，结合团队优势选定赛题 技术选型阶段 2022.1.5-2022.2.1 阅读业内前沿算法相关论文，结合赛题选定技术路线 模型复现阶段 2022.2.5-2022.3.1 根据论文方法，优化模型结构并训练 模型测试阶段 2022.3.1-2022.3.10 优化提升模型性能，降低模型大小 web页面设计阶段 2023.2.20.1-2023.3.5 实现web页面的设计与代码编写 前后端本地部署阶段 2023.3.10-2023.3.20 前后端代码整合与测试，实现前后端的本地化部署 前后端服务器端部署 2023.3.20-2023.3.23 实现前后端的服务器端部署与测试 第一次阶段性总结 2023.3.23 对目前团队工作成果的总结回顾，给出作品后续优化方向 项目优化与文档收集 2023.3.23-2023.3.30 对总结提出的问题进行解决优化，收集团队汇总开发文档 文档编写与排版 2023.4.1-2023.4.5 完成项目文档初稿 文档修订与完善 2023.4.5-2023.4.10 修订完善文档初稿，完成开发文档 PPT编排与Web页面更新 2023.4.10-2023.4.14 设计实现展示PPT,在web页面上传项目文档 项目提交 2023.4.15 核验项目所有材料并提交 表 8-1 项目进度安排\n8.2.2 开发文档管理 在项目开发期间，团队共编写相关技术文档35篇，总字数超5万字。为实现开发共享与技术交流，团队采用在线工作台模式，形成文档共享知识库，打造体系化的知识管理，极大提高了项目开发和文档编写效率。\n8.2.3 团队分工 团队技术结构如下所示：\n图 8-1 团队技术结构图\n成员分工如下所示：\n姓名 职务 分工介绍 成员1 队长 团队配置，人员管理，项目进度控制，任务分配 组织小组会议，对关键项目节点（如模型确定）进行评审和决议 主要负责模型部分落地实现 负责各个项目阶段的评审 成员2 成员 1.参与模型技术选型与论文阅读 2.参与模型训练工作 3.参与数据集收集与扩充 4.负责项目web端部署；参与撰写项目文档 成员3 成员 参与模型技术选型与论文阅读 负责web前端页面设计与交互 参与编写web框架 成员4 成员 1参与模型技术选型与论文阅读 2.参与模型架构调整；负责项目文档设计与撰写 成员5 成员 负责web页面设计 负责页面动画、logo、及页面背景制作 负责ppt设计与展示 表 8-2 成员分工图\n8.3项目总结 从22年12月份组队到23年4月份项目提交，团队成员合作无间，分工明确，圆满完成了赛题所需工作，但难免有不足之处，我们的项目仍有以下可以改进和完善之处：\n模型大小 目前效果较好的模型为FP6截断版本，大小为56MB，仍有优化空间。可以通过以下方法进一步缩小模型：\n（1）剪枝：通过删除模型中的一些权重或神经元来减少模型大小。例如L1正则化、L2正则化、结构化剪枝等。\n（2）量化：将模型中的浮点数参数转换为较小的整数，从而减少模型大小。这种方法可以通过使用一些量化算法来实现，例如线性量化、非线性量化、混合精度量化等。\n（3）低秩分解：通过将卷积层或全连接层分解为多个较小的矩阵来减少模型大小。这种方法可以通过使用一些低秩分解算法来实现，例如SVD分解、CP分解、Tucker分解等。\n模型准确率 （1）增加训练数据量，可以通过数据增强的方式来实现。\n（2）调整模型的超参数，学习率、batch size等来调整模型性能。\n（3）在模型大小与准确率之间取得较好的平衡。\n就目前情况而言，虚拟试衣的应用场景主要是在线电商或数字营销，提升用户感官体验和交互体验。此外，虚拟试衣还可以应用于展厅、展馆、大型商场、超市等场景，吸引流量，快速试衣，让顾客体验到新颖高科技的购物模式，也节省购物时间。在未来，团队会尝试将该项目多方应用结合，助力元宇宙发展，使其与日常生活的融入更加贴近。\n9 参考文献 Bertiche, H., Madadi, M., Escalera, S.: Cloth3d: clothed 3d humans. In:European Conference on Computer Vision. pp. 344–359. Springer (2020)\nBhatnagar, B.L., Tiwari, G., Theobalt, C., Pons-Moll, G.: Multi-garment net: Learning to dress 3d people from images. In: Proceedings of the IEEE/CVF international conference on computer vision. pp. 5420–5430 (2019)\nChang, A.X., Funkhouser, T., Guibas, L., Hanrahan, P., Huang, Q., Li, Z.,Savarese, S., Savva, M., Song, S., Su, H., et al.: Shapenet: An information-rich 3d model repository. arXiv preprint arXiv:1512.03012 (2015)\nChoi, S., Park, S., Lee, M., Choo, J.: Viton-hd: High-resolution virtual try-on via misalignment-aware normalization. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 14131–14140 (2021)\nChopra, A., Jain, R., Hemani, M., Krishnamurthy, B.: Zflow: Gated appearance flow-based virtual try-on with 3d priors. In: Proceedings of the IEEE/CVF InternationalConference on Computer Vision. pp. 5433–5442 (2021)\nDong, H., Liang, X., Shen, X., Wang, B., Lai, H., Zhu, J., Hu, Z., Yin, J.: Towards multi-pose guided virtual try-on network. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 9026–9035 (2019)\nDuchon, J.: Splines minimizing rotation-invariant semi-norms in sobolev spaces. In:Constructive theory of functions of several variables, pp. 85–100. Springer (1977)\nFeng, Y., Wu, F., Shao, X., Wang, Y., Zhou, X.: Joint 3d face reconstruction and dense alignment with position map regression network. In: Proceedings of the European conference on computer vision (ECCV). pp. 534–551 (2018)\nGe, C., Song, Y., Ge, Y., Yang, H., Liu, W., Luo, P.: Disentangled cycle consistency for highly-realistic virtual try-on. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 16928–16937 (2021)\nGe, Y., Song, Y., Zhang, R., Ge, C., Liu, W., Luo, P.: Parser-free virtual try-on via distilling appearance flows. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 8485–8493 (2021)\nGong, K., Liang, X., Zhang, D., Shen, X., Lin, L.: Look into person: Self-supervised structure-sensitive learning and a new benchmark for human parsing. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 932–940 (2017)\nGoodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S.,Courville, A., Bengio, Y.: Generative adversarial nets. Advances in neural informationprocessing systems 27 (2014)\nG¨uler, R.A., Neverova, N., Kokkinos, I.: Densepose: Dense human pose estimation in the wild. In: Proceedings of the IEEE conference on computer vision and patternrecognition. pp. 7297–7306 (2018)\nHan, X., Hu, X., Huang, W., Scott, M.R.: Clothflow: A flow-based model for clothed person generation. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 10471–10480 (2019)\nHan, X., Wu, Z., Wu, Z., Yu, R., Davis, L.S.: Viton: An image-based virtual try-on network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 7543–7552 (2018)\nHe, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In:Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR) (June 2016)\n","date":1709027917,"headings":[{"anchor":"1-引言","title":"1 引言"},{"anchor":"2-项目概述","title":"2 项目概述"},{"anchor":"21-项目背景","title":"2.1 项目背景"},{"anchor":"22-项目目标","title":"2.2 项目目标"},{"anchor":"23-项目价值","title":"2.3 项目价值"},{"anchor":"24-作品简介","title":"2.4 作品简介"},{"anchor":"25-创新点与优势","title":"2.5 创新点与优势"},{"anchor":"4-模型架构","title":"4 模型架构"},{"anchor":"41-相关工作","title":"4.1 相关工作"},{"anchor":"411-虚拟试衣技术的发展历史","title":"4.1.1 虚拟试衣技术的发展历史"},{"anchor":"412-空间变换模块","title":"4.1.2 空间变换模块"},{"anchor":"413-注意力机制","title":"4.1.3 注意力机制"},{"anchor":"431-金字塔特征提取器","title":"4.3.1 金字塔特征提取器"},{"anchor":"432-级联流估计","title":"4.3.2 级联流估计"},{"anchor":"433-浅编码器与解码器","title":"4.3.3 浅编码器与解码器"},{"anchor":"44-模型训练","title":"4.4 模型训练"},{"anchor":"441-训练平台","title":"4.4.1 训练平台"},{"anchor":"442-数据集","title":"4.4.2 数据集"},{"anchor":"443-训练过程","title":"4.4.3 训练过程"},{"anchor":"5-工程化实现","title":"5 工程化实现"},{"anchor":"52-模型转换","title":"5.2 模型转换"},{"anchor":"521-pth模型的后处理","title":"5.2.1 pth模型的后处理"},{"anchor":"522模型的导出","title":"5.2.2模型的导出"},{"anchor":"523-导出代码","title":"5.2.3 导出代码"},{"anchor":"53-模型量化","title":"5.3 模型量化"},{"anchor":"531-fp16量化","title":"5.3.1 Fp16量化"},{"anchor":"532-int8量化","title":"5.3.2 Int8量化"},{"anchor":"54-模型推断","title":"5.4 模型推断"},{"anchor":"6-模型部署","title":"6 模型部署"},{"anchor":"61-web部署整体框架图","title":"6.1 web部署整体框架图"},{"anchor":"62-web前端部署","title":"6.2 web前端部署"},{"anchor":"621-目录结构与文件","title":"6.2.1 目录结构与文件"},{"anchor":"622-项目构建与打包","title":"6.2.2 项目构建与打包"},{"anchor":"63-web后端部署","title":"6.3 web后端部署"},{"anchor":"64-项目服务器环境部署","title":"6.4 项目服务器环境部署"},{"anchor":"71-实际效果图展示","title":"7.1 实际效果图展示"},{"anchor":"72-评价指标","title":"7.2 评价指标"},{"anchor":"73-模型大小分析","title":"7.3 模型大小分析"},{"anchor":"74-推理速度分析","title":"7.4 推理速度分析"},{"anchor":"8-项目总结","title":"8 项目总结"},{"anchor":"81-团队简介与团队文化","title":"8.1 团队简介与团队文化"},{"anchor":"811-团队简介","title":"8.1.1 团队简介"},{"anchor":"812-团队文化","title":"8.1.2 团队文化"},{"anchor":"82-项目规划","title":"8.2 项目规划"},{"anchor":"821-进度计划","title":"8.2.1 进度计划"},{"anchor":"822-开发文档管理","title":"8.2.2 开发文档管理"},{"anchor":"823-团队分工","title":"8.2.3 团队分工"},{"anchor":"83项目总结","title":"8.3项目总结"},{"anchor":"9-参考文献","title":"9 参考文献"},{"anchor":"span-stylebackgroundfff88f3-系统设计span","title":"3 系统设计"},{"anchor":"span-stylebackgroundfff88f42-模型总体架构span","title":"4.2 模型总体架构"},{"anchor":"span-stylebackgroundfff88f43-学生模型sdafn_plus分析span","title":"4.3 学生模型SDAFN_plus分析"},{"anchor":"span-stylebackgroundfff88f51-工程化实现的整体框架span","title":"5.1 工程化实现的整体框架"},{"anchor":"span-stylebackgroundfff88f524-bug修复span","title":"5.2.4 Bug修复"},{"anchor":"span-stylebackgroundfff88f7-模型测试span","title":"7 模型测试"}],"kind":"page","lang":"zh-hans","summary":"","title":"项目详细方案","url":"/%E8%99%9A%E6%8B%9F%E8%AF%95%E8%A1%A3/%E9%A1%B9%E7%9B%AE%E8%AF%A6%E7%BB%86%E6%96%B9%E6%A1%88/","year":"2024"},{"content":" “无忧 Try-On”虚拟试衣系统\n项目概要介绍\nVersion 1.0\n2023.4.15\nWritten By 无忧工作室\n1 前言 随着元宇宙概念的火爆以及虚拟数字技术的大迸发，在人们购买力逐步上升的今天，世界看到了“虚拟试衣”技术未来巨大的发展空间。根据 CB Insights 的预测，全球虚拟试衣间的市场规模将从 2020 年的 34 亿美元，增长至 2030 年的 193 亿美元。虚拟试衣技术在不断地发展中和突破中，在电子商业普及和移动端用户迅速增长的阶段，如果虚拟试衣系统能提高其真实性以及对不同衣物的贴合度，将在网络时代获得巨大的市场。基于赛题方要求，我们团队开发了符合要求的虚拟试衣系统。下文中，我们将会从创意、功能、特色、开发工具与技术、应用对象以及应用环境等多个维度对于相关成果进行阐述。\n2 创意描述 现有的虚拟试衣模型在生成真实的结果和细节方面取得了较大进展。然而，这仍是一项具有挑战性的任务，特别是在人体姿态复杂以及生成的图像与原有图像存在较大变形的情况下，大多数现有方法仍然存在错位或明显的生成痕迹。为解决以上问题，我们团队设计了基于SDAFN与PF-AFN的虚拟试衣系统。该系统不需要人体解析图的引入，且为单阶段模型，部署难度大大降低；通过利用知识蒸馏的方法，在保持高质量虚拟试衣图像生成的同时，减少了模型计算量和参数量，实现了模型轻量化。\n3 功能简介 团队使用开源数据集VITON及在此基础上进行预处理得到的VITON_plus数据集，建立虚拟试衣算法模型，并完成模型训练、优化、工程化、部署等工作，最终产出一个本地可执行程序以及部署在服务器支持试用的Web界面(无忧工作室)，同时测试了模型性能以及对模型的试穿效果进行了评估。对于Web界面与本地化可执行程序，我们考虑到用户使用的便捷性，设计了简洁的用户界面，仅仅需要按照对应按钮点击进行图片上传，即可完成虚拟试衣的操作。\n图 1 前端首页面\n图 2 试衣页面\n图 3 本地化可执行程序\n4 特色综述 我们的模型为端到端单任务模型，避免了多任务模型计算开销大的缺点，加快了推导速度。\n我们的模型不需要依赖人体解析图，人体姿态估计图等任何辅助信息，只需要将人的图片和衣服的图片作为输入。\n使用知识蒸馏的方法，我们的模型在保持高质量虚拟试衣图像生成的同时，减少了模型计算量和参数量，实现了模型轻量化。\n团队通过数据增强的方式，扩充了模型训练的数据集，提高了模型的鲁棒性。\n模型性能优异，在FID等关键指标中取得领先得分，并在衣物细节保留、人物身体拟合和边缘识别等传统虚拟试衣难点取得较好表现。\n5 开发工具与技术 6 应用对象 虚拟试衣应用对象主要是消费者，也包括服装品牌和零售商。对于消费者来说，虚拟试衣应用可以帮助他们在线上购买时更好的选择尺码和款式，并且可以节省时间和物流成本。对于服装品牌和零售商来说，虚拟试衣能够提升顾客购买体验和增加销售额。\n7 应用环境 网上购物体验：虚拟试衣可以让消费者在网上购物时直接在网站上试穿衣服，评估是否适合自己的风格和尺码\n个性化定制：虚拟试衣技术可以提供更好的个性化定制服务，消费者可以在虚拟试衣应用中输入自己的体型数据，量身打造符合自己尺码和风格的服装。\n生产设计：设计师可以利用虚拟试衣技术，通过三维模拟试穿，评估和改进服装的设计和版型，提高生产效率和质量。\n8 结语 从22年12月份组队到23年4月份项目提交，团队成员合作无间，分工明确，圆满完成了赛题所需工作，但难免有不足之处，我们的项目仍有以下可以改进和完善之处：\n模型大小 目前效果较好的模型为FP6截断版本，大小为56MB，仍有优化空间。可以通过剪枝、量化、低秩分解等方法进一步缩小模型。\n模型准确率 目前模型准确率仍有提升空间，可以通过增加训练数据量、调整超参数与模型大小等方式进一步提高。\n在未来，团队会尝试将该项目多方应用结合，助力元宇宙发展，使其与日常生活的融入更加贴近。\n","date":1709025933,"headings":[{"anchor":"1-前言","title":"1 前言"},{"anchor":"2-创意描述","title":"2 创意描述"},{"anchor":"3-功能简介","title":"3 功能简介"},{"anchor":"4-特色综述","title":"4 特色综述"},{"anchor":"5-开发工具与技术","title":"5 开发工具与技术"},{"anchor":"6-应用对象","title":"6 应用对象"},{"anchor":"7-应用环境","title":"7 应用环境"},{"anchor":"8-结语","title":"8 结语"}],"kind":"page","lang":"zh-hans","summary":"","title":"项目介绍","url":"/%E8%99%9A%E6%8B%9F%E8%AF%95%E8%A1%A3/%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/","year":"2024"},{"content":"【A16】虚拟试衣算法【万兴科技】 1. 命题方向 图像生成\n2. 题目类别 计算机类\n3. 题目名称 虚拟试衣算法\n4. 背景说明 随着在线购物重要性的增加 ， 一 项允许客户虚拟试穿衣服的技术有望丰富客 户 的体验 。虚拟试穿任务旨在将人身上的衣服变成给定的服装产 品 。大多数基于 图像的虚拟试穿方法存在试穿结果变形 、部分区域出现伪影或者部分区域不完整 的情况 ， 因此应用到实际产品端具有较强的挑战性。\n5. 项目说明 【问题说明】\n虚拟试衣指根据输入的人物图像和衣服图像，实现衣服的试穿，效果如下图所示 ，在完成衣服试穿后不会出现衣服不完整 ，伪影等情况。\n将虚拟试衣技术应用到实际产品中时往往会存在一些问题 ，因此站在用户角度对虚拟试衣技术总结了以下四点期望：\n( 1 ) 可以实现任意人物的虚拟试衣 ，因为有些人物版权问题 ，或者展示效果上的需求 ，部分用户希望能够让自己的模特试穿特定的衣服；\n(2) 试穿衣服支持的种类 ，包括短袖 ，衬衫，外套等 ，支持的种类越多越好；\n(3) 试穿效果要确保不存在有明显瑕疵 ，部分破损 ，伪影等情况；\n( 4) 算法要求正面和背面人物的虚拟换衣 ，对于长头发人群的背身虚拟换衣\n需要额外优化。\n6. 任务要求 【开发说明】\n本项目要求参赛者设计技术方案流程 ， 以及完成虚拟试衣模型的训练 、优化 、 工 程化等工 作 ， 最终产生 一 个支持用户上传人物图像和衣服图像输出试穿后的结 果的可执行程序( .exe)或部署在服务器的web端体验平台。\n【技术要求与指标】\n【提交材料】\n【任务清单】\n【开发工具与数据接口】\n开发工具： 开发工具及平台不限。\n7. 评分要点 内容 分值 初赛评分表 算法创新 算法创新描述详细、清晰，不限于数据预处理方法、模型改进、损失函数设计、优化器设计、主体边缘后处理以及模型加速等技术的创新。 20分 实施分案 整个项目的实施进度安排合理，在模型改进和模型部署等阶段工作创新合理清晰，突出算法解决的难点；算法调研、训练、优化、工程化落地周期安排恰当。 30分 算法实现与交付 算法设计方案可行性高，算法的性能和效果与技术指标相匹配，项目完成度好。项目相关的知识产权证明（包括但不限于：专利证书、著作证书等） 30分 项目展示 提交文档完整性、结构清晰合理、逻辑顺畅、文笔精炼。 20分 赛题评分要点见附件 一： A 类企业命题初赛统一评分标准。\n除此之外 ， 企业还重点关注以下几个方面：\n( 1 ) 算法的创新性： 算法创新描述详细 、 清晰 ，不限于数据预处理方法 、模 型改进 、损失函数设计 、优化器设计 、 主体边缘后处理以及模型加速等技术的创新。\n( 2 ) 算法的实施过程： 整个项目的实施进度安排合理 ，在模型改进和模型部署等阶段工作创新合理清晰 ， 突出算法解决的难点；算法调研 、训练 、优化 、工程化落地周期安排恰当。\n( 3 ) 算法的性能/效果：算法设计方案可行性高 ， 算法的性能和效果与技术指标相匹配 ，项目完成度好。\n","date":1709025501,"headings":[{"anchor":"1-命题方向","title":"1. 命题方向"},{"anchor":"2-题目类别","title":"2. 题目类别"},{"anchor":"3-题目名称","title":"3. 题目名称"},{"anchor":"4-背景说明","title":"4. 背景说明"},{"anchor":"5-项目说明","title":"5. 项目说明"},{"anchor":"6-任务要求","title":"6. 任务要求"},{"anchor":"7-评分要点","title":"7. 评分要点"},{"anchor":"a16虚拟试衣算法万兴科技","title":"【A16】虚拟试衣算法【万兴科技】"}],"kind":"page","lang":"zh-hans","summary":"","title":"赛题要求","url":"/%E8%99%9A%E6%8B%9F%E8%AF%95%E8%A1%A3/%E8%B5%9B%E9%A2%98%E8%A6%81%E6%B1%82/","year":"2024"},{"content":"一、I/O系统基本概念 外部设备 输入设备 鼠标、键盘 输出设备 显示器 种类 阴极射线管显示器（CRT） 电子枪、偏转线圈、荧光粉等组成 液晶显示器（LCD） 利用液晶分子的光电效应 发光二极管显示器（LED） 通过发光二极管发光来显示 参数 屏幕大小 以对角线长度表示 分辨率 屏幕上像素点的个数 灰度级 表示一个颜色需要多少二进制位数 刷新频率 单位时间内更新屏幕的次数 显示存储器（VRAM） 容量=分辨率*灰度级位数（2010） 带宽=容量*刷新频率（2010） 打印机 针式打印机 喷墨式打印机 激光式打印机 外部存储器 磁表面存储器 固态硬盘（SSD） 光盘存储器 二、I/O接口 1. I/O接口的功能 进行地址译码和设备选择、实现主机和外设的通信联络控制、实现数据缓冲、信号格式转换、传送控制命令和状态信息 2. I/O接口的基本结构 （状态端口和控制端口可以合用一个寄存器） 3. I/O接口的类型 并行接口/串行接口 程序查询接口/中断接口/DMA接口 可编程接口/不可编程接口 4. I/O端口及其编址 概念 接口电路中可被CPU直接访问的一组寄存器（2014） I/O指令实现的数据传输通常发生在通用寄存器和I/O端口之间（2017） 编址 统一编址（存储器映射） 使用统一的访存指令来完成输入输出操作（2014） 端口有较大的编址空间但内存容量变小 统一编址下的I/O地址可以在地址空间的任何地方 靠不同的地址码区分存储单元和I/O设备 独立编址（I/O映射） 使用专门的输入输出指令（IN/OUT） 靠不同的指令区分存储单元和I/O设备 三、I/O方式 1. 程序查询方式 工作流程 CPU向I/O接口发出命令字，启动I/O设备 CPU不断从接口读取状态信息，直到外设准备就绪 传输一次数据，修改地址和计数器参数 反复执行直到计数器为0 特点 一段时间内CPU只能和一个外设交换信息，CPU要花费大量时间查询和等待 2. 程序中断方式 中断原理 （CPU与外设并行工作示意图） 中断优先级 中断源的识别和判优 软件查询 原理 按照中断优先顺序依次查询哪个设备有中断请求并转到第一个查询到的中断服务程序去执行 特点 可以改变软件的查询顺序来改变中断响应优先级，比较灵活；但查询速度较慢 硬件判优 原理 根据中断判优电路和编码器得到所有未被屏蔽的中断请求中具有最高响应优先权的中断源 涉及到的概念 中断向量 中断服务程序的首地址 中断向量地址 每个中断向量所在的地址 中断向量表 所有中断向量存放在一个表中称为中断向量表 中断类型号 每个中断向量在中断向量表中的位置或编号 中断优先级 分类 中断响应优先级 由查询程序或判优电路决定的优先权（不可更改），反映的是多个中断同时请求时选择哪个先被相应 中断处理优先级 由各自的中断屏蔽字来动态设定（可以更改），反映了本中断与其它中断之间的处理优先关系（2020） 优先顺序 不可屏蔽中断\u0026gt;内部异常\u0026gt;可屏蔽中断（2020） 内部异常中，硬件故障\u0026gt;软件故障 DMA中断\u0026gt;I/O中断（2020） I/O中断中，高速设备\u0026gt;低速设备，输入设备\u0026gt;输出设备，实时设备\u0026gt;普通设备 中断屏蔽字 每个中断源都有屏蔽触发器，所有屏蔽触发器组合在一起构成中断屏蔽字寄存器，其中的内容称为屏蔽字 “1”表示屏蔽，“0”表示正常申请（每个中断源都要屏蔽自身）（2011） 例：A\u0026gt;B\u0026gt;C\u0026gt;D C的屏蔽字为0011 中断响应的三个条件 CPU处于“开中断”状态（2018、2021） 至少有一个未被屏蔽的中断请求（2021） 当前指令刚执行完（2018） 中断过程（经常考） 中断响应（硬件实现） 关中断 将中断允许标志置为不允许状态，此时可屏蔽掉所有可屏蔽中断请求 保存断点 将PC和PSW送入栈或特殊寄存器 识别中断源 取得中断服务程序首地址和初始 PSW分别送PC和PSWR 中断处理（软件实现） 保护现场（用户可见的工作寄存器的内容）和屏蔽字 开中断 执行中断服务程序 关中断\u0026mdash;-恢复现场和屏蔽字\u0026mdash;-开中断\u0026mdash;-中断返回 3. DMA方式 基本概念 全名：直接存储器存取。在外设与内存之间直接开设一条数据通道，由DMA控制器控制数据传输，数据不再经过CPU 适用于磁盘、显卡、声卡、网卡等高速设备大批量数据的传送（鼠标键盘适合中断方式） 数据流向：内存\u0026ndash;数据总线\u0026ndash;DMA控制器\u0026ndash;外设 DMA传送方式 CPU停止法 CPU脱离总线停止访问主存 周期挪用法 CPU让出一个总线事务周期，DMA控制器挪用一个主存周期来访问主存传输一个数据缓冲寄存器的内容（2020） 交替分时访问法 每个存储周期分为两个时间片，一个给CPU，一个给DMA控制器 DMA传送过程（经常考） 图示 步骤 预处理 CPU完成一些准备工作后执行原来程序，I/O设备准备好收发数据后向DMA控制器发出DMA请求信号，DMA控制器向CPU发出总线请求信号（申请总线使用权） 数据传输 DMA控制器占用总线后进行数据传输（此阶段完全由DMA控制器控制，CPU不可以访问主存储器）（2018、2020） 后处理 数据传输完成后DMA控制器向CPU发出中断请求并转入中断服务程序，做一些数据校验等后续处理工作（2020） 中断和DMA方式的比较 （经常涉及到） 四、考研大题 出题年份：2009、2012、2016、2018\n出题方向\n程序查询 查询的最大间隔 中断 给出主频、CPI、中断处理程序指令个数、数据传输速率、求CPU利用率 能否使用中断？否，因为CPU来不及处理，数据可能丢失 中断过程：设备把数据送给缓冲寄存器\u0026mdash;-I/O接口发出中断请求\u0026mdash;-CPU响应并执行中断处理程序 DMA 给出主频、CPI、中断处理程序指令个数、数据传输速率、求CPU利用率 DMA请求优先级高于CPU，原因是数据不及时传送可能丢失（2012大题） 补充（异步串行通信）\n","date":1708779471,"headings":[{"anchor":"1-io接口的功能","title":"1. I/O接口的功能"},{"anchor":"1-程序查询方式","title":"1. 程序查询方式"},{"anchor":"2-io接口的基本结构","title":"2. I/O接口的基本结构"},{"anchor":"2-程序中断方式","title":"2. 程序中断方式"},{"anchor":"3-dma方式","title":"3. DMA方式"},{"anchor":"3-io接口的类型","title":"3. I/O接口的类型"},{"anchor":"4-io端口及其编址","title":"4. I/O端口及其编址"},{"anchor":"一io系统基本概念","title":"一、I/O系统基本概念"},{"anchor":"三io方式","title":"三、I/O方式"},{"anchor":"二io接口","title":"二、I/O接口"},{"anchor":"四考研大题","title":"四、考研大题"},{"anchor":"外部设备","title":"外部设备"}],"kind":"page","lang":"zh-hans","summary":"","tags":["计算机组成原理"],"title":"第七章：输入输出系统","url":"/408/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E7%AC%AC%E4%B8%83%E7%AB%A0%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B3%BB%E7%BB%9F/","year":"2024"},{"content":"六、总线概述 1. 总线的基本概念 同一时刻只允许有一个部件向总线发出信息 主设备是指获得总线控制权的设备；从设备是指被主设备访问的设备且只能被动响应各种总线命令 2. 总线的分类 片内总线 芯片内部的总线（寄存器之间、寄存器与ALU之间） 系统总线 数据总线 特点 双向传输 位数与机器字长、存储字长有关 传输内容 数据、中断向量、状态信息、命令字（2011、2012） 地址总线 特点 单向传输 位数与主存地址空间的大小有关 传输内容 要访问的地址 控制总线 特点 对于特定的一条控制总线传输是单向的 但对于所有控制总线来看，传输是双向的 传输内容 读写、请求、响应、时钟信号、复位信号 I/O总线 连接中低速的I/O设备并通过I/O接口与系统总线相连接，目的是将低速设备与高速总线相分离（USB、PCI） 通信总线 同步总线、异步总线 下面6.2的总线定时细讲 串行总线、并行总线 串行总线抗干扰能力强，适合远距离传输 并行总线抗干扰能力弱，但在近距离传输时速度很快 串行并不一定比并行慢，现在的发展趋势是并行传输速度\u0026laquo;串行传输速度（2016） 3. 系统总线的结构 单总线结构 双总线结构 主存总线+I/O总线 多总线结构 主存总线+I/O总线+DMA总线 4. 常见的总线标准 （PCI并行、PCI-E串行、USB串行）（真题中涉及到的：ISA、EISA、VESA、APG、USB、PCI-E） 5. 总线的性能指标 总线传输周期 一次总线操作所需要的时间（包括申请阶段、寻址阶段、传输阶段和结束阶段）（经常考） 总线工作频率 为总线传输周期的倒数（经常考）（现在有些总线一个时钟周期可以传输2次或4次数据） 总线时钟周期 也就是机器的时钟周期 总线时钟频率 为总线时钟周期的倒数 总线宽度 总线上同时能够传输的数据位数 总线带宽 可以理解为总线的最大数据传输率 总线带宽=数据传输速率=总线频率*总线宽度=单位时间内传输的二进制信息位数（经常考） 总线传送方式 非突发传输 每次先传输地址，再传输数据 突发传输 每次传输一次地址，再传输多个数据（2014） 可以提高同步总线数据传输率（2016、2018） 二、总线事务和定时 1. 总线事务 请求阶段-仲裁阶段-寻址阶段-传输阶段-释放阶段 2. 总线定时 同步式 由统一的时钟信号进行协调，而不能由各设备提供（2015） 提高同步总线带宽措施 提高时钟频率、增加数据线宽度、支持突发传输、拆分总线事务、不采用分时复用（2018） 优点 控制逻辑简单、传输速度较快 缺点 总线定时以最慢设备所花时间为标准，所以只适合连接速度相差不大的设备 由于时钟偏移问题总线的长度不能过长 异步式 没有统一的时钟，也没有固定的时间间隔，靠“握手信号”实现定时控制 特点：灵活、接口逻辑复杂、对噪声敏感、传输速度较慢 分类 不互锁（速率最快，最不可靠）（2015） 请求\u0026mdash;-撤销请求 半互锁（介于中间） 请求\u0026mdash;-回答\u0026mdash;-撤销请求 全互锁（速率最慢，最可靠）（2015） 请求\u0026mdash;-回答\u0026mdash;-撤销请求\u0026mdash;-撤销回答 图示 半同步 按照统一的时钟信号（同步特点），增加一条“等待”响应信号从而使不同速度的模块和谐工作（异步特点）（2015） 三、基于总线的互连结构（补充） 1. 图示 （总线之间需要通过桥接器相连接） 2. 总线细节 前端总线 速度最快的总线 QPI总线 基于包的串行传输总线，连接不同CPU内核 双向传输，每个时钟周期传输两次（2020） 带宽=每秒传输次数_每次传输的有效数据_2（2020） 存储器总线 注意多通道存储器，计算时带总带宽=单个通道宽*n（2019） I/O总线 第一代 XT、ISA、EISA、VESA（这些总线早已被淘汰，了解即可） 第二代 PCI、AGP、PCI-X 第三代 PCI-Express 采用串行传输方式（2017） PCI-Express*n表示有n个通路，每个通路有两个差分信号线可以同时发送和接收数据 在发送和接收时每个字节的数据被转换为10位信息被传输 总线带宽=每个方向接收或发送速率_2_通路数/10 ","date":1708779171,"headings":[{"anchor":"1-图示","title":"1. 图示"},{"anchor":"1-总线事务","title":"1. 总线事务"},{"anchor":"1-总线的基本概念","title":"1. 总线的基本概念"},{"anchor":"2-总线定时","title":"2. 总线定时"},{"anchor":"2-总线的分类","title":"2. 总线的分类"},{"anchor":"2-总线细节","title":"2. 总线细节"},{"anchor":"3-系统总线的结构","title":"3. 系统总线的结构"},{"anchor":"4-常见的总线标准","title":"4. 常见的总线标准"},{"anchor":"5-总线的性能指标","title":"5. 总线的性能指标"},{"anchor":"三基于总线的互连结构补充","title":"三、基于总线的互连结构（补充）"},{"anchor":"二总线事务和定时","title":"二、总线事务和定时"},{"anchor":"六总线概述","title":"六、总线概述"}],"kind":"page","lang":"zh-hans","summary":"","title":"第六章：系统总线","url":"/408/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E7%AC%AC%E5%85%AD%E7%AB%A0%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BA%BF/","year":"2024"},{"content":"一、CPU的功能和基本结构 1. CPU的功能 指令控制 操作控制 时间控制 数据加工 中断处理 2. CPU的基本结构 组成 运算器 算数逻辑单元 进行算术逻辑运算 暂存寄存器 用于暂存从主存读来的数据 累加寄存器 暂存ALU运算的结果，可以作为加法运算的一个输入端 通用寄存器组 存放操作数和各种地址信息（不存放指令） 程序状态字寄存器 保存各种运行过程中产生的状态信息 移位器 对操作数或者运算结果进行移位运算 计数器 控制乘除运算的操作步数 控制器 程序计数器PC 取指阶段（PC）\u0026ndash;\u0026gt;（MAR）后便能+1 执行转移指令时PC值不一定修改（条件不满足） 在执行无条件转移指令过程中，PC值改变两次 PC+1可以自己完成，也可以通过ALU完成 指令寄存器 保存当前正在执行的指令 指令译码器 对操作码字段进行译码并向控制器提供特定的操作信号 存储器地址寄存器 存放要访问的主存单元的地址 存储器数据寄存器 存放要写入主存或读出主存的信息 时序系统 用于产生各种信号，它们都由统一时钟（CLOCK）分频得到 微操作信号发生器 根据IR、PSW和时序信号产生各种控制信号 二、指令执行过程 1. 各种周期的关系 机器周期通常以存取周期为基准，存储字长等于指令字长时取指周期也可视为机器周期 CPU周期也就是机器周期，各个机器周期的长度不一定相等 2. 指令周期的数据流 取指周期 （PC）\u0026ndash;\u0026gt;MAR; M（MAR）\u0026ndash;\u0026gt;MDR; （MDR）\u0026ndash;\u0026gt;IR; （PC）+1\u0026ndash;\u0026gt;PC 间指周期 Ad（IR）\u0026ndash;\u0026gt;MAR; M（MAR）\u0026ndash;\u0026gt;MDR（不需要经过PC） 执行周期 数据在ALU运算的表示：（X）+（Y）\u0026ndash;\u0026gt;Z; （Z）\u0026ndash;\u0026gt;某个寄存器 中断周期 保存断点（（PC）\u0026ndash;\u0026gt;M（SP-1）），中断向量\u0026ndash;\u0026gt;PC （书写标准） 3. 指令执行方案 单周期CPU 所有指令采用相同的时钟周期完成，以花费时间最长的指令的时间为准，因此处理器时钟频率较低（2016） 每条指令执行过程中控制信号不变（2016） 同一个功能部件不能被重复使用（2016） 不能使用单总线结构数据通路（2016） CPI=1（2020） 指令串型执行，不需添加临时寄存器存放中间结果 （袁春风课本上的结构图，了解即可） 多周期CPU 可以选用不同个数的时钟周期来完成不同指令的执行过程 每条指令分成多个阶段 需要添加临时寄存器存放指令执行的中间结果 同一个部件可以在不同的阶段被重复使用 4. 大题 注意存储器控制信号（MemR、MemW）、算术逻辑单元控制信号（ALUop、add） 操作码+源操作数+目的操作数，目的操作数用来存放运算结果 ADD (R1),R2：R1寄存器间接寻址，R2寄存器直接寻址 书写指令功能时，一般为B\u0026lt;\u0026ndash;（A），即A的内容存放到B中 自增型寄存器间接寻址，意思是寻址完了后，把寄存器中的数值+1 加法器和ALU不是一个东西，2015年考察了MUX（多路选择器）和ALU输出端的三态门 三、数据通路的功能和基本结构 1. CPU组成（袁春风书补充） 数据通路 定义：指令执行过程中数据所经过的路径以及部件 包括：ALU、通用寄存器、状态寄存器、Cache、MMU、浮点运算逻辑、异常和中断处理逻辑（2017、2021） 元件分类 组合逻辑元件 定义：输出只取决于当前的输入 包括：多路选择器、加法器、算术逻辑部件、译码器等 （时序）状态元件 定义：具有存储功能 包括：暂存寄存器、通用寄存器组等 控制部件 主要是指令译码器 2. 数据通路的基本结构 CPU内单总线 图示 经常考 特点 一个时钟周期只能执行一个操作，一个时钟周期内控制信号不会发生改变（2016） 所有寄存器输入端、输出端都接到一条公共通路上 ALU一端与总线直接连接，另一端必须通过暂存器与总线连接 CPU内三多总线 几乎不会考，略过 专用数据通路 几乎不会考，略过 四、控制器的功能和工作原理 1. 硬布线 别名：组合逻辑电路、有限状态机。电路原理几乎不考，了解即可 CU的输入 指令译码、时钟信号、状态标志 2. 微程序 每个时钟执行一条微指令；每个指令周期执行一条微程序 微指令 微指令组成 微操作码字段：产生各种操作控制信号 微地址码字段：控制下一条要执行的微指令的地址 编码方式 直接编码 一位对应一个微命令，微操作码的长度与所有微命令的个数相当，无需译码 字段直接编码 微操作之间存在两种关系：相容（能同时进行）个互斥（不能同时进行） 将微指令分为若干字段，互斥的在同一段，相容的在不同段（2012） 每段还要留出一个状态表示不发出微命令（2012） 一条微指令中最多可同时发出的微操作数就是微命令字段的个数 间接编码 一个字段的微命令需要另一个字段的微命令解释（了解即可） 后继地址形成（按袁春风书） 计数器法 使用一个专门的微程序计数器uPC 顺序执行时，uPC+1\u0026ndash;\u0026gt;uPC；转移执行时在当前微指令后添加一条转移微指令 断定法 在微指令中明确指定下一条微指令地址（2014） 增加了微指令的长度，影响控制存储器的有效利用 微指令的格式 水平型 微指令长，微程序短、执行速度快、编写麻烦、一条指令对应几种并行操作 垂直型 微指令短、微程序长、执行速度慢、编写简单、一条指令对应一种基本操作 混合型 3. 硬布线和微程序的比较 （2009） 五、中断和中断机制（按袁春风书） 1. 中断（极其重要） 分类 内部异常 根据发生原因分 硬故障中断 电源掉电、存储器线路错误（硬件线路出现异常） 程序性异常 溢出、地址越界、整数除零、非法指令、时间片中断、单步跟踪（CPU执行某个指令引起） 根据异常的报告和返回方式 故障 非法操作码、缺段缺页、整数除零（不能回到原断点执行必须终止）、保护错 陷入 程序调试断点、系统调用（用户程序的I/O请求）、条件自陷指令（返回到自陷指令的下一条指令执行） 终止 电源掉电、线路故障等（程序无法执行只能终止，不是由特定指令引起而是随机发生的） 中断（外中断） I/O设备中断、定时器到时、时钟中断、打印机缺纸、键盘缓冲满（这些事件与执行的指令无关） 其它 内部异常的产生与当前指令的执行有关，而外部中断的产生与当前指令的执行无关 内部异常的检测发生在指令执行过程中，外部中断的检测发生在每条指令执行结束时 内部异常是由CPU发现和识别的，外部中断必须经过CPU对中断请求线采样并获取设备信息才能识别 缺页发生在CPU外（内存）但却是内部异常，且缺页中断结束后必须回到当前指令执行 Cache缺失不是内部异常也不是外部中断 不可屏蔽中断（全部内中断、突然掉电）；可屏蔽中断（外设请求） 2. 响应处理过程 中断响应 关中断 改变中断允许触发器 保存断点（PC和PSW） 识别中断源 取得中断服务程序首地址和初始 PSW分别送PC和PSWR 中断处理 保护现场（寄存器信息）和屏蔽字 开中断 执行中断服务程序 关中断\u0026mdash;-恢复现场和屏蔽字\u0026mdash;-开中断\u0026mdash;-中断返回 六、指令流水线 1. 流水线设计 设计原则 流水段个数以最复杂指令所用的功能段个数为准，流水段长度以最复杂的操作所花时间为准（2009、2018） 流水段有自己的寄存器，长度可能不同，存储的是下一阶段用到的控制信息和下面所有阶段的控制信息 指令集特征 指令长度尽量一致，格式尽量规整 使用Load/Store指令 数据和指令在存储器中对齐存放 2. 流水线的性能指标 功能段：一个指令执行过程分为几个功能段，理想情况下一个功能段需要一个时钟周期 吞吐率=处理指令数n/所用时间t 加速比=不使用流水线所用时间/使用流水线所用时间 效率=有效面积/总面积 3. 五段式指令流水线 图示 各阶段功能 取指令（IF） 从Cache或主存取指令 指令译码（ID） 产生指令执行所需要的控制信号 取操作数（OF） 读取存储器操作数或寄存器操作数 执行（EX） 对操作数完成制定操作 写回（WB） 将操作数写回存储器或寄存器 4. 高级流水线技术 超流水线技术 特点 增加流水线级数，配置多个功能部件，以空间换时间 图示 多发射流水线技术 静态多发射处理器（超长指令字） 特点 一条指令包含多个操作并行执行，能减少访存次数 图示 动态多发射处理器（超标量流水） 特点 CPU中有一条以上的流水线，每个时钟周期可以完成一条以上的指令，以空间换时间（2017） 能结合动态调度技术提高指令流水线的并行性（2017） 支持指令级并行，每个周期可以发射多条指令，由硬件完成指令调度 图示 5. 流水线的冒险与处理 结构冒险（资源冲突） 含义 同一个部件同时被不同指令使用（尤其是存储器、寄存器、ALU） 解决措施 指令存储器和数据存储器分开 规定功能部件在一条指令中只能使用一次 数据冒险（数据冲突） 含义 前面指令的结果是后面指令的操作数（2016、2019） 在正常执行的基本流水线中，所有数据冒险都属于写后读数据冒险 解决措施 软件NOP、气泡 数据旁路技术（转发技术）（2010） 编译优化，调整指令顺序 控制冒险（控制冲突） 含义 指令执行顺序改变（调用、转移、异常、中断）而引起流水线阻塞 解决措施 分支预测，尽早生成转移目标地址 预取转移成功和不成功两个控制流方向上的目标指令 提高转移方向的猜准率 加快和提前形成条件码 七、多处理器的基本概念 1. 基本分类 SISD（单指令流，单数据流） 平常学的计算机结构，可采用流水线CPU和交叉编址存储器 SIMD（单指令流，多数据流） 不同的处理单元执行同一条指令处理不同的数据，用在for循环、图像处理（数据级并行） MISD（多指令流，单数据流） 同时执行多条指令来处理同一个数据，实际中不存在 MIMD（多指令流，多数据流） 多处理器系统 多处理器一主存，可通过访存指令互相传送数据 多计算机系统 多处理器多主存，可通过消息传递互相传送数据 向量处理机 擅长向量运算和浮点计算 2. 硬件多线程 概念 目的：为了减小线程切换的开销 方法：为每个线程提供单独的通用寄存器朱、程序计数器等 分类 细粒度多线程 多个线程之间轮流交叉执行指令，每个时钟周期切换线程 粗粒度多线程 只在一个线程出现较大开销的阻塞才切换线程，切换开销较大 同时多线程 同一时钟周期发射多条指令执行，实现指令级并行和线程级并行 超线程技术 在一个CPU内提供两套线程处理单元，能够同时执行两个线程，但可能出现争抢资源的现象 超线程的性能要弱于两个CPU的性能 需要芯片组、操作系统和应用软件的支持 3. 多核处理器 将多个处理单元集成到单个CPU中，每个处理单元称为1个核 可以有自己的Cache也可以共享Cache,共享内存 若要发挥硬件性能，必须采用多线程或多进程技术 一般采用偶数路CPU 双核技术是指将两个CPU集成到一个封装，主板上有两个CPU属于多处理器 4. 共享内存多处理器（SMP） UMA（统一存储访问） 需要解决的重要问题是Cache一致性 每个处理器对所有存储单元的访问时间是大致相同的 NUMA（非统一存储访问） 访存请求快慢不同 相比之下运算扩展性更好 八、习题 通用寄存器可以存放指令和数据\n指令包括操作码和地址码，指令译码只对操作码解释\n取指周期取的是指令，间指周期取的是操作数的有效地址，而不是操作数\n取指操作是机器自动完成的，不需要指令控制\n微程序控制器的时序系统比较简单\n指令系统有n种机器指令，则微程序至少n+1个（公共取指微程序和中断微程序）\n取指操作是控制器固有的功能，不需要在操作码控制下完成\n指令周期一定大于等于一个时钟周期（2011）\n主存储器由RAM和ROM实现（2017）\n","date":1708778896,"headings":[{"anchor":"1-cpu的功能","title":"1. CPU的功能"},{"anchor":"1-cpu组成袁春风书补充","title":"1. CPU组成（袁春风书补充）"},{"anchor":"1-中断极其重要","title":"1. 中断（极其重要）"},{"anchor":"1-各种周期的关系","title":"1. 各种周期的关系"},{"anchor":"1-基本分类","title":"1. 基本分类"},{"anchor":"1-流水线设计","title":"1. 流水线设计"},{"anchor":"1-硬布线","title":"1. 硬布线"},{"anchor":"2-cpu的基本结构","title":"2. CPU的基本结构"},{"anchor":"2-响应处理过程","title":"2. 响应处理过程"},{"anchor":"2-微程序","title":"2. 微程序"},{"anchor":"2-指令周期的数据流","title":"2. 指令周期的数据流"},{"anchor":"2-数据通路的基本结构","title":"2. 数据通路的基本结构"},{"anchor":"2-流水线的性能指标","title":"2. 流水线的性能指标"},{"anchor":"2-硬件多线程","title":"2. 硬件多线程"},{"anchor":"3-五段式指令流水线","title":"3. 五段式指令流水线"},{"anchor":"3-多核处理器","title":"3. 多核处理器"},{"anchor":"3-指令执行方案","title":"3. 指令执行方案"},{"anchor":"3-硬布线和微程序的比较","title":"3. 硬布线和微程序的比较"},{"anchor":"4-共享内存多处理器smp","title":"4. 共享内存多处理器（SMP）"},{"anchor":"4-大题","title":"4. 大题"},{"anchor":"4-高级流水线技术","title":"4. 高级流水线技术"},{"anchor":"5-流水线的冒险与处理","title":"5. 流水线的冒险与处理"},{"anchor":"一cpu的功能和基本结构","title":"一、CPU的功能和基本结构"},{"anchor":"七多处理器的基本概念","title":"七、多处理器的基本概念"},{"anchor":"三数据通路的功能和基本结构","title":"三、数据通路的功能和基本结构"},{"anchor":"二指令执行过程","title":"二、指令执行过程"},{"anchor":"五中断和中断机制按袁春风书","title":"五、中断和中断机制（按袁春风书）"},{"anchor":"八习题","title":"八、习题"},{"anchor":"六指令流水线","title":"六、指令流水线"},{"anchor":"四控制器的功能和工作原理","title":"四、控制器的功能和工作原理"}],"kind":"page","lang":"zh-hans","summary":"","tags":["计算机组成原理"],"title":"第五章：中央处理器","url":"/408/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E7%AC%AC%E4%BA%94%E7%AB%A0%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/","year":"2024"},{"content":"一、指令格式 1. 按操作数个数分类 零地址指令 不需要操作数的指令 空操作指令、停机指令、关中断指令 需要操作数的指令 两个操作数从栈顶和次栈顶弹出运算结构再压入堆栈 一地址指令 单操作数指令 加1、减1、求反、求补 双操作数指令 另一个操作数由ACC提供，运算结果放入ACC（(ACC)OP(A1)） 二地址指令 (A1)OP(A2)\u0026ndash;\u0026gt;A1 常用的算术逻辑运算指令 三地址指令 第三个地址用于存放运算结果 四地址指令 第四个地址用于存放下一条指令的地址 2. 定长操作码 指令格式固定 3. 扩展操作码 使用频率高的指令分配短操作码，使用频率低的指令分配长操作码 指令字长一般是存储字长的整数倍（2017） 4. 常见的汇编指令 二、指令寻址和数据寻址 1. 指令寻址 顺序寻址 PC=PC+1 跳跃寻址 跳跃只是改变PC的值，下条指令地址还是PC给出 由本条指令给出下条指令的地址 2. 数据寻址 基本概念 A：形式地址 EA：有效地址 （A）：地址内存储的内容 偏移寻址（2011） 基址寻址 为逻辑地址到物理地址的变换提供了支持，用以实现程序的动态重定位 基址寄存器的内容不变，形式地址不断改变（2019） 相对寻址 特别有利于程序浮动 PC存储的是下一条指令的地址，形式地址一般用整数补码表示（2009） 变址寻址 设定形式地址A为数组首地址，不断改变变址寄存器的内容 对线性表之类的数组元素进行方便的访问（2017、2018） 3. 考题 相对寻址相对的是PC+1；且要注意当前指令的长度 基址寻址的形式地址按无符号数存储，但计算时却按补码运算（2019） 大题给出了定长指令字的格式，就不能使用扩展指令字计算最值问题（2010、2015） 硬件：符号扩展器、移位寄存器、加法器、多路选择器（2013） 大题代码区：行号\u0026mdash;-虚拟地址\u0026mdash;-二进制机器指令\u0026mdash;-汇编代码 指令格式：操作码+源操作数+目的操作数（目的操作数存放运算结果）（2010） 三、程序的机器级代码表示 1. 无符号和带符号整数的大小比较（2011） 电路图 标志位 ZF：最终结果是否为0 OF：符号位进位情况异或最高数位进位情况 SF：符号位为多少 CF：Sub异或Cout（A+B大于表示范围或A-B的时A\u0026lt;B） 根据标志位分析结果 2. 常用汇编指令介绍 四、CISC/RISC的基本概念 （2009） 五、习题 为了缩短指令中某个地址段的位数，有效的方法是采取寄存器寻址\n简化地址结构的基本方法是采用隐地址\n在多道程序设计中，最重要的寻址方式是相对寻址\n","date":1708778299,"headings":[{"anchor":"1-指令寻址","title":"1. 指令寻址"},{"anchor":"1-按操作数个数分类","title":"1. 按操作数个数分类"},{"anchor":"1-无符号和带符号整数的大小比较2011","title":"1. 无符号和带符号整数的大小比较（2011）"},{"anchor":"2-定长操作码","title":"2. 定长操作码"},{"anchor":"2-常用汇编指令介绍","title":"2. 常用汇编指令介绍"},{"anchor":"2-数据寻址","title":"2. 数据寻址"},{"anchor":"2009","title":"（2009）"},{"anchor":"3-扩展操作码","title":"3. 扩展操作码"},{"anchor":"3-考题","title":"3. 考题"},{"anchor":"4-常见的汇编指令","title":"4. 常见的汇编指令"},{"anchor":"一指令格式","title":"一、指令格式"},{"anchor":"三程序的机器级代码表示","title":"三、程序的机器级代码表示"},{"anchor":"二指令寻址和数据寻址","title":"二、指令寻址和数据寻址"},{"anchor":"五习题","title":"五、习题"},{"anchor":"四ciscrisc的基本概念","title":"四、CISC/RISC的基本概念"}],"kind":"page","lang":"zh-hans","summary":"","tags":["计算机组成原理"],"title":"第四章：指令系统","url":"/408/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E7%AC%AC%E5%9B%9B%E7%AB%A0%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F/","year":"2024"},{"content":"一、存储器概述 1. 存储器的分类 按存取方式 随机存取存储器 访问每个地址的时间都相同（RAM、ROM）（2011） 顺序存取存储器 信息顺序存放和读出（磁带） 直接存取存储器 兼有随机访问和顺序访问的特点（磁盘、光盘） 相联存储器 可以按照内容或地址寻找信息（快表） 按可保护性 断电后信息是否消失 （易失性）断电消失 RAM、cache （非易失性）断电不消失 ROM、光、磁存储器 读出后信息是否破坏 破坏性读 动态RAM 非破坏性读 静态RAM 按存储介质 磁表面存储器（磁盘、磁带）、半导体存储器（RAM、ROM）、光存储器（光盘） 按层次结构 主存 由RAM（用户程序）和ROM（系统程序）构成 TLB 采用相联存储器或SRAM（2018、2020） 高速缓存（Cache） 只能由SRAM构成 内存（主存） 辅存 磁盘、磁带、光盘等 2. 存储器的性能指标 存储容量 =存储字数*字长 单位成本 =总成本/总容量 存取速度 又名数据传输率、主存带宽 存取周期 根本定义：进行一次完整读写操作所需要的时间或者连续两次访存所需的最小时间间隔 （存取周期往往大于存取时间） 3. 多级层次的存储系统 （图示） 主存-Cache 由硬件完成，主要解决CPU和主存速度不匹配的问题 主存-辅存 由硬件和操作系统完成，主要解决存储系统容量的问题 二、主存储器 1. 随机存储器（RAM） 静态SRAM（Cache使用） 原理：由双稳态触发器（六晶体管MOS）组成 特点：存取速度快，集成度低、功耗大、价格昂贵 动态DRAM（主存使用） 原理：靠电容存储电荷的原理来寄存信息 集成度高、容量大、功耗低、地址复用（地址线为原来的1/2，分两次传输） 刷新 刷新方式 集中（利用一段连续时间，对所有行进行刷新） 优点：读写操作不受刷新工作的影响 缺点：存在死时间/死区（不能进行读/写操作） 分散（每个系统工作周期先读写操作后刷新一行） 优点：不存在死时间 缺点：增加了系统存取周期，降低了机器速度 异步（计算出刷新的时间间隔，每次刷新一行） 折中方案，既可以减少刷新次数，又可以缩短死时间 刷新特点 刷新是一行行进行的，一次刷新只需占用一个存取周期（2018） SDRAM 升级版的DRAM，也是电荷存储信息需要刷新，但是与CPU之间采用同步方式交换数据，支持猝发传输（2015） 2. 只读存储器（ROM） 掩膜ROM 出厂时直接写入，任何人无法修改 PROM（一次可编程） 用户可以编写一次，但之后不能修改 EPROM（可擦除可编程） 可编程多次，但编程次数有限且写入时间较长 改写方法 用紫外线照射，擦除时芯片中所有信息都会消失 EEPROM（电可擦除） 电可擦除，可以选择只删除个别字 FLASH（闪速存储器） 特点 属于ROM（存储元由MOS管组成），是半导体存储器，可随机存取（2012） 操作 编写 所有存储元最开始都是“1”，需要改为“0”的地方充电即可 擦除 对所有存储元都放电，使所有存储元都是“1” 读取 读速度比写速度快很多（2012） 固态硬盘SSD 2022年考纲新加，会细讲 3. 并行存储器结构技术（按袁春风书来） 双端口存储器 一个存储器有两个读写端口 若两个端口同时读写的地址不同，则正常读写互不影响 若两个端口同时读写相同的地址则发生冲突，按照特定的优先顺序进行读写 单体多字 一个存储体，每个存储单元存储m个字，一次读出m个字 缺点是指令和数据在主存内必须是连续存放的，否则效果就不明显 多模块存储器 连续编址方式\n（注意高位地址表示体号） 交叉编址方式\n（注意低位地址表示体号） 启动方式 轮流启动 （图示）（2015考） 两个重要公式 m\u0026gt;=T/r\nt=T+(m-1)r 同时启动（2017） 三、主存储器与CPU的连接 1. 主存容量扩展 字、位、字位扩展（经常考简单计算，扩展电路图从来不考） 扩展后形成的地址空间 扩展后编址默认是顺序编址（2010） 2. 片选法与线选法 线选法 高位地址信号直接连接各存储器的片选端 地址空间不连续，不能充分利用系统的地址空间 译码片选法 通常地址线低位作为位选，高位作为片选信号 （高位地址信号经过地址译码器后再连接到各存储器的片选端） 3. 芯片最小引脚数 SRAM 通常使用一维地址，地址线=2^n 总引脚=地址线+数据线+电源接地线+片选线1+读写线（1或2） 地址线通过芯片容量计算；数据线通过存储字长计算；电源接地线往往不考虑；片选线一定为1；读写线看题目描述 DRAM 通常使用二维地址，地址总线复用，引脚数减半 总引脚=地址线/2+数据线+电源接地线+行选通信号1+列选通信号1+读写线（1或2） 地址线通过芯片容量计算；数据线通过存储字长计算；电源接地线往往不考虑；行列选通信号和为2；读写线看题目描述（2014） 四、外部存储器 1. 磁盘存储器 磁盘设备的组成 （磁盘存储器由磁盘控制器、磁盘驱动器和盘片组成） 磁记录原理 磁头和磁性记录介质相对运动，通过电磁转换完成读写操作 磁盘存储器的一个最小读写单位为扇区（2019） 磁盘的性能指标 平均存取时间（2013、2015） 寻道时间 旋转延迟时间 转半周的时间 传输时间 按照读写速率和读写块的大小计算（2013） 按照磁盘旋转n个扇区的时间计算（2015） 记录密度 道密度 沿磁盘半径方向单位长度上的磁道数 位密度 磁道单位长度上能记录的二进制代码位数 面密度 =位密度*道密度 磁盘容量 格式化容量比非格式化容量小（2019）（操作系统会细讲原理） 数据传输率 根据具体情况计算 磁盘地址 驱动器号+柱面号+盘面号+扇区号（操作系统部分大题会考到） 硬盘的工作过程 读写操作是串行的，不能同时读写，也不能同时读两组数据或写两组数据 2. 磁盘阵列 RAID（独立冗余磁盘阵列） 由多个物理磁盘组成，数据交叉存储并行访问，有更好的存储性能、可靠性和安全性 总结（2013） 使用多个磁盘，提高了传输率 通过多个磁盘并行存取，提高了数据吞吐量 通过镜像功能，提高了安全可靠性 通过数据校验，提高了容错能力 3. 固态硬盘（SSD）（2022考纲新加，需注意） 基于闪存Flash，属于EEPROM 以页为单位读写，以块为单位擦除 读得快写得慢，但也比传统的机械硬盘快，且功耗低 缺点就是容易磨损，使用磨损均衡技术延长使用寿命 五、高速缓冲存储器 1. 程序访问的局部性（按袁书） 时间局部性 被访问的某个存储单元在较短时间内很有可能又被访问（通常由于程序的循环执行）（2017） 空间局部性 被访问的某个存储单元的邻近单元在较短时间内很有可能被访问（通常由于程序的顺序执行，如访问数组）（2017） 2. Cache的基本工作原理 通常由SRAM构成，Cache和主存划分为许多大小相同的快，每个块由若干字节组成 CPU访问地址命中Cache，则直接读Cache，若不命中则读主存同时把访问的字所在的主存块调入Cache 若Cache满了，则调入主存块时需要执行替换算法进行替换 CPU与Cache之间的交换以字为单位，Cache与主存之间的交换以块为单位 3. Cache和主存的映射方式 （三种映射方式示意图） 地址结构划分（做题基础） 首先根据题中映射方式确定地址结构 直接映射 地址：标记+Cache行号+块内地址 全相联映射 地址：标记+块内地址 组相联映射 地址：标记+Cache组号+块内地址 块内地址位数a 若为按字节编址，a=log2(主存块大小/字节长度) 若为按字编址，a=log2(主存块大小/字的长度) Cache行号位数b b=log2(Cache容量/主存块大小） Cache组号位数c c=log2（Cache容量/每组的大小） 标记位数d d=地址位数-前面计算过的各项长度（经常考） d=主存容量/Cache容量（不常用） Cache总容量的计算（2015、2021） （Cache总体结构示意图） 标记项长度计算 有效位 一定有有效位且长度为1位 脏位 采用回写法时长度为1位，否则长度为0 替换控制e 使用LRU替换算法时才会使用,一般在组相连映射中考察 e=log2（每组包含的Cache块数）【比如4路组相连时e=2，8路组相连时e=3】 标记位长度 上面已给出 Cache总容量=Cache块数*（每个Cache块标记项位数+数据位数） Cache命中率的计算 给出访存次数和访问Cache次数计算（2009） 组相联+LRU替换策略下计算Cache缺失次数（2012） 访问数组的Cache缺失率（2016）（修改数组一个单元的内容需要访问Cache两次即取出和存入） 4. Cache中主存快的替换算法 先进先出（FIFO） 选择最早调入的块进行替换 随机法 随机地选择块进行替换 近期最少使用（LRU） 符合程序访问的局部性原理 当集中访问的存储区超过cache组大小时，会出现颠簸抖动现象，命中率非常低 2^n路组相连，就需要n个LRU位（2018） 5. Cache写策略 写命中时 全写法 对cache写命中时，必须把数据同时写入cache和主存 回写法 对cache写命中只修改Cache内容，等此块被换出再写入主存 每个cache 需设置一个标志位，判断是否被CPU修改过（经常考） 写不命中时 写分配法 更新主存并更换cache块 非写分配法 更新主存不更换cache块 6. Cache结构示意图 （了解现代计算机往往采用多级Cache，且有时数据Cache和指令Cache相分离） 指令Cache和数据Cache相分离的主要目的是减少指令流水线的冲突（2014） 六、虚拟存储器 1.虚拟存储器的基本概念 主存和辅存共同构成了虚拟存储器，虚拟存储器具有主存的速度和辅存的容量 虚地址（逻辑地址） 用户编程允许涉及的地址 实地址（物理地址） 实际的主存单元地址 虚拟存储机制采用全相联映射和回写法 2. 分类 页式虚拟存储器 页表 作用是通过查表将虚页号转换为实页号 各页大小相等，虚拟地址结构为虚页号+页内地址 快表（TLB） 页表存放在主存中访问速度较慢，因此把部分页表内容放入快表中加快访问速度 TLB使用相联存储器 快表通常采用全相联或者组相联。全相联情况下TLB标记=虚页号；组相联情况下TLB标记+组号=虚页号 （TLB、page、Cache的访问情况组合）（2010） 段式虚拟存储器 段式按照程序的逻辑结构划分，各段长度因程序而异 段页式虚拟存储器 把程序按逻辑分段，每段再划分为固定大小的页 每个程序对应一个段表，每段对应一个页表 ","date":1708777881,"headings":[{"anchor":"1-主存容量扩展","title":"1. 主存容量扩展"},{"anchor":"1-存储器的分类","title":"1. 存储器的分类"},{"anchor":"1-磁盘存储器","title":"1. 磁盘存储器"},{"anchor":"1-程序访问的局部性按袁书","title":"1. 程序访问的局部性（按袁书）"},{"anchor":"1-随机存储器ram","title":"1. 随机存储器（RAM）"},{"anchor":"1虚拟存储器的基本概念","title":"1.虚拟存储器的基本概念"},{"anchor":"2-cache的基本工作原理","title":"2. Cache的基本工作原理"},{"anchor":"2-分类","title":"2. 分类"},{"anchor":"2-只读存储器rom","title":"2. 只读存储器（ROM）"},{"anchor":"2-存储器的性能指标","title":"2. 存储器的性能指标"},{"anchor":"2-片选法与线选法","title":"2. 片选法与线选法"},{"anchor":"2-磁盘阵列","title":"2. 磁盘阵列"},{"anchor":"3-cache和主存的映射方式","title":"3. Cache和主存的映射方式"},{"anchor":"3-固态硬盘ssd2022考纲新加需注意","title":"3. 固态硬盘（SSD）（2022考纲新加，需注意）"},{"anchor":"3-多级层次的存储系统","title":"3. 多级层次的存储系统"},{"anchor":"3-并行存储器结构技术按袁春风书来","title":"3. 并行存储器结构技术（按袁春风书来）"},{"anchor":"3-芯片最小引脚数","title":"3. 芯片最小引脚数"},{"anchor":"4-cache中主存快的替换算法","title":"4. Cache中主存快的替换算法"},{"anchor":"5-cache写策略","title":"5. Cache写策略"},{"anchor":"6-cache结构示意图","title":"6. Cache结构示意图"},{"anchor":"一存储器概述","title":"一、存储器概述"},{"anchor":"三主存储器与cpu的连接","title":"三、主存储器与CPU的连接"},{"anchor":"二主存储器","title":"二、主存储器"},{"anchor":"五高速缓冲存储器","title":"五、高速缓冲存储器"},{"anchor":"六虚拟存储器","title":"六、虚拟存储器"},{"anchor":"四外部存储器","title":"四、外部存储器"}],"kind":"page","lang":"zh-hans","summary":"","tags":["计算机组成原理"],"title":"第三章：存储器","url":"/408/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%AD%98%E5%82%A8%E5%99%A8/","year":"2024"},{"content":"一、数制与编码 1. 进位计数制及其转换 （1）采用二进制编码的原因 二进制只有两种状态，使用物理器件制作成本低（2018） “1”与“0”正好与逻辑中的真假对应，方便实现逻辑运算（2018） 二进制的编码和运算简单，方便实现算术运算（2018） （2）不同进制间的相互转换 二进制转换为八进制\n从小数点开始向左向右每隔3位为一组 二进制转换为十六进制\n从小数点开始向左向右每隔4位为一组 十进制转换为二进制（不直接考但会间接用到）\n整数部分：除基取余法 小数部分：乘基取整法 （3）真值与机器数 真值\n用正负号表示的数值为真值，最真实的数值 机器数\n用“0”和“1”表示正负的数值为机器数，机器中使用的数 2. BCD码 2022版考纲删除此部分 3. 定点数的编码表示 机器数的定点表示\n表示法 定义 原码 最高位表示数的符号，其余位表示数值 补码 正数的补码是本身，负数的补码是符号位不变，其它各位取反后末位+1 反码 正数的反码是本身，负数的反码是符号位不变，其它各位取反 移码 只能表示整数，把补码的符号位取反便是移码，方便比较大小 请注意，移码通常用于浮点数的指数部分，以便于进行数值大小的比较。在移码表示法中，所有的非负数（包括零）的表示都是唯一的，并且数值越大，其移码表示也越大，这使得比较操作变得简单。 （假设字长n+1位） 4. 整数的表示 （1）无符号整数 无符号整数常用来表示内存地址 无符号数和带符号数相互转换，存储的数值不变，只是解释方式变了（2019） 表达式中存在无符号数和有符号数时，所有数都转换为无符号数类型（数值不变，解释方法变了） unsigned int 比 int所表示的正数的范围广，经常考察int溢出而unsigned int 不溢出的情况 四则运算 无符号数加法：X+Y=X+Y然后左边溢出的位数都扔掉 无符号数减法：X-Y=X+【-Y】补 乘除法：简单的移位运算，有些数据该丢掉就丢掉 无符号数-1=11111111 编程通常用a\u0026gt;b，而不用a-b\u0026gt;0（可能发生类型转换而出错） （2）带符号整数 计算机中的带符号整数都用补码表示 二、运算方法和运算电路 1. 运算电路 （1）标志寄存器 标志位名称 描述 溢出标志位（OF） 有符号数运算的结果发生溢出则为1（只针对有符号数）（2018） 进位标志位（CF） 无符号数运算向更高位进位或借位则为1（只针对无符号数）（2018） 零标志位（ZF） 执行结果为0则为1 符号标志位（SF） 执行结果为负则为1（只针对有符号数） 奇偶标志位（PF） 执行结果最低八位中1的个数为偶数个则为1 调整标志位（AF） 运算时最低半字节有进位或借位则为1 这些标志位是CPU状态寄存器的一部分，它们在执行算术和逻辑运算后由CPU自动设置，用于指示特定的运算结果状态，从而影响程序的执行流程，例如在条件分支指令中根据这些标志位的状态决定是否跳转。\n（2）算数逻辑单元 （3）加法器 ①一位全加器\n②串行加法器\n③并行加法器\n串行进位的并行加法器 并行进位的并行加法器 ④补码加减运算器 注意 无符号数加减法、补码加减法都可通过此电路实现 Sub信号加法为0，减法为1 CF=Sub异或Cout（2018） 2. 运算方法 （1）移位运算 算术移位（2018） 逻辑移位（2018）\n带上符号位一起移位（无论左移还是右移都补0） 循环移位\n分类 不带进位位CF 类似逻辑移位，CF不参与其中，但移位产生的副本会送进CF 带进位位CF 注意指向CF的箭头 （2）加减运算 溢出判断 一位符号位 符号位和最高数位，同时进位不进位或同时不进位不溢出，否则溢出（2010、2014、2018） 双符号位 特点 具有模2补码全部优点且更易检查加减运算中的溢出问题（不能解决溢出问题） 存储时只需要存一个符号位，只在ALU中运算时采用双符号位 结论 00：正数无溢出 11，负数无溢出 01，结果正溢出 10，结果负溢出 （3）乘除运算 乘法 乘法类型 描述 原码一位乘 累加次数n，右移次数n，符号位不参与运算 补码一位乘 累加次数n+1，右移次数n，符号位参与运算 在原码一位乘中，由于符号位不参与运算，所以需要额外的步骤来处理符号位，以确保结果的正确性。而在补码一位乘中，符号位的处理更加自然，因为它可以像其他位一样参与运算，这使得补码在计算机中的运算更加普遍。\n除法 运算方法 描述 原码加减交替法 加减次数n+1或n+2，左移次数n，符号位不参与运算 原码恢复余数法 补码加减交替法 加减次数n+1，左移次数n，符号位参与运算 乘除法从未考过电路原理或运算步骤 （4）类型转换 类型 描述 无符号数\u0026lt;\u0026ndash;\u0026gt;有符号数 数字不变，只不过解释方法变了（2012、2016、2019） 长\u0026ndash;\u0026gt;短 低位留着，高位截断 短\u0026ndash;\u0026gt;长 即符号扩展，数值不会发生变化 例子：\nchar(1B)\u0026ndash;\u0026gt;short(2B)\u0026ndash;\u0026gt;int(4B)\u0026ndash;\u0026gt;long(4B)\u0026ndash;\u0026gt;float(4B)\u0026ndash;\u0026gt;double(8B) 215=32768;216=65536（2012、2016默认记住） int\u0026ndash;\u0026gt;float可能影响精度（int数值在2^24范围内，float能精确表示，超过后可能不能精确表示） float\u0026ndash;\u0026gt;int可能影响精度（比如float含小数时转换过程中小数部分丢失），也可能会溢出（float表示范围远大于int） int\u0026ndash;\u0026gt;double一定不会出现精度丢失 undesignd（无符号数）：在运算时按照int型运算，在读取时按照无符号数 （5）符号扩展 正数 都是添0 负数 原码：添0 反码：添1 补码：整数添1；小数添0（2009） （6）数据存储和排列 ①基本概念\n对于一个数：10 23 45H LSB（最低有效字节）：45 MSB（最高有效字节）：10 ②存储方式\n大端方式：数据从高位到低位存储，即在一个多字节的数字中，最有效位（最高位）存储在最小的内存地址处。 小端方式：数据从低位到高位存储，即在一个多字节的数字中，最有效位（最高位）存储在最大的内存地址处。 大端小端方式考察频率非常高，一定要掌握！！ 存储方式 描述 大端方式 数据从高位到低位存储（符合习惯）（2020） 小端方式 数据从低位到高位存储（反人类法）（经常考） ③边界对齐方式（2012、2020）\n32位计算机按字编址，1字等于4B 字节随意存，半字地址是2整数倍，字地址是4整数倍，双字地址是8整数倍 三、浮点数表示与运算 1. 浮点数的表示 （1）浮点数的表示格式 （2）浮点数的表示范围\n正上溢和负上溢都是上溢，正下溢和负下溢都是下溢 尾数决定精度，阶码决定范围 （3）浮点数的规格化\n目的\n使尾数的有效数位尽可能多，从而提高运算的精度 途径\n左归（尾数左移）；右归（尾数右移） 表示法 规格化方式 基为2 原码规格化：0.1……/1.1……（尾数最高位一定是1） 补码规格化：0.1……/1.0……（尾数最高位和尾数符号位相反） 基为4、8 原码规格化：尾数最高两位或三位不全为0 阶码基为8，则表示的真值为8^(二进制阶码的真值） （4）IEEE754标准\n①图示\n经常考察把存储的二进制数转换为真值（2011、2014、2020） ②尾数M\n采用原码表示，且隐藏了最高位的1. ③阶码E\n采用移码表示，即减去127或者1023 短浮点数阶码的表示范围为-126~127 ④表示范围\n规格化浮点数 计算表示的最值（最大正负数、最小正负数等）（2012、2018）\n下面这个表格多次考察： 阶码 尾数 表示的值 全0 全0 0 全0 非全0（非规格化小数） 2^-126 * 0.xxxx（2018） 全1 全0 +∞（正无穷大）或 -∞（负无穷大） 全1 非全0（非数值） NaN（不是一个数，2012） 2. 浮点数的加减运算 （1）对阶\n小阶向大看阶齐，不会产生阶码溢出（2015） 右归时尾数右移，可能会舍掉有效位影响精度 （2）尾数求和 （3）规格化\n左归或右归 （4）舎入\n恒置1法 只要因移位而丢失的位中有1，就把尾数末位置1（原来是0或1，现在都置为1） 截断法 直接截取所需位数，丢弃后面所有位 0舍1入法 被舍去的最高数值位为0则直接舍去，被舍去的最高数值位为1则尾数的末位加1 这样做可能使尾数又溢出，此时还需要做一次右归（2015） （5）溢出判断\n溢出判断方法\n尾数的“溢出”不是溢出，规格化后，阶码的溢出才是真正的溢出（2015） 溢出处理方法\n上溢：绝对值太大，会引起溢出中断 下溢：绝对值太小，按0处理，一般不需要溢出中断 溢出类型 处理方法 上溢 绝对值太大，会引起溢出中断 下溢 当绝对值太小，按0处理，一般不需要溢出中断 四、习题 十六进制的数相加，直接按位相加，逢16进1即可 十进制转为八进制，可以先转为二进制再转为八进制 很多十进制小数都不能由二进制精确表示，如1.3 ALU属于组合逻辑电路 逻辑电路类型 描述 常见电路 组合逻辑电路 任意时刻的输出只与当前时刻的输入有关 多路选择器、编码器、译码器、比较器 时序逻辑电路 任意时刻的输出与当前时刻以及历史状态有关 锁存器、触发器 影响串行进位的并行加法器运算速度的关键因素是进位传递延迟 定点数运算不存在舎入，舎入不一定会产生误差 ","date":1708756687,"headings":[{"anchor":"1-浮点数的表示","title":"1. 浮点数的表示"},{"anchor":"1-运算电路","title":"1. 运算电路"},{"anchor":"1-进位计数制及其转换","title":"1. 进位计数制及其转换"},{"anchor":"1无符号整数","title":"（1）无符号整数"},{"anchor":"1标志寄存器","title":"（1）标志寄存器"},{"anchor":"1移位运算","title":"（1）移位运算"},{"anchor":"1采用二进制编码的原因","title":"（1）采用二进制编码的原因"},{"anchor":"2-bcd码","title":"2. BCD码"},{"anchor":"2-浮点数的加减运算","title":"2. 浮点数的加减运算"},{"anchor":"2-运算方法","title":"2. 运算方法"},{"anchor":"2不同进制间的相互转换","title":"（2）不同进制间的相互转换"},{"anchor":"2加减运算","title":"（2）加减运算"},{"anchor":"2带符号整数","title":"（2）带符号整数"},{"anchor":"2算数逻辑单元","title":"（2）算数逻辑单元"},{"anchor":"3-定点数的编码表示","title":"3. 定点数的编码表示"},{"anchor":"3乘除运算","title":"（3）乘除运算"},{"anchor":"3加法器","title":"（3）加法器"},{"anchor":"3真值与机器数","title":"（3）真值与机器数"},{"anchor":"4-整数的表示","title":"4. 整数的表示"},{"anchor":"4类型转换","title":"（4）类型转换"},{"anchor":"5符号扩展","title":"（5）符号扩展"},{"anchor":"6数据存储和排列","title":"（6）数据存储和排列"},{"anchor":"一数制与编码","title":"一、数制与编码"},{"anchor":"三浮点数表示与运算","title":"三、浮点数表示与运算"},{"anchor":"二运算方法和运算电路","title":"二、运算方法和运算电路"},{"anchor":"四习题","title":"四、习题"}],"kind":"page","lang":"zh-hans","summary":"","tags":["计算机组成原理"],"title":"第二章：数据表示与运算","url":"/408/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E7%AC%AC%E4%BA%8C%E7%AB%A0%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%A4%BA%E4%B8%8E%E8%BF%90%E7%AE%97/","year":"2024"},{"content":"一、计算机发展历程 代数 主要元件 特点 第一代 电子管 占用空间大、耗电多、可靠性差、价格昂贵 第二代 晶体管 占用空间小、耗电少、可靠性高、价格相对较低 第三代 中小规模集成电路 进一步缩小体积、降低功耗、提高可靠性、增加计算速度 第四代 超大规模集成电路 集成度更高、计算速度更快、功耗更低、价格更加亲民 以上表格简要介绍了计算机的发展历程，从第一代到第四代，计算机的主要元件从电子管发展到超大规模集成电路，体积越来越小，计算速度越来越快，功耗越来越低，价格越来越亲民。\n二、计算机系统层次结构 1. 计算机系统组成 硬件系统和软件系统共同组成了一个计算机系统 2. 计算机硬件 （1）冯诺依曼计算机\n采用“存储程序”工作方式：程序事先存入主存，然后程序的指令按规定顺序执行 计算机由5部分组成：运算器、存储器、控制器、输入设备、输出设备- 指令和数据执行前都存放在内存中，CPU根据指令周期的不同阶段区分它们（2009） 指令和数据均用二进制代码表示（2019） 指令顺序存放，通常顺序执行（也可跳跃） 早期以运算器为中心，现代计算机以存储器为中心 （2）计算机的功能部件\n图示 ①输入设备\n键盘、鼠标、扫描仪、摄像机 ②输出设备\n显示器、打印机 ③存储器\n存储系统结构\n寄存器\u0026ndash;高速缓存（cache）\u0026ndash;主存\u0026ndash;外存（存取速度越来越慢） 工作方式\n按地址存取 绝大部分存储器都是如此 按内容存取 相联存储器 重要寄存器\nMAR（存储器地址寄存器）=地址码长度，能用于计算存储器的容量（2016） MDR（存储器数据寄存器）=存储字长 基本概念\n概念 定义 存储元件 最基本最小的元件，存储一位二进制0或1 存储单元 由若干个存储元件构成 存储字长 一个存储单元包含的二进制的位数 ④运算器\n功能 进行算术运算（加减乘除等）和逻辑运算（与或非、异或、比较、移位等） 组成 算术逻辑单元（ALU） 通用寄存器 累加器（ACC）、乘商寄存器（MQ）、操作数寄存器（X）、基址寄存器、变址寄存器 标志寄存器（PSW） ⑤控制器\n程序计数器（PC） 存放当前欲执行指令的地址，能自动“+1”从而指向下一条指令的地址 指令寄存器（IR） 存放当前执行的指令 控制单元（CU） 3. 计算机软件 （1）系统软件和应用软件\n类别 软件名称 系统软件 数据库管理系统、编译器、汇编程序、编译程序、连接程序 应用软件 数据库系统、文本编辑、驱动程序 （2）三个级别的语言\n语言类型 描述 机器语言 二进制代码，计算机唯一可以识别和执行的语言（2015） 汇编语言 用英文单词或缩写组成，便于人们理解记忆 高级语言 如C、C++、Java等。可以编译、汇编后得到机器语言程序，也可直接编译为机器语言程序 翻译程序类型 描述 编译程序 把高级语言源程序翻译为汇编语言或机器语言目标程序（2016） 一次全部，较快，能够生成目标程序 汇编程序 把汇编语言翻译成机器语言目标程序 解释程序 把源程序按执行次序逐条翻译成机器指令并立即执行 一次一句，较慢，不能生成目标程序 （3）软件和硬件在逻辑功能上是等价的\n4. 计算机工作过程 从源程序到可执行文件 阶段 描述 预处理 对以#开头的命令进行处理，如宏定义等，生成预处理后的源文件（.i） 编译 生成汇编语言源程序（.s） 汇编 把机器语言指令打包成为一个可重定位目标文件（.o） 链接 把多个可重定位目标文件和标准库函数合并成一个可执行目标文件（.o） 指令执行过程 取指令、分析指令、执行指令（后面章节会细讲） 5. 多级层次结构 高级语言机器\u0026ndash;汇编语言机器\u0026ndash;操作系统机器\u0026ndash;用机器语言的机器\u0026ndash;微指令系统 三、计算机的性能指标 1. 性能指标 （1）机器字长\n概念 定义 机器字长 CPU一次执行多少位数，等于ALU、内部寄存器的存储字长、通用寄存器长度、等于数据总线宽度（2020） 指令字长 指令的长度，指令字长为存储字长的整数倍且等于MAR长度 存储字长 一个存储单元的长度 （2）数据通路带宽\n数据总线一次所能并行传送信息的位数 （3）主存容量\n注意：1K=1024、1B=8bit、2^16=65536 （4）运算速度\n①吞吐量\n单位时间内处理请求的数量 ②响应时间\n用户发出请求到获得结果所需的时间 ③CPU时钟周期\n概念 定义 时钟周期 CPU中最小的时间单位，等于主频的倒数 机器周期（CPU周期） 完成一条指令中一个基本操作所需要的时间 指令周期 取出一条指令并执行完成的时间\n④主频\n机器内部主时钟的频率（2013、2014） ⑤CPI\n执行一条指令所需的平均时钟周期数（2013、2014） ⑥MIPS\n每秒执行多少百万条指令，等于主频/（CPI*10^6）（2013、2014） ⑦每秒浮点运算次数（xFLOPS）\nM（10^6）、G（10^9）、T（10^12）、P（10^15）、E（10^18）、Z（10^21）（2011、2021、2022） （5）基准程序\n在不同的机器上运行相同的基准程序，从而评测机器的性能（2012、2017） 2. 重要术语 术语 定义 系列机 体系结构与指令系统相同而型号不同的一系列计算机 兼容 软件或硬件的通用性 软件可移植性 把软件一直到同系列计算机上 固件 把程序固化在ROM中所组成的固件 四、习题 地址译码器 位于存储器中，能够通过输入的地址找到相应的存储单元 操作系统原语 原语是一段用机器指令编写的完成特定功能的程序,在执行过程中不允许中断。 寄存器由触发器构成\nxFLOPS是评估科学计算的计算机性能最有效的参数\n浮点寄存器\n不是CPU的一部分，而是浮点处理单元的一部分，决定计算机的计算精度 当前设计高性能计算机的重要途径是采用并行处理技术 透明 寄存器的透明性十分重要，经常考察。 在计算机体系结构中，\"不透明\"寄存器是指那些对程序员来说不可见或不可直接访问的寄存器，它们的操作由硬件或操作系统管理。而\"透明\"寄存器则是指那些程序员可以直接访问和操作的寄存器。有关寄存器的透明性可归纳如下： 类别 寄存器名称 不透明 PC（程序计数器） PSW（程序状态字寄存器） 通用寄存器组 基址寄存器（2020、2021） 透明 剩余的其他寄存器 ","date":1708753271,"headings":[{"anchor":"1-性能指标","title":"1. 性能指标"},{"anchor":"1-计算机系统组成","title":"1. 计算机系统组成"},{"anchor":"2-计算机硬件","title":"2. 计算机硬件"},{"anchor":"2-重要术语","title":"2. 重要术语"},{"anchor":"3-计算机软件","title":"3. 计算机软件"},{"anchor":"4-计算机工作过程","title":"4. 计算机工作过程"},{"anchor":"5-多级层次结构","title":"5. 多级层次结构"},{"anchor":"一计算机发展历程","title":"一、计算机发展历程"},{"anchor":"三计算机的性能指标","title":"三、计算机的性能指标"},{"anchor":"二计算机系统层次结构","title":"二、计算机系统层次结构"},{"anchor":"四习题","title":"四、习题"}],"kind":"page","lang":"zh-hans","summary":"","tags":["计算机组成原理"],"title":"第一章：计算机组成原理概论","url":"/408/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E6%A6%82%E8%AE%BA/","year":"2024"},{"content":"一、I/O管理概述 1. I/O设备 （1）设备分类\n分类依据 设备类型 描述 示例 按信息交换单位 块设备 数据交换以块为单位，传输速率高，可寻址，采用DMA方式 磁盘 字符设备 数据交换以字符为单位，传输速率低，不可寻址，采用中断I/O方式 交互式终端机、打印机 按传输速率 低速设备 传输速率低，通常用于输入和输出 键盘、鼠标 中速设备 传输速率中等，常用于网络和存储设备 网卡、USB存储设备 高速设备 传输速率高，常用于高速存储和网络设备 SSD、千兆以太网卡 （2）I/O接口\n（组成：设备控制器与CPU的接口+设备控制器与设备的接口+I/O逻辑）\n（3）I/O端口\n概念：是指设备控制器中可被CPU直接访问的寄存器（数据、状态、控制寄存器） 编址方式：独立编制、统一编址 2. I/O控制方式 （1）程序直接控制方式、中断驱动方式、DMA方式（计组详细介绍）\n（2）通道控制方式\n通道：I/O通道是专门负责输入/输出的处理机，是DMA方式的发展 执行过程：CPU发送通道程序首地址和I/O设备\u0026ndash;\u0026gt;通道执行通道指令\u0026ndash;\u0026gt;传输结束向CPU发送中断请求 通道指令类型单一，通道程序存放在主机的内存中（通道与CPU共享内存） 通道与DMA 一个DMA控制一台设备与内存的数据交换；一个通道可以控制多台设备与内存的数据交换 DMA方式需要CPU控制传输的数据块大小、 传输的内存位置； 通道方式中这些信息都是由通道控制 DMA（直接内存访问）： DMA允许外部设备（如磁盘控制器、网卡等）在不经过CPU干预的情况下直接读写内存。当CPU启动一个DMA传输后，DMA控制器接管数据传输过程，根据预设的地址、传输方向和字节数进行数据交换。 在DMA方式下，虽然CPU不必参与每个数据字节的传输，但仍需要初始化DMA传输参数，如设置源地址、目的地址及传输长度等，并在传输完成后接收到中断通知。 每个设备通常需要自己的DMA控制器来管理其与内存之间的数据传输。 通道（Channels）： 通道是比DMA更高级别的I/O技术，常见于大型计算机系统中，它实际上是一个能够执行有限指令集的微型处理器，专门负责输入输出操作。 通道可以独立于CPU运行简单的程序（称为通道程序），这些程序能够管理和控制多个I/O设备的数据传输任务。 当CPU向通道发送一条I/O指令后，通道就能够自主完成一组相关的读写操作，包括设备寻址、数据缓冲区管理以及完成后的状态报告等，显著减少了CPU的介入次数。 一个通道可以连接并同时服务多个外设，实现真正的并行I/O操作，极大地提高了系统的并发处理能力。 注意DMA与通道的区别： 通道（Channels）和DMA（Direct Memory Access）都是为了提高I/O操作效率而设计的技术，DMA主要通过减少CPU在数据传输中的作用来提高效率，而通道则更进一步，不仅减少了CPU的干预，还提供了更强的并行性和自主性，使得I/O操作更为高效和灵活。 3. I/O软件层次结构 （1）用户层I/O软件\n实现与用户交互的接口， 用户可直接调用在用户层提供的、 与I/O操作有关的库函数 （2）设备独立性软件\n对用户提供统一接口，如read\\write命令 对设备的分配回收、逻辑设备名和物理设备名的映射、缓冲管理、差错控制、速率差异\u0026hellip; 把系统调用参数翻译成设备操作命令 （3）设备驱动程序\n与硬件直接相关，负责具体实现操作系统对设备发出的操作命令 把抽象I/O请求变为具体要求，如把read\\write命令变为设备能识别的命令 再例如将磁盘块号转换为磁盘的盘面、 磁道号及扇区号（2013） （4）中断处理程序\n进行进程上下文的切换，对处理中断信号源进行测试，读取设备状态和修改进程状态 是首先获得键盘输入信息的程序（2010） 4. 应用程序I/O接口 （1）字符设备接口、块设备接口、网络设备接口\n（2）I/O接口模式\nI/O操作类型 特点 阻塞I/O 用户进程调用I/O操作时， 进程就被阻塞， 需要等待I/O操作完成， 进程才被唤醒继续执行 非阻塞I/O 用户进程调用I/O操作时， 不阻塞该进程， 该I/O调用返回一个错误返回值 二、设备独立性软件 1. 高速缓存与缓冲区 （1）磁盘高速缓存\n目的：减少磁盘I/O次数（2015） 利用内存的存储空间来暂存从磁盘中读出的一系列盘块的信息 磁盘高速缓存逻辑上属于磁盘，物理上则是驻留在内存中的盘块 （2）缓冲区\n引入缓冲区的原因\n缓和CPU与I/O设备间速度不匹配的矛盾 减少对CPU的中断频率，放宽对CPU中断响应时间的限制 解决数据粒度不匹配的问题 提高CPU和I/O设备之间的并行性 （3）分类\n① 单缓冲区与双缓冲区 ② 环形缓冲区\n多个大小相等的缓冲区首尾相连构成一个环形 in指针指向可以输入数据的第一个空缓冲区 out指针指向可以提取数据的第一个满缓冲区 ③ 缓冲池\n了解即可 2. 设备分配与回收 （1）考虑因素\n固有属性 设备类型 描述 独占设备 使用时不再允许其他设备申请使用，属于临界资源，不合理分配可能会引起进程死锁（一般用静态分配） 共享设备 一段时间内被同时访问（而不是同一时间内被同时访问），分配不会引起进程死锁（一般用动态分配） 虚拟设备 虚拟设备：SPOOLing技术实现的，以空间换时间 安全性 安全分配：进程获得I/O后便进入阻塞状态 不安全分配：发出I/O请求后继续运行 （2）分配方式\n静态分配 作业开始前一次性分配完设备，不会死锁 动态分配 边运行边分配，可能死锁 （3）设备独立性\n概念：应用程序独立于具体使用的物理设备 I/O重定向：更换用于I/O操作的设备时不必更改应用程序（2020） 外部设备是一种特殊的文件，可以用文件名访问物理设备（2020） 为实现设备独立性，须在驱动程序上设置一层软件，称为设备独立性软件 程序员和应用程序使用逻辑设备名来请求某类设备（2009、2020） 系统实际执行时必须将逻辑设备名转为物理设备名（2020） 逻辑设备表LUT（逻辑设备名，物理设备名，驱动程序入口地址）用于实现逻辑设备名和物理设备名的转换 （4）设备分配中的数据结构\n设备控制表DCT（表述设备属性，如标识符、状态等） 控制器控制表COCT 通道控制表CHCT 系统设备表SDT（系统只有一张，包括设备类、设备标识符、DCT等） 逻辑设备表LUT（逻辑设备名，物理设备名，驱动程序入口地址） 分配的流程，从资源多的到资源紧张的:LUT-\u0026gt;SDT-\u0026gt;DCT-\u0026gt;COCT-\u0026gt;CHCT （5）分配步骤\n根据用户请求的I/O设备的逻辑名，查找逻辑设备和物理设备的映射表 以物理设备为索引，查找SDT，找到该设备所连接的DCT 根据DCT找到COCT再找到CHCT 在有通道的系统中，一个进程只有获得了通道，控制器和所需设备三者之后，才具备了进行I/O操作的物理条件 3. 假脱机系统（SPOOLing） （1）主要组成：\n（2）特点\n提高了I/O的速度和设备利用率 将独占设备改造为共享设备，以空间换时间 实际分给用户进程的不是打印设备，而是共享输出井中的磁盘上的一片存储区域 外设输入数据首先放在磁盘输入井中 由操作系统控制设备与输入/输出井之间的数据传送（2016） 在输入进程的控制下，＂输入缓冲区“用于暂存从输入设备输入的数据，之后再转存到输入井中 在输出进程的控制下，＂输出缓冲区“用于暂存从输出井送来的数据，之后再传到到输出设备上 （3）支持条件\n大容量高速度的外存、spooling相关软件、独占设备、多道程序设计技术（2016） 三、磁盘和固态硬盘 1. 磁盘结构 （1）图示\n（2）重要概念\n扇区：通常固定为512B，也称为盘块，是磁盘最小的物理存储单元 簇：由于扇区众多难以寻址，通常把2^n个扇区合并形成簇，一个簇中只能存放一个文件的内容（2017） （3）地址结构\n柱面号，盘面号，扇区号 假设每个磁道m个扇区，每个柱面n个盘面，每个盘面q个磁道。第x个盘块地址为 柱面号=x/mn；盘面号=（x%mn）/m；扇区号=x/m 2. 磁盘的管理 （1）磁盘初始化\n物理格式化 将磁盘各个磁道划分为扇区，一个扇区通常包含三部分 格式化后磁盘空间会减少，用来存储前导码、ECC校验码以及间隙 对磁盘分区 为什么要分区：方便管理、数据安全 逻辑格式化 建立文件系统 建立引导块、根目录、空闲块管理、空文件系统（2017） 为什么要逻辑格式化：操作系统无法识别系统上磁盘分区的格式 （2）坏块\n坏块标明 在FAT中指明，坏块对操作系统不透明 扇区备用 使用时用其它扇区替换，坏块对操作系统透明 3. 磁盘调度算法 （1）读写时间\n组成 寻找（寻道）时间、（旋转）延迟时间、传输时间 减少延迟方法 交替编号：让编号相邻的扇区在物理上不相邻 错位命名：让相邻盘面的扇区编号错位 （2）调度算法\n调度算法 描述 先来先服务（FCFS） 性能很差，但不会导致磁臂黏着（2018） 最短寻找时间优先 会导致饥饿现象 扫描算法（电梯算法、SCAN） 对各个未知的响应频率不均匀默认是LOOK算法（2015） 循环扫描算法（C-SCAN） 朝某方向移动到最末端后快速返回，返回期间不处理请求 LOOK/C-LOOK 不移动到最末端就可以返回\n4. 提高磁盘I/O速度途径 磁盘高速缓存：在内存中为磁盘盘块设置一个缓冲区，在缓冲区中保存了某些盘块的副本 提前读：在读当前块时也把下一个盘块数据读入缓冲区（2012） 延迟写：缓冲区的数据不立即写回磁盘，因为可能会在不久后被访问（2012） 重排I/O请求次序（2012） 优化文件物理块分布（2012） 虚拟盘：利用内存空间去仿真磁盘 廉价磁盘冗余阵列 方法：把数据分别存储到不同磁盘的相同位置，各个磁盘数据并行传输 优点：速度提高n-1倍；牺牲1/n的容量为代价 5. 固态硬盘 （1）图示\n基于闪存技术 （2）特性\n数据以页为单位读写，只有在一页所属的块被整个擦除后才能写这一页 ①随机写比随机读慢很多 ②比起传统机械硬盘读写速度更快、没有机械噪声和震动， 能耗更低、 抗震性好、 安全性高 （3）磨损均衡\n动态磨损均衡 写入数据时， 自动选择较新的闪存块。 老的闪存块先歇一歇 静态磨损均衡 没有数据写入时自动进行数据分配，让老闪存块承担无需写任务的存储任务，平时读写操作在新闪存块中进行 静态磨损均衡比动态磨损均衡的性能更好 ","date":1708597769,"headings":[{"anchor":"1-io设备","title":"1. I/O设备"},{"anchor":"1-磁盘结构","title":"1. 磁盘结构"},{"anchor":"1-高速缓存与缓冲区","title":"1. 高速缓存与缓冲区"},{"anchor":"2-io控制方式","title":"2. I/O控制方式"},{"anchor":"2-磁盘的管理","title":"2. 磁盘的管理"},{"anchor":"2-设备分配与回收","title":"2. 设备分配与回收"},{"anchor":"3-io软件层次结构","title":"3. I/O软件层次结构"},{"anchor":"3-假脱机系统spooling","title":"3. 假脱机系统（SPOOLing）"},{"anchor":"3-磁盘调度算法","title":"3. 磁盘调度算法"},{"anchor":"4-应用程序io接口","title":"4. 应用程序I/O接口"},{"anchor":"4-提高磁盘io速度途径","title":"4. 提高磁盘I/O速度途径"},{"anchor":"5-固态硬盘","title":"5. 固态硬盘"},{"anchor":"一io管理概述","title":"一、I/O管理概述"},{"anchor":"三磁盘和固态硬盘","title":"三、磁盘和固态硬盘"},{"anchor":"二设备独立性软件","title":"二、设备独立性软件"}],"kind":"page","lang":"zh-hans","summary":"","title":"第五章：输入输出系统","url":"/408/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%AC%AC%E4%BA%94%E7%AB%A0%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B3%BB%E7%BB%9F/","year":"2024"},{"content":"一、文件系统基础 1. 文件控制块和索引结点 （1）文件控制块\nFCB是用来存放控制文件需要的各种信息的数据结构（2009） FCB的有序集合称为文件目录，一个FCB就是一个文件目录项 （2）索引结点\n目录项结构：文件名+索引结点号（2020） 磁盘索引结点 每个文件对应有一个唯一的磁盘索引结点 内存索引结点 文件被打开时要将磁盘索引结点复制到内存索引结点便于以后使用 （3）图示\n2. 文件的操作 （1）文件的基本操作\n操作 描述 创建文件 create 分配一定的外存空间并创建一个目录项（参数：所需外存大小、文件存放路径、文件名） 读文件 read 参数：文件描述符fd、buf缓冲区首址、传送的字节数n（2012） 写文件 write 提供文件描述符、写回多少数据、写回外存的数据在内存什么位置 文件定位 搜索目录以找到适当的条目， 并将当前文件位置指针重新定位到给定值 删除文件 delete 释放外存空间并删除目录项（参数：文件存放路径、文件名）（2013）删除文件不必完成的操作是删除文件的快捷方式（2021） 截断文件 删除文件内容但文件所有属性不变 （2）文件的打开与关闭\n打开open：将文件属性从外存复制到内存打开文件表的一个表目中并将文件描述符fd返回给用户（2014） 此后对文件的读写操作不使用文件名而使用文件描述符，只有在操作文件时才把文件调入内存 关闭close：把进程打开文件表的相应表项删除，把系统打开文件表的打开计数器-1 两级表：\n关于进程的打开文件表和系统的打开文件的辨析十分重要,此处经常出题： ①不同的进程中会出现相同的文件描述符，它们可能指向同一个文件，也可能指向不同的文件 ②各进程的用户打开文件表中关于同一个文件F的读写指针位置一般不同（2017） ③各进程的用户打开文件表中关于同一个文件F的表项内容一般不同（2020） ④所有进程都关闭文件F时，系统打开文件表才会删除文件F对应的表项（2020） 3. 文件保护 （1）口令保护\n访问文件首先要输入口令，口令存在于FCB或索引结点中，不安全 （2）加密保护\n对文件进行加密，访问文件时需要密码对文件进行解密 （3）访问控制\n特点 对于一个文件的访问，常由用户访问权限和文件属性共同限制 访问控制列表（ACL）有三种用户类型：拥有者、组、其它 若用户和拥有者在同一组，则按照同组权限访问，否则只能按其它用户权限访问 图示 （2017） 4. 文件的逻辑结构 无结构文件（流式文件）：以字节为单位，如源程序文件、目标代码文件\n无结构文件考查较少，此处重点介绍有结构文件（记录式文件）：\n（1）顺序文件\n分类： 记录类型 结构 特点 变长记录 无法随机存取 定长记录 串结构 记录之间的顺序与关键字无关，无法快速存取 定长记录 顺序结构 记录顺序与关键字有关，可以快速存取 特点 优点：进行批量存取效率最高；缺点：修改、增加、删除记录比较困难 （2）索引文件\n组成 索引表 索引号+长度+指针（指向逻辑文件） 索引表是定长记录的顺序文件 特点 优点：增删方便，不定长记录也能随机存取；缺点：花费空间 （3）顺序索引文件\n流程 利用索引表找到记录所在的记录组的第一个记录 利用顺序查找法找到所需要的记录 特点 查找效率大大提高 （4）直接文件或散列文件\n给定记录的键值或通过散列函数转换的键值直接决定记录的物理地址，可能会产生地址冲突 5. 文件的物理结构 （1）连续分配\n每个文件占用一组连续的块，文件的目录条目包含（开始块、块数）（访磁盘1次） 优点：可以随机访问、访问很快（磁盘寻道时间短）（2013） 缺点：不利于文件扩展和删除，会产生磁盘碎片 （2）链接分配\n①隐式链接\n文件目录包括文件的首块指针和尾块指针，中间盘块之间相互链接对用户透明（访磁盘n次） 优点：不需要连续存放，不存在外部碎片 缺点：只能顺序访问，不能随机访问 ②显式链接\n把各指针显式存放在文件分配表（FAT） FAT表项：盘块号+下一块地址 FAT系统只有一张，开机后常驻内存 （3）索引分配\n为每个文件创建一个索引表（块）：逻辑块号+物理块号（访磁盘m+1次） 优点：可以随机访问，文件长度可变（2009、2020） 缺点：需要索引快，增加了系统存储空间的开销 （4）支持大文件机制\n链接方案 将多个索引快链接起来 多层索引 一级索引块指向二级索引块，二级索引块指向文件块 混合索引 二、目录 1. 目录结构 （1）单级文件目录\n文件不允许重名 （2）两级目录结构\n不同用户的文件可以重名 （3）树形文件目录\n绝对路径：从根目录出发的路径 相对路径：从当前目录出发的路径（加快文件索引速度）（2010） 2. 文件共享 （1）有向无循环图（硬链接）\n图示 特点 各个用户的目录项指向同一个索引结点 索引结点中有链接计数器count，只有count=0时才能删除 （2）符号链接（软链接）\n图示\n特点\n文件主才拥有指向索引结点的指针，其他文件只有该文件的路径名 当文件主删除文件后其它文件通过符号链接访问会失败，此时不会产生什么影响，可以把符号链接删除 优点：删除文件不会留下悬空指针；缺点：需要查询多级目录，时间长 建立符号链接时，引用计数值count直接复制（2009） 4.3文件系统 1. 文件系统布局 （1）图示\n（2）简单描述\n概念 描述 主引导记录 MBR 位于磁盘的0号扇区，确定活动分区并读入其中的引导块 分区表 给出每个分区的起始和结束地址 引导块 启动该分区中的操作系统 超级块 包含文件系统的所有关键信息（每个分区块的数量和块的大小、 空闲块的数量和指针、 空闲的FCB数量和FCB指针） 空闲空间管理 用位示图或指针链接的形式给出空闲块的信息 i结点区 存放i-node结点，每个文件对应一个i-node结点 根目录 存放文件系统目录树的根部 2. 外存空闲空间管理 （1）空闲表法\n（2）空闲链表法\n空闲空间管理方式 描述 空闲盘块链 所有空闲空间以盘块为单位拉成一条链 空闲盘区链 所有空闲盘区（每个盘区可包含若干个盘块） 拉成一条链 （3）位视图法\n用二进制的一位来表示磁盘中一个盘块的使用情况（0空闲1分配）（2015计算位视图具体位置） （4）成组链接法\nUNIX系统使用，适合大文件，把空闲扇区用指针链接起来 （5）文件分配表（2019）\n文件分配表（File Allocation Table，简称FAT）是计算机文件系统中的一个重要数据结构，它用于记录文件存储在存储设备（如硬盘、闪存盘等）上的位置。FAT系统最初是为MS-DOS操作系统设计的，后来被Windows操作系统所采用，尽管Windows后来推出了更先进的文件系统，如NTFS。\nFAT的工作原理如下：\n磁盘分区：磁盘被分成多个分区，每个分区可以包含一个文件分配表。 存储单元：磁盘被进一步划分为多个存储单元，这些单元通常称为“簇”（cluster）。每个簇可以包含一个或多个连续的扇区。 文件分配表：FAT本身是一个表格，其中包含了磁盘上每个簇的状态信息。每个表项对应一个簇，记录了以下信息： 该簇是否空闲。 如果簇已被文件使用，它是指向文件下一个簇的指针，或者是一些特殊值，如“结束簇”标记。 文件存储：当一个文件被保存时，文件系统会查找FAT中空闲的簇，并将这些簇的编号记录下来。如果文件超过一个簇，FAT会记录一个链，指示文件下一个簇的位置。 文件读取：当读取文件时，文件系统会根据FAT中的链来定位文件的数据簇，并按顺序读取这些簇，直到遇到结束簇标记。 FAT有几种不同的版本，如FAT12、FAT16、FAT32等，这些数字代表了FAT表项的大小，即它们可以引用的簇的数目。例如，FAT16每个表项可以引用2^16（65536）个簇，而FAT32每个表项可以引用2^32（4294967296）个簇。 随着磁盘容量的增加和文件大小的增长，FAT文件系统在处理大容量磁盘和大型文件时显得力不从心，因此出现了更先进的文件系统，如NTFS（New Technology File System），它提供了更好的性能、更大的容量支持和更强的可靠性。\n3. 虚拟文件系统 （1）概念\n概念：屏蔽了不同文件系统的差异和操作细节，向用户程序提供统一的调用函数 抽象了四种对象类型：超级块对象、索引结点对象、目录项对象、文件对象 并不是实际的文件系统且只存在于内存中，在系统启动时建立在系统关闭时消亡 （2）例子\n","date":1708589180,"headings":[{"anchor":"1-文件控制块和索引结点","title":"1. 文件控制块和索引结点"},{"anchor":"1-文件系统布局","title":"1. 文件系统布局"},{"anchor":"1-目录结构","title":"1. 目录结构"},{"anchor":"2-外存空闲空间管理","title":"2. 外存空闲空间管理"},{"anchor":"2-文件共享","title":"2. 文件共享"},{"anchor":"2-文件的操作","title":"2. 文件的操作"},{"anchor":"3-文件保护","title":"3. 文件保护"},{"anchor":"3-虚拟文件系统","title":"3. 虚拟文件系统"},{"anchor":"4-文件的逻辑结构","title":"4. 文件的逻辑结构"},{"anchor":"43文件系统","title":"4.3文件系统"},{"anchor":"5-文件的物理结构","title":"5. 文件的物理结构"},{"anchor":"一文件系统基础","title":"一、文件系统基础"},{"anchor":"二目录","title":"二、目录"}],"kind":"page","lang":"zh-hans","summary":"","title":"第四章：文件管理","url":"/408/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%AC%AC%E5%9B%9B%E7%AB%A0%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/","year":"2024"},{"content":"一、论文总览 该论文提出了一种基于深度卷积神经网络（CNN）的图像分类方法，并在ILSVRC-2010和ILSVRC-2012图像分类挑战赛中取得了新的记录。主要工作和贡献如下：\n训练了当时最大的卷积神经网络，包含5个卷积层和3个全连接层，参数量达6000万个，在ILSVRC-2010测试集上取得了top-1错误率37.5%,top-5错误率17.0%,明显优于之前的方法。 提出了几个新的网络架构优化技巧，如**ReLU激活函数、数据增强、局部响应归一化（Local Response Normalization）、重叠池化(Overlapping Pooling)**等，这些技巧显著提升了网络的性能。 3. 模型并行（model parrallel）: 使用了两个GTX 580 3GB显卡并行训练，实现了高效的GPU卷积操作，显著减少了训练时间。\n使用了随机失活（dropout） 等正则化方法来控制过拟合，并详细分析了其有效性。 在ILSVRC-2012比赛中使用该模型，取得了top-5错误率18.2%的成绩，显著优于第二名的16.4%。 获得了大量视觉知识，如不同层级的卷积核表示，高维特征向量的相似度计算等。 总体而言，该论文通过构建当时最大的卷积神经网络并使用各种优化技巧，在ImageNet等大规模图像数据集上取得了新的state-of-the-art结果，对后续的计算机视觉研究产生了重大影响。\n二、数据预处理/增强 使用的是ImageNet数据集，将所有图像缩放到256x256大小，如果图像尺寸不是正方形，先按比例缩小，然后从中间裁剪出256x256大小的正方形区域。\n注意：此处是直接使用的原始RGB图片，没有进行SIFT的特征提取，这也被看作端到端的训练模型，简化了训练以及推理的流程，这种端到端的思想深刻影响了深度学习模型的发展，目前大多数模型均是采用端到端的方法进行训练的。\n同时论文使用两种方法进行数据增强，第一种是对每张图片进行裁取和翻转，经过处理每张图片会得到十张图片输入模型预测出结果。第二种是对图片的RGB三个颜色通道进行平移和调整，即进行RGB通道强度调整。\n三、AlexNet网络结构分析 论文中的模型作者用了两块GPU进行训练，即使用了模型并行的方法，这种方法会给模型的工程实践带来困难，所以在之后随着显卡性能的提升已很少使用，但目前在NLP领域，LLM（large language model）的训练再次遇到了算力瓶颈，以GPT为代表的大模型再次使用模型并行的方法进行训练。\n模型一共有八层，前五层是CNN层，紧接着跟着两个全连接层，最后是一个1000类的softmax分类层。第二层，第四层，第五层的CNN层后面均跟着Max pooling层和LRM层（local response normalization，作用是防止过拟合）。两层全连接层均使用了Dropout的方法防止过拟合。实际上这两层全连接层是参数最多的，构成了模型训练的瓶颈，也是可能造成过拟合的罪魁祸首，为了防止过拟合，这两层全连接层都使用了Dropout的方法。\nLRM层现在基本已不再使用，其作用现在普遍认为也比较小，故本文不再做介绍，只需知道论文作者使用其本意是为了防止过拟合，提升模型泛化能力。\n其结构图可以简化为在单块gpu上进行训练的。\n图片来源：https://blog.csdn.net/guzhao9901/article/details/118552085?spm=1001.2014.3001.5506\n原图输入256 × 256，实际上进行了随机裁剪，实际大小为227 × 227。\n\u0026lt;span style=\u0026quot;background:#fff88f\u0026quot;\u0026gt;①卷积层C1\nC1的基本结构：卷积–\u0026gt;局部响应归一化(LRN)–\u0026gt;ReLU–\u0026gt;池化\n卷积：输入为227 × 227 × 3，使用96个11×11×3的卷积核，padding = 0，stride = 4。 FeatureMap为(227-11+0×2+4)/4 = 55，即55×55×96。 局部响应归一化(LRN)：对ReLU激活函数前的输出进行局部响应归一化处理。 激活函数：采用ReLU激活函数。 池化：3×3的池化核，padding = 0，stride = 2，池化后的FeatureMap为(55-3+0×2+2)/2=27, 即C1输出为27×27×96（若按照论文将数据分到两个GPU中处理，每组输出为27×27×48）。 \u0026lt;span style=\u0026quot;background:#fff88f\u0026quot;\u0026gt;②卷积层C2\nC2的基本结构：卷积–\u0026gt;局部响应归一化(LRN)–\u0026gt;ReLU–\u0026gt;池化\n卷积：输入为27×27×96，使用256个5×5×96的卷积核，padding = 2， stride = 1。 FeatureMap为(27-5+2×2+1)/1 = 27，即27×27×256。 局部响应归一化(LRN)：在ReLU激活之前同样执行局部响应归一化操作。 激活函数：使用ReLU激活函数。 池化：3 × 3的池化核，padding = 0，stride = 2，池化后的FeatureMap为(27-3+0+2)/2=13, 即C2输出为13×13×256（若按论文方式分配到两个GPU，则每组输出为13×13×128）。 \u0026lt;span style=\u0026quot;background:#fff88f\u0026quot;\u0026gt;③卷积层C3\nC3的基本结构为：卷积–\u0026gt;ReLU\n卷积：输入为13×13×256，使用384个3×3×256的卷积核，padding = 1，stride = 1。 FeatureMap为(13-3+1×2+1)/1 = 13，即13×13×384。 激活函数：采用ReLU激活函数，C3输出为13×13×384（若按照论文将数据分配到两个GPU中处理，则每组输出为13×13×192）。 \u0026lt;span style=\u0026quot;background:#fff88f\u0026quot;\u0026gt;④ 卷积层C4\nC4的基本结构为：卷积–\u0026gt;ReLU\n卷积：输入为13×13×384，使用384个3×3×384的卷积核，padding = 1，stride = 1。 FeatureMap为13×13×384。 激活函数：采用ReLU激活函数，C4输出为13×13×384（若按论文方式分配到两个GPU，则每组输出为13×13×192）。 \u0026lt;span style=\u0026quot;background:#fff88f\u0026quot;\u0026gt;⑤ 卷积层C5\nC5的基本结构为：卷积–\u0026gt;ReLU–\u0026gt;池化\n卷积：输入为13×13×384，使用256个3×3×384的卷积核，padding = 1，stride = 1。 FeatureMap大小仍为13×13×256。 激活函数：采用ReLU激活函数。 池化：池化核大小为3 × 3，padding = 0，stride = 2，池化后的FeatureMap为(13-3+0×2+2)/2=6, C5输出为6×6×256（若按照论文分到两个GPU中处理，每组输出为6×6×128）。 \u0026lt;span style=\u0026quot;background:#fff88f\u0026quot;\u0026gt;⑥全连接层FC6\nFC6的基本结构为：卷积（全连接实现）–\u0026gt;ReLU–\u0026gt;Dropout\n全连接：实际上通过卷积进行等效的全连接操作，输入为6×6×256，使用4096个6×6×256的卷积核，padding = 0，stride = 1， FeatureMap大小为1×1×4096。 激活函数：采用ReLU激活函数。 Dropout：在全连接层中应用Dropout技术，随机丢弃一部分神经元节点，以防止过拟合，最终FC6输出为1×1×4096。 \u0026lt;span style=\u0026quot;background:#fff88f\u0026quot;\u0026gt;⑦全连接层FC7\nFC7的基本结构为：全连接–\u0026gt;ReLU–\u0026gt;Dropout\n全连接：直接进行全连接操作，输入维度为1×1×4096。 激活函数：采用ReLU激活函数。 Dropout：同样应用Dropout防止过拟合，FC7输出为1×1×4096。 \u0026lt;span style=\u0026quot;background:#fff88f\u0026quot;\u0026gt;⑧ 全连接层FC8\nFC8的基本结构为：全连接–\u0026gt;softmax\n全连接：对上一层的输出进行全连接操作，输入维度为1×1×4096。 softmax：最后采用softmax激活函数进行分类，输出维度为1×1×1000，对应1000类物体类别概率分布。 四、ReLU激活函数 $$ ReLU(x)=max(0,x) $$\nReLU函数的导数：\n$$\\frac{dReLU(x)}{dx} = \\begin{cases} 1 \u0026amp; \\text{if } x \u0026gt; 0 \\ 0 \u0026amp; \\text{if } x \\leq 0 \\end{cases}$$ $$ {\\sigma(x)} = \\frac{1}{1 + e^{-x}} $$\nSigmoid函数的导数：\n$$ \\frac{d\\sigma(x)}{dx} = \\sigma(x) * (1 - \\sigma(x)) = \\frac{e^{-x}}{(1 + e^{-x})^2} $$\n一个sigmoid函数大致相当于两个ReLU函数\n关于ReLU的具体分析可以见这篇文章：（暂未更新）\n五、重叠池化（overlapping pooling） 重叠池化(overlapping pooling)是一种改进传统的池化层的策略。传统的池化层通常由间隔一定距离的池化单元组成，每个单元对相邻的神经元输出进行汇总。相邻池化单元所覆盖的区域不重叠。而重叠池化则通过设置池化单元之间的间隔小于池化区域大小来实现重叠，例如使用间隔2像素的池化单元和区域大小为3x3的池化单元。文中提到，相比传统的非重叠池化，使用重叠池化可以将模型在ImageNet数据集上的top-1错误率降低0.4%，top-5错误率降低0.3%。因此，重叠池化是一种改进池化层设计的策略，能够提高模型性能。\n六、Dropout dropout是一种有效的正则化方法，可以减少深度卷积神经网络中全连接层过拟合的问题。\n注意：dropout是解决的全连接层过拟合的问题，所以论文中的两个全连接层使用了dropout，而CNN层没有使用dropout\ndropout的主要思想是：在每次前向传播时，以一定概率（如0.5）将每个隐藏神经元的输出置为0，使得每个神经元在每次前向传播时都有一定的概率不参与计算。论文中认为，这样做的目的是打破全连接层中不同神经元之间的复杂共适应性，迫使每个神经元学习更强大的特征表示，对不同的随机子集都有效。在测试时，不进行dropout，而是将每个神经元的输出乘以一定比例（如0.5），近似于取所有可能dropout网络结果的几何平均。\n现在普遍认为dropout相当于一个L2正则项，可以有效减少过拟合问题，同时让模型更强大。值得注意的是，dropout在训练时会增加迭代收敛次数，但可以大大提高模型的泛化能力。\n七、训练细节 使用随机梯度下降（SGD Stochastic Gradient Descent进行训练，批大小为128，动量为0.9，权重衰减为0.0005。发现权重衰减对模型学习非常重要。 对每个层的权重进行高斯初始化，均值为0，标准差为0.01。注意对权重进行均值为0标准差为0.01的高斯初始化现在非常常见，只有对一些特别深的网络例如GPT这样的模型，才会对权重做均值为0标准差为0.02的高斯初始化。 对第二、四、五卷积层以及全连接隐藏层的神经元偏置进行常数1初始化，其余层偏置初始化为常数0。（偏置常数1初始化理论性不强，多为实验炼丹结果，现在普遍将偏置初始化为常数0，结果也不差） 使用所有层相等的固定学习率，并在验证损失停止改善时手动将学习率变为原来的十分之一。初始学习率为0.01，训练过程中降低3次。 训练了大约90个周期，耗时5-6天在两块NVIDIA GTX 580 3GB GPU上进行训练。 损失函数是最小化交叉熵，即最大化标签的正确对数概率。 八、PyTorch代码实现 1import time 2import torch 3from torch import nn, optim 4import torchvision 5device = torch.device(\u0026#39;cuda\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39;) 6 7class AlexNet(nn.Module): 8 def __init__(self): 9 super(AlexNet, self).__init__() 10 self.conv = nn.Sequential( 11 nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding 12 nn.ReLU(), 13 nn.MaxPool2d(3, 2), # kernel_size, stride 14 # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数 15 nn.Conv2d(96, 256, 5, 1, 2), 16 nn.ReLU(), 17 nn.MaxPool2d(3, 2), 18 # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。 19 # 前两个卷积层后不使用池化层来减小输入的高和宽 20 nn.Conv2d(256, 384, 3, 1, 1), 21 nn.ReLU(), 22 nn.Conv2d(384, 384, 3, 1, 1), 23 nn.ReLU(), 24 nn.Conv2d(384, 256, 3, 1, 1), 25 nn.ReLU(), 26 nn.MaxPool2d(3, 2) 27 ) 28 # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合 29 self.fc = nn.Sequential( 30 nn.Linear(256*5*5, 4096), 31 nn.ReLU(), 32 nn.Dropout(0.5), 33 nn.Linear(4096, 4096), 34 nn.ReLU(), 35 nn.Dropout(0.5), 36 # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000 37 nn.Linear(4096, 10), 38 ) 39 40 def forward(self, img): 41 feature = self.conv(img) 42 output = self.fc(feature.view(img.shape[0], -1)) 43 return output ","date":1708528866,"headings":[{"anchor":"一论文总览","title":"一、论文总览"},{"anchor":"七训练细节","title":"七、训练细节"},{"anchor":"三alexnet网络结构分析","title":"三、AlexNet网络结构分析"},{"anchor":"二数据预处理增强","title":"二、数据预处理/增强"},{"anchor":"五重叠池化overlapping-pooling","title":"五、重叠池化（overlapping pooling）"},{"anchor":"八pytorch代码实现","title":"八、PyTorch代码实现"},{"anchor":"六dropout","title":"六、Dropout"},{"anchor":"四relu激活函数","title":"四、ReLU激活函数"}],"kind":"page","lang":"zh-hans","series":["AI论文"],"summary":"","title":"AlexNet论文精读及模型详解","url":"/ai%E8%AE%BA%E6%96%87/%E7%BB%8F%E5%85%B8ai%E8%AE%BA%E6%96%87/alexnet%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%E5%8F%8A%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/","year":"2024"},{"content":"一、进程与线程 1. 进程的概念和特征 （1）进程的概念\n进程是程序的一次执行过程（进程与程序的关系） 进程实体由程序段、相关数据段和PCB（进程控制块）构成 创建和删除进程的本质是创建和删除PCB PCB是进程存在的唯一标志 （2）进程的特征\n动态性 并发性 独立性 异步性 其中，动态性是进程最基本的特性\n2. 进程的状态与转换 进程状态 描述 创建状态 分配进程标识符并申请PCB\u0026mdash;-分配资源\u0026mdash;-初始化PCB\u0026mdash;-插入就绪队列 就绪状态 已分配到除CPU外的所有必要资源 执行状态 单CPU中同一时刻只能有一个进程在执行 阻塞状态 等待某一事件（通常是等待输入输出完成，比如等待打印机空闲） 终止状态 操作系统善后处理\u0026mdash;-PCB清零并返还系统 挂起操作 为了系统和用户观察分析进程。 在操作系统中，挂起原语（Suspend）和激活原语（Activate）与挂起状态（Suspended State）的关系是管理进程生命周期的一部分。\n挂起原语（Suspend）： 挂起原语是操作系统中用于将进程从运行状态或就绪状态转换到挂起状态的一个系统调用或操作。当一个进程被挂起时，它通常会释放所占用的资源，并且其状态会被设置为挂起状态。挂起状态意味着进程不会被操作系统调度执行，直到它被激活或者被终止。\n激活原语（Activate）： 激活原语与挂起原语相反，它用于将处于挂起状态的进程恢复到就绪状态。当进程被激活时，它的状态会被设置为就绪，这意味着它可以被操作系统调度执行，只要它满足执行条件（如没有更高的优先级进程正在执行）。\n挂起状态（Suspended State）： 挂起状态是进程可以进入的一种状态，当进程被挂起原语操作时，它就会进入这种状态。在挂起状态下，进程不会消耗CPU资源，也不会执行任何操作，直到它被激活。挂起状态通常用于暂停进程以便进行维护、调试或等待某些事件（如等待I/O操作完成）。\n总结来说，挂起原语和激活原语是操作系统用来控制进程状态转换的工具，而挂起状态则是进程在这些转换中可能经历的一种状态。通过这些操作，操作系统能够灵活地管理进程，以满足用户和系统的需求。\n3. 进程的组织 （1）进程控制块（PCB） （2）程序段\n能被进程调度到CPU执行的程序代码段（多个进程可以运行同一个程序） （3）数据段\n程序加工处理的原始数据或程序执行时产生的中间结果或最终结果 4. 进程控制 （1）进程的创建\n①父子进程 父子进程之间代码共享，数据独有 关系 一个进程创建另一个进程，创建者称为父进程，被创建者称为子进程 撤销子进程时，资源要归还父进程；撤销父进程时，要同时撤销所有子进程 子进程可以继承父进程所有资源 父子进程可以共享一部分资源，子进程创建也会分配自己独有的资源（2020） 父子进程不能共享虚拟地址空间（2020） ②引起进程创建的事件\n用户登录、作业调度、系统提供提供服务、应用请求、启动程序执行（设备分配不会引起进程创建）（2010） ③进程创建过程\n分配进程标识符并申请PCB\u0026ndash;\u0026gt;分配资源\u0026ndash;\u0026gt;初始化PCB\u0026ndash;\u0026gt;插入就绪队列（2021） （2）进程的终止\n引起进程终止的事件：\n正常结束：进程的任务已经完成并准备退出运行 异常结束：存储区越界、保护错、非法指令、特权指令错、运行超时、算术运算错、I/O故障等 外部干预：操作员或操作系统干预、父进程请求、父进程终止 （3）进程的阻塞和唤醒\nBLOCK原语是自我调用（自己阻塞自己），Wake up原语是被其它进程调用（其它进程唤醒） 5. 进程的通信 进程间的低级通信方式为PV操作，后面会细讲，这里先详细介绍一下高级通信方式\n（1）共享存储\n进程空间是独立的，一般不能被互相直接访问，所以需要一块共享空间作为中介 进程对共享空间的访问必须是互斥的 两个不同进程不能通过全局变量通信，全局变量是对同一进程而言的 分类 低级方式：基于共享数据结构 高级方式：基于共享存储区 （2）消息传递系统\n将数据封装在消息中，使用发送和接收原语在进程间传递消息从而完成数据交换 分类：\n通信方式 描述 直接通信方式 使用OS提供的发送原语直接将消息发送给目标进程 间接通信方式 通过共享中间实体（邮箱）,需要发送和接收原语 （3）管道通信系统 管道通信系统多次在选择题考察到，而且容易混淆，需要格外注意： ① 管道：连接一个读进程和写进程的共享文件，是一种独立的文件系统 ② 只存在于内存中，大小不受磁盘容量的影响（2014） ③ 管道满，写管道write()调用被阻塞；管道空，读管道read()调用被阻塞（2014） ④ 特点：同一时刻数据单向流动，半双工通信、必须写满或者读满（2014） ⑤ 一个管道的读进程只能有一个，写进程可以有多个（2014） 6. 线程和多线程模型 （1）线程的基本概念\n引入进程是为了多道程序并发执行；引入线程是未了减小程序切换的开销 线程组成：线程ID、程序计数器、寄存器集合、堆栈 同一进程中的线程切换不会引起进程切换；不同进程中的线程切换会引起进程切换 线程不拥有系统资源（仅有一点必不可少的资源） 同一进程的不同线程 线程共享资源：地址空间（拥有相同的地址空间）、全局变量、打开的文件、子进程（2012） 线程独享资源：程序计数器、寄存器、栈、状态字（2011） （2）线程与进程的比较\n进程是资源分配的基本单位；线程是处理机调度的基本单位 （3）线程的状态与转换\n执行态、就绪态、阻塞态（类比线程） （4）线程的实现方式\n①用户级线程\n有关线程管理（创建、撤销和切换等）的所有工作都在用户空间完成 内核意识不到线程的存在，处理及调度仍以进程为单位 内核每次分配给一个进程一个CPU，因此进程中仅有一个线程能执行 可以在不支持线程的操作系统上实现（2019） ②内核级线程\n有关线程管理的所有工作都在内核空间实现（2019） 处理机调度以线程为单位 内核能同时调度统一进程中的多个线程并行执行 内核级线程比用户级线程的切换效率低（2019） ③组合方式\n（5）多线程模型\n模型 描述 多对一模型 一个进程的多个用户级线程映射到一个内核级线程上。一个线程访问内核时阻塞则整个进程都被阻塞；任何时候只有一个线程能够访问内核 一对一模型 每个用户级线程都有一个内核级线程与之对应。一个线程被阻塞后，允许另一个线程运行，但开销较大 多对多模型 用户级线程与内核级线程之间存在多对多的映射关系。开销不大且并发性较高 二、处理机调度 1. 调度的概念 2. 调度的目标 性能指标 描述 CPU利用率 CPU在单位时间内用于处理作业的比率 系统吞吐量 单位时间内CPU完成作业的数量 周转时间 作业完成时间 - 作业提交时间 平均周转时间 n个作业的周转时间平均值 带权周转时间 作业周转时间/作业运行时间 平均带权周转时间 n个带权周转时间的平均值 等待时间 进程处于等待处理机的时间 响应时间 用户提交请求到系统首次产生响应所需要的时间 3. 调度的实现 （1）调度时机\n不能进行进程调度与切换的情况\n情况 描述 处理中断时 中断处理复杂很难同时进行进程切换 进程在操作系统内核临界区中 2012年真题指出进程在临界区时可以调度 其它需要完全屏蔽中断的原子操作中 加锁、解锁、中断现场保护、恢复 （2）进程调度方式\n非抢占调度（非剥夺） 不能用于分时系统和大多数实时系统 抢占式调度（剥夺） （3）闲逛进程\n进程切换时若没有其它进程就绪就执行闲逛进程 闲逛进程的优先级最低，只要有进程就绪就会立即让出处理机 闲逛进程不需要CPU之外的资源，因此不会被阻塞 4. 典型的调度算法 （1）先来先服务（FCFS）调度算法\n对长作业有利；对短作业不利 有利于CPU繁忙型作业（一般是长作业）；不利于I/O繁忙型作业（一般是短作业） （2）短作业优先（SJF）调度算法\n对长作业不利；对短作业有利 分为抢占式短作业优先和非抢占式式短作业优先（都会造成饥饿现象）（2011、2014） 平均等待时间、平均周转时间最少 （3）优先级调度算法\n调度相关特性 描述 是否可以抢占 剥夺式、非剥夺式 优先级是否改变 静态优先级、动态优先级 进程优先级设置原则 系统进程\u0026gt;用户进程；交互式进程\u0026gt;非交互式进程；I/O型进程\u0026gt;计算型进程（2013） （4）高响应比优先调度算法\n综合考虑了每个进程的等待时间和执行时间（2009） （5）时间片轮转调度算法\n主要适用于分时系统 时钟中断发生后，系统会修改当前进程在时间片内的剩余时间（2017） 时间片太大将退化为先来先服务调度算法；时间片太小处理机频繁进行进程切换则开销增大（2017） （6）多级反馈队列调度算法（2019、2020）\n步骤 设置多个队列，并为每个序列设置不同的优先级 优先级越高的队列中时间片就越小，每个队列都采用FCFS算法 进程进入内存后，先放入第1级队列的队尾，若未执行完，放入下一队列末尾 只有当前面的队列执行完，才能执行后面的队列 若有更高优先级的队列进入，当前进程放置所处队列的队尾，执行新来的进程 特点 对很多作业都能较好处理；可能造成饥饿 不会产生饥饿的调度算法：先来先服务、高响应比、时间片轮转。会产生饥饿：短作业优先、多级反馈队列（2011、2014） 5. 进程切换 （1）基本概念\n上下文：某一时刻CPU寄存器和程序计数器的内容 上下文切换：CPU从一个进程切换到另一个进程保存当前进程状态并回复另一个进程状态的过程 进程切换要在内核支持下完成 （2）上下文切换流程\n挂起一个进程，保存其CPU上下文，更新其PCB并移入相应的队列 选择新的进程，更新其PCB并转到程序计数器所指位置执行，恢复该进程的CPU上下文 （3）区分\n操作系统概念 解释 模式切换 用户态和内核态之间的切换 调度 决定资源分配给哪一个进程（一般现有资源调度后有进程切换） 上下文切换 CPU从一个进程切换到另一个进程，保存当前进程的状态，并恢复另一个进程的状态的过程 三、同步与互斥 1. 同步与互斥的基本概念 （1）基本概念\n概念 解释 临界资源 一次只允许一个进程使用的共享资源（打印机、共享变量、共享缓冲区、公用队列） 临界区 每个进程中访问临界资源的代码段 临界资源访问过程 进入区\u0026ndash;\u0026gt;临界区\u0026ndash;\u0026gt;退出区\u0026ndash;\u0026gt;剩余区 （2）直接相互制约（同步）\n进程为完成同一项任务而协调工作次序所产生的制约关系 （3）间接相互制约（互斥）\n对临界资源只能互斥地访问 互斥机制应遵循的规则：\n规则 描述 空闲让进 临界区空闲时，允许进程进入 忙则等待 已有进程进入临界区时，其他进程必须等待 有限等待 请求进入临界区的进程应在有限时间内进入 让权等待 当进程不能进入临界区时，应立即释放处理器（不是必须遵守的规则） 2. 实现临界区互斥的基本方法 （1）软件实现\n（2）硬件实现\n中断屏蔽方法: 进程在执行临界区代码时，通过关中断防止其它进程进入临界区\n3. 互斥锁 进程在进入临界区时获得锁，在退出临界区时释放锁 函数acquire()获得锁，函数release()释放锁，两者执行必须是原子操作。因此互斥锁通常采用硬件机制实现 主要缺点：忙等待 4. 信号量 （1）特点\n是低级进程通信，因为效率低、对用户不透明 PV操作是原子操作不可被中断；PV操作不是系统调用 V操作能让进程进入就绪状态；P操作能让进程进入阻塞状态 value为正表示还有同类资源；value为-m表示有m个进程处于阻塞态等待使用资源（2010） P（S）和wait（S）等价；V（S）和signal（S）等价（2022） （2）分类\n信号量类型 描述 整型信号量 wait(S): while(S\u0026lt;=0); S=S-1（这里可能卡在while语句一直循环占用处理器，故不遵循让权等待） 记录型信号量 增加一个进程链表指针list，用于链接所有等待该信号量的进程。在wait操作后，进程会添加到链表中等待，实现了让权等待。（2018） （3）应用\n同步/互斥类型 描述 进程同步 使用信号量实现，确保X在Y之前执行。初值S为资源数量。 S=0; X；V;P；Y 进程互斥 使用信号量实现，确保同一时刻只有一个进程能够进入临界区。 S=1; P1（P;临界区；V）；P2（P；临界区；V） 实现前驱关系 进程同步中S初值为资源数量，进程互斥中S初值必须为1 5. 管程机制 （1）组成\n管程的名称 局部于管程内部的共享数据结构说明 对该数据结构进行操作的一组过程（或函数） 对局部于管程内部的共享数据设置初始值的语句 （2）特点\n由编译语言支持的进程同步机制（2016） 管程可以用于实现进程的同步或互斥（2016） 所有进程都只能用过管程访问临界资源，管程每次只允许一个进程进入（2016） （3）条件变量\n一种抽象数据类型，保存一个链表，用于记录因该条件变量而阻塞的所有进程 x.wait：把进程挂在x对应的阻塞队列上；x.signal：唤醒x的阻塞队列上的一个进程（2018） 若没有等待进程，x.signal不会有任何操作，这与信号量中的signal不同（会修改信号量变量的值） 6. 经典同步问题 大题部分细讲 四、死锁 1. 死锁的定义 两个或两个以上进程因竞争资源而相互等待，若无外力作用这些进程都无法向前推进（2019）\n2. 死锁产生的原因 （1）系统资源的竞争\n竞争不可抢占性资源（磁带、打印机） （2）进程推进顺序非法\n问题描述 描述 竞争可消耗资源 信号量引起死锁 进程推进顺序不当 1. 请求和释放资源的顺序不当（A申请B占有的资源，B申请A占有的资源）2. 信号量使用不当（A等待B发消息，B等待A发消息） 3. 产生死锁的必要条件 产生死锁的四个必要条件必须牢固掌握！！！ 死锁条件 描述 互斥条件 进程对资源只能互斥访问（一段时间内只能有一个进程访问） 不可抢占条件 进程所获得的资源在未使用完毕前不可被其他进程剥夺。 请求和保持条件 进程保持了至少一个资源的同时请求其他资源。 循环等待条件 形成循环等待链，每个进程已获得的资源同时被下一个进程所请求。 4. 死锁的处理策略 （1）预防死锁\n死锁条件 破坏策略 破坏互斥条件 将临界资源改为可共享资源（SPOOLing技术） 破坏不可抢占 进程提出资源请求不能得到满足时释放自己已保持的全部资源 破坏请求和保持 进程在开始之前，必须一次性申请所需全部资源进程运行过程中逐步释放自己用过的资源再请求新资源 破坏循环等待 对系统所有资源线性排序，进程必须按顺序请求资源\n（2）避免死锁\n原理\n在资源动态分配过程中，防止系统进入不安全状态 银行家算法\n可以求出安全队列；需要知道进程所需全部资源数 银行家算法只能避免死锁，不能检测死锁（2013、2019） n个进程，每个进程所需设备为x1,x2\u0026hellip;xn，则保证不发生死锁的最小设备数为(x1-1)+(x2-1)+\u0026hellip;(xn-1)+1（经常考） 不安全状态与死锁\n死锁一定是不安全状态；不安全状态不一定是死锁（2013） （3）检测死锁\n资源分配图（有向图） （学会简化资源分配图） 死锁定理：S为死锁状态的充分条件是：当且仅当S的资源分配图是不可完全简化的 （4）解除死锁\n方法 描述 资源剥夺法 抢占某些死锁进程的资源分配给其它死锁进程（2019） 撤销进程法 撤销部分或全部死锁进程并剥夺这些进程的资源 进程回退法 让进程逐个回退到足以回避死锁的地步 ","date":1708509852,"headings":[{"anchor":"1-同步与互斥的基本概念","title":"1. 同步与互斥的基本概念"},{"anchor":"1-死锁的定义","title":"1. 死锁的定义"},{"anchor":"1-调度的概念","title":"1. 调度的概念"},{"anchor":"1-进程的概念和特征","title":"1. 进程的概念和特征"},{"anchor":"2-实现临界区互斥的基本方法","title":"2. 实现临界区互斥的基本方法"},{"anchor":"2-死锁产生的原因","title":"2. 死锁产生的原因"},{"anchor":"2-调度的目标","title":"2. 调度的目标"},{"anchor":"2-进程的状态与转换","title":"2. 进程的状态与转换"},{"anchor":"3-互斥锁","title":"3. 互斥锁"},{"anchor":"3-产生死锁的必要条件","title":"3. 产生死锁的必要条件"},{"anchor":"3-调度的实现","title":"3. 调度的实现"},{"anchor":"3-进程的组织","title":"3. 进程的组织"},{"anchor":"4-信号量","title":"4. 信号量"},{"anchor":"4-典型的调度算法","title":"4. 典型的调度算法"},{"anchor":"4-死锁的处理策略","title":"4. 死锁的处理策略"},{"anchor":"4-进程控制","title":"4. 进程控制"},{"anchor":"5-管程机制","title":"5. 管程机制"},{"anchor":"5-进程切换","title":"5. 进程切换"},{"anchor":"5-进程的通信","title":"5. 进程的通信"},{"anchor":"6-线程和多线程模型","title":"6. 线程和多线程模型"},{"anchor":"6-经典同步问题","title":"6. 经典同步问题"},{"anchor":"一进程与线程","title":"一、进程与线程"},{"anchor":"三同步与互斥","title":"三、同步与互斥"},{"anchor":"二处理机调度","title":"二、处理机调度"},{"anchor":"四死锁","title":"四、死锁"}],"kind":"page","lang":"zh-hans","summary":"","tags":["操作系统"],"title":"第二章：进程的描述与控制","url":"/408/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%AC%AC%E4%BA%8C%E7%AB%A0%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%8F%8F%E8%BF%B0%E4%B8%8E%E6%8E%A7%E5%88%B6/","year":"2024"},{"content":"一、内存管理概念 1. 基本原理和要求 （1）程序执行过程 ①编译\n编译形成若干目标模块，形成汇编文本 ②链接\n把一组目标模块和需要的库函数链接在一起形成一个装入模块 形成整个程序完整逻辑地址空间（2011） 分类： 链接方式 描述 静态链接方式 在程序运行之前把目标模块和库函数链接成一个完整的装配模块 装入时动态链接 边装入边链接 运行时动态链接 程序执行时需要该模块时才链接 ③装入\n把程序装入内存，且逻辑地址变为物理地址 分类： 装入方式 描述 特点 绝对装入方式 编译时便产生绝对地址，只适合单道程序环境 编译时确定内存位置，运行时无需改变地址 静态重定位 装入时对地址“重定位”，将逻辑地址一次性变为物理地址 作业装入内存时，必须分配其要求的全部内存空间；作业装入内存后不能再移动，只适合固定分区 动态重定位 装入内存后仍为逻辑地址，到程序真正执行时才地址转换，需要重定位寄存器的支持 程序只需装入部分代码就可运行；需要硬件支持（动态重定位寄存器） （2）进程的内存映像 （3）内存保护 基本概念 分区分配内存管理方式的主要保护措施是界地址保护（2009） 内存保护需要由操作系统和硬件机构合作完成 保护方法 设置上下限寄存器，每当CPU访问地址时进行比较判断是否越界 重定位寄存器和界地址寄存器配合 首先逻辑地址和界地址寄存器（含逻辑地址最大值）进行比较，判断是否越界 然后逻辑地址+重定位寄存器（含物理地址最小值）=物理地址 （4）内存共享 可重入代码（纯代码）：允许多个进程同时访问但不允许任何进程修改 2. 连续分配 分配策略 描述 特点 首次适应 空闲分区按地址递增顺序链接。 会留下很多碎片，但通常最快最好 循环首次适应 空闲分区按地址递增顺序链接 从上次找到的空闲分区的下一个空闲分区查找 最佳适应 空闲分区按容量递增顺序链接 最容易产生内存碎片（2019） 最坏适应 空闲分区按容量递减顺序链接 产生碎片的可能最小、会很快导致没有可用的大内存块 动态可重定位分区分配 紧凑：移动内存中作业位置，把分散的小分区拼接成大分区 3. 离散分配 （1） 分页 ①地址结构：页号+页内偏移量\n②分页存储基本概念\n用户程序分为“页”或“页面”，内存空间分为“物理块”、“页框”或“页帧”；它们都大小相同 地址结构：页号+页内地址 页面过大会使页内碎片增多；页面过小会使页表过大占用内存 页表 系统为每个进程建立一张页表，记录页号和物理块号的对应关系 页表由页表项组成，大多驻留在内存中 ③基本地址变换机构\n在系统中有一个页表寄存器（PTR），存放页表在内存的起始物理地址和页表长度（2021） 进程未执行时页表信息存放在进程PCB中，调度到进程时才把信息装入页表寄存器 ④快表\n也叫相联存储器（TLB），在地址变换机构中增设的，为了减少对内存的访问次数（经常考） ⑤两级页表\n目的：解决页表大而连续问题 页表级别 特点 单级页表 会产生很多页表，这些页表需要连续存储且进程执行时必须全部调入内存 二级页表 二级页表在进程执行时只需调入一级页表并调入所需页表 两级页表的地址结构：页目录号+页号+页内偏移量（经常考） 特点 顶级页表最多只能占一个页面 多级页表不能减少页表所占用的内存空间，但是能减少占用的连续内存空间（2014） 多级页表会减慢地址变换速度，可能增加缺页中断次数 （2）分段 ①地址结构：段号+段内偏移量（2009、2016）\n②特点\n呈现二维特性：既包含地址空间，又标识逻辑关系 各段可以不等长、可以不相邻 优点：方便编程；信息共享；信息保护；动态链接、动态增长等 ③分页和分段的区别\n概念 区别 页 信息的物理单位，大小固定，一维的。为了系统，对用户不可见。 段 信息的逻辑单位，大小不定，二维的。为了满足用户的需求。 （3） 段页式 地址结构：段号+段内页号+页内地址 一个进程中只有一个段表，每个段对应一个页表 段表寄存器和页表寄存器都有两个作用：在段表或页表中寻址、判断是否越界 二、虚拟内存管理 1. 虚拟内存基本概念 （1）传统存储方式特征 一次性：作业必须一次性全部装入内存后才能开始运行 驻留性：作业从开始运行到结束一直在内存中不会被换出 （2）局部性原理 局部性概念 描述 时间局部性 某条指令执行后不久可能再次执行，某个数据访问后不久可能被再次访问（程序的循环执行） 空间局部性 某个存储单元访问后不久其附近的存储单元会被访问（指令的顺序执行、数据以向量、数组、表等形式簇聚存储） （3）虚拟内存的特征 特征 描述 多次性 作业无需一次性全部装入内存，可以在需要时分多次调入内存。 对换性 程序和数据无需常驻内存，可以在内存和外存之间进行交换。 虚拟性 用户看到的逻辑内存容量远远大于实际的物理内存容量。 （4）虚拟内存技术的实现 必须建立在离散分配（分页分段）的内存管理方式基础之上（2012） 三种实现方式：请求分页、请求分段、请求段页式 虚拟内存的实际容量=min{内存+外存，地址位数表示能力}（2012） 虚拟内存的最大容量=地址位数的表示能力 2. 请求分页管理 （1）页表机制\n页表项： 页表项字段 描述 状态位 该页是否在内存（程序访问时参考） 访问字段 访问字段：页面访问次数（页面置换算法使用） 修改位 页面调入内存后是否被修改（页面置换时是否写回外存） 外存地址 页面对应的物理块号（地址转换使用） （2）缺页中断机构\n缺页中断属于内部异常，一条指令在执行期间可能产生多次缺页中断 3. 页框分配 （1）内存分配策略 ①固定分配局部置换\n固定分配：每个进程固定数目的物理块； 局部置换:只能在该进程所分配的内存页面进行调换 ②可变分配全局置换\n可变分配：每个进程的物理块可适当增加或减少； 全局置换：发现缺页将OS保留的空闲物理块取出一块分配 ③可变分配局部置换\n正常情况下是固定分配局部置换 若频繁缺页或缺页率一直很低，就采用可变分配全局置换 ④固定分配全局置换\n不存在（2015） （2）调入策略 ①何时调入\n调页策略 描述 预调页策略 一次调入若干个相邻的页，但页面可能不会被访问（主要用于进程的首次调入，由程序员指定） 请求调页策略 当发现页面不在内存时再调入，页面一定会被访问（所学的虚拟存储器就是采用这种方法） ②从何处调入\n外存划分 描述 I/O速度特点 文件区 用于存放文件，通常采用连续分配方式。 I/O速度较慢，因为涉及大量数据的读写。 对换区 用于存放对换页面，通常采用离散分配方式。 I/O速度较快，因为每次只访问少量数据。 情况 调入方法 若对换区足够大 都从对换区调入 若对换区不够大 不会修改的从文件区调入；可能被修改的换出时调到对换区，以后从对换区调入 UNIX方式 未运行过的页面从文件区调入；运行过但又被调出页面从对换区调入 ③如何调入\n当进程所访问的页面不在内存中时（存在位为0)，便向CPU发出缺页中断，中断响应后便转入缺页中断处理程序。该程序通过查找页表得到该页的物理块，此时如果内存未满，则启动磁盘IO，将所缺页调入内存，并修改页表。如果内存已满，则先按某种置换算法从内存中选出一页准备换出;如果该页未被修改过（修改位为0)，则无须将该页写回磁盘;但是，如果该页已被修改(修改位为1)，则必须将该页写回磁盘，然后将所缺页调入内存，并修改页表中的相应表项，置其存在位为1。调入完成后，进程就可利用修改后的页表形成所要访问数据的内存地址。（2011） 4. 页面置换算法 （1）最佳（OPT）置换算法 置换出未来最长时间不被访问的页面（不可实现） （2）先进先出（FIFO）置换算法 设第一个队列，总是淘汰最先进入内存的页面 可能出现Belady异常，即分配的物理块增多，缺页次数不减反增（2014） （3）最近最久未使用（LRU）置换算法 置换出最近最久未使用的页面 需要一组寄存器或一个栈的支持 （4） Clock置换算法 ①简单型\n某页被访问，置1；没有被访问，为0 算法步骤：置换算法检查到0，换出，检查到1，置0，这样循环进行 ②改进型\n再考虑一个因素：置换代价（修改过的页面置换代价大），将所有页面分为四类（访问位，修改位） 算法步骤 第一轮：寻找00的页面置换，不更改访问位和修改位 第二轮：寻找01的页面置换，同时将扫描过得页面的访问位置0 重复第一轮、第二轮\u0026hellip;\u0026hellip; 改进型Clock置换算法的页面置换顺序：00--01--10--11 5. 抖动和工作集 （1）抖动（颠簸）\n概念：刚刚换出的页面马上又要换入主存，刚刚换入的页面马上又要换出主存 产生原因：系统中运行的进程太多，内存分配给每个进程的物理块太少 抖动的预防策略 采用局部置换策略 使用工作集算法 利用“L=S”调节缺页率 L：缺页之间平均时间；S：置换一个页面所需时间 暂停一部分进程（增大对换区容量没有用）（2011） （2）工作集\n概念 解释 工作集 某段时间内进程访问的页面集合 工作窗口 这段时间的长度 驻留集 进程分配的物理页框的集合 工作窗口一般要远大于工作集；驻留集一般大于工作集 6. 内存映射文件 概念 将磁盘块映射到内存块，从而把进程对磁盘块的访问转换为对内存页的访问 作用 多个进程允许并发地内存映射同一个文件，以便实现数据共 很多时候共享内存是通过内存映射实现的，进程可以通过共享内存来通信 1\\documentclass{article} 2\\usepackage{resume} % Assuming a custom resume.cls file is used 3\\usepackage{hyperref} 4\\usepackage[margin=1in]{geometry} 5\\usepackage{fancyhdr} 6\\usepackage{tabularx} 7\\pagestyle{fancy} 8\\fancyhf{} 9\\rhead{\\today} 10\\lhead{[Your Name]} 11\\rfoot{\\thepage} 12\\begin{document} 13\\begin{center} 14 {\\Large [Your Name]} \\\\ 15 \\textit{[Address]} \\\\ 16 \\textit{[Phone]} \\\\ 17 \\textit{[Email]} \\\\ 18 \\textit{[LinkedIn Profile]} (if applicable) \\\\ 19\\end{center} 20\\section*{EDUCATION} 21\\begin{tabularx}{\\linewidth}{@{}l X@{}} 22 \\textbf{South Central University, Changsha, Hunan, China} \u0026amp; Bachelor of Law, October 2020 - July 2024 \\\\ 23 \u0026amp; \\textit{GPA: 89.79/100, ranked 2nd out of 28 students} \\\\ 24 \u0026amp; \\textit{Language Proficiency: IELTS 7.5, CET-6 559, CET-4 586} \\\\ 25 \u0026amp; \\textit{Awards: 3rd Prize in National English Competition for College Students (2023), 2nd Prize in 21st Century Cup National English Speaking Competition (2023)} \\\\ 26 \u0026amp; \\textit{Bar Exam: Passed the Objective Exam (2023), pending the Subjective Exam} \\\\ 27 \u0026amp; \\textit{Future Education: Admitted to Master of Law program in International Financial Law at Shanghai University of Finance and Economics} \\\\ 28\\end{tabularx} 29\\section*{WORK EXPERIENCE} 30\\begin{tabularx}{\\linewidth}{@{}l X@{}} 31 \\textbf{Guohao Lawyers (Changsha Office), Changsha, Hunan, China} \u0026amp; Legal Assistant, June - August 2022 \\\\ 32 \u0026amp; \\textit{Assisted in the issuance of USD bonds for Chinese companies, utilizing knowledge of international economic law and business law} \\\\ 33 \u0026amp; \\textit{Participated in all-English projects, providing legal opinions to bond issuers} \\\\ 34\\end{tabularx} 35\\section*{SOCIAL RESPONSIBILITY} 36\\begin{tabularx}{\\linewidth}{@{}l X@{}} 37 \\textbf{Legal Publicity and Education Practice in Miluo City, Hunan, China} \u0026amp; Project Leader, June - August 2022 \\\\ 38 \u0026amp; \\textit{Led a team to Miluo City to conduct legal publicity, drug prevention work research, and dissemination of legal knowledge} \\\\ 39 \u0026amp; \\textit{Achievements: University-level approval for the project, 1st Prize in the 17th Shenghua Cup extracurricular academic competition, selected for SKSUNNY Happy Action by China Youth Development Foundation, published reports in local media} \\\\ 40\\end{tabularx} 41\\section*{RESEARCH EXPERIENCE} 42\\begin{tabularx}{\\linewidth}{@{}l X@{}} 43 \\textbf{Entrepreneurship Training Project for College Students, South Central University, Changsha, Hunan, China} \u0026amp; Deputy Project Leader, May 2023 - Present \\\\ 44 \u0026amp; \\textit{Conducted research in over 10 mines and visited over 20 companies, leading to the establishment of an ecological restoration service system for mines} \\\\ 45 \u0026amp; \\textit{Achieved national-level approval for the project, integrating technical support and legal policy support} \\\\ 46\\end{tabularx} 47\\section*{EXTRACURRICULAR ACTIVITIES} 48\\begin{tabularx}{\\linewidth}{@{}l X@{}} 49 \\textbf{Challenge Cup Competition, South Central University, Changsha, Hunan, China} \u0026amp; Deputy Project Leader, June 2022 - May 2023 \\\\ 50 \u0026amp; \\textit{Conducted field surveys and questionnaires on elderly couples with chronic diseases in 6 communities in Changsha} \\\\ 51 \u0026amp; \\textit{Achieved 3rd Prize in university-level competition} \\\\ 52\\end{tabularx} 53\\section*{HONORS \\\u0026amp; AWARDS} 54\\begin{tabularx}{\\linewidth}{@{}l X@{}} 55 \\textbf{Outstanding Individual in Social Practice, South Central University} \u0026amp; (2022) \\\\ 56 \\textbf{Outstanding Student, South Central University} \u0026amp; (2022) \\\\ 57 \\textbf{3rd Prize, National English Competition for College Students} \u0026amp; (2023) \\\\ 58 \\textbf{2nd Prize, 21st Century Cup National English Speaking Competition} \u0026amp; (2023) \\\\ 59 ","date":1708509852,"headings":[{"anchor":"1-分页","title":"（1） 分页"},{"anchor":"1-基本原理和要求","title":"1. 基本原理和要求"},{"anchor":"1-虚拟内存基本概念","title":"1. 虚拟内存基本概念"},{"anchor":"1传统存储方式特征","title":"（1）传统存储方式特征"},{"anchor":"1内存分配策略","title":"（1）内存分配策略"},{"anchor":"1最佳opt置换算法","title":"（1）最佳（OPT）置换算法"},{"anchor":"1程序执行过程","title":"（1）程序执行过程"},{"anchor":"2-请求分页管理","title":"2. 请求分页管理"},{"anchor":"2-连续分配","title":"2. 连续分配"},{"anchor":"2先进先出fifo置换算法","title":"（2）先进先出（FIFO）置换算法"},{"anchor":"2分段","title":"（2）分段"},{"anchor":"2局部性原理","title":"（2）局部性原理"},{"anchor":"2调入策略","title":"（2）调入策略"},{"anchor":"2进程的内存映像","title":"（2）进程的内存映像"},{"anchor":"3-段页式","title":"（3） 段页式"},{"anchor":"3-离散分配","title":"3. 离散分配"},{"anchor":"3-页框分配","title":"3. 页框分配"},{"anchor":"3内存保护","title":"（3）内存保护"},{"anchor":"3最近最久未使用lru置换算法","title":"（3）最近最久未使用（LRU）置换算法"},{"anchor":"3虚拟内存的特征","title":"（3）虚拟内存的特征"},{"anchor":"4-clock置换算法","title":"（4） Clock置换算法"},{"anchor":"4-页面置换算法","title":"4. 页面置换算法"},{"anchor":"4内存共享","title":"（4）内存共享"},{"anchor":"4虚拟内存技术的实现","title":"（4）虚拟内存技术的实现"},{"anchor":"5-抖动和工作集","title":"5. 抖动和工作集"},{"anchor":"6-内存映射文件","title":"6. 内存映射文件"},{"anchor":"一内存管理概念","title":"一、内存管理概念"},{"anchor":"二虚拟内存管理","title":"二、虚拟内存管理"}],"kind":"page","lang":"zh-hans","summary":"","tags":["操作系统"],"title":"第三章：内存管理","url":"/408/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","year":"2024"},{"content":"一、仓库初始化和克隆 初始化新仓库： 1git init 该命令会在当前目录下创建一个名为.git的隐藏文件夹，用于存储Git仓库的相关信息。\n可在当前目录下创建一个.gitignore文件，用于指定 Git 应该忽略的文件和文件模式。这个文件非常有用，因为它可以帮助你隐藏不想提交到仓库的文件，比如编译生成的文件、日志文件、本地设置文件等。 克隆远程仓库： 1git clone [远程仓库地址] [本地目录名] //若不指明本地目录名则是在当前目录下 可选参数：\n-b [分支名]：克隆特定分支。 二、仓库管理 在 Git 中，如果你想添加或者更改远程仓库的 URL，你可以使用 git remote 命令来添加一个新的远程仓库或修改现有的远程仓库。以下是一些相关的命令和步骤：\n1.添加远程仓库 在本地仓库中，可以通过以下命令添加远程仓库：\n1git remote add [远程仓库名] [远程仓库地址] 例如，将名为origin的远程仓库设置为https://github.com/username/my_project.git：\n1git remote add origin https://github.com/username/my_project.git 2.更改现有远程仓库的： 如果你想要更改一个现有远程仓库的 URL，你可以先删除原来的远程仓库，然后添加一个新的远程仓库。 删除远程仓库：\n1git remote rm [远程仓库名] 然后，添加新的远程仓库：\n1git remote add [远程仓库名] [新的远程仓库地址] 3.查看远程仓库列表： 要查看所有已添加的远程仓库，可以使用以下命令：\n1git remote -v 这个命令会列出所有远程仓库的名称和 URL。 在进行远程仓库 URL 的更改时，请确保你的本地仓库中的所有更改都已经提交，并且与远程仓库同步。这样可以避免在更改 URL 过程中出现版本冲突或数据丢失的问题。如果你已经将更改推送到远程仓库，那么其他协作者可能无法通过旧的 URL 获取你的更改，因此你可能需要通知他们更新远程仓库的 URL。\n三、暂存并提交更改 1.暂存更改 git add 是 Git 版本控制系统中一个非常重要的命令，它的作用是将工作目录中的文件更改添加到暂存区（Staging Area），为下一次的提交做准备。\n1git add [file_path] //暂存特定文件或文件夹 2git add . //暂存所有更改 暂存更改是一个关键步骤，因为它决定了下一次 git commit 将会包含哪些更改。 2.查看暂存更改 查看暂存状态，这会告诉你哪些文件被暂存了，哪些文件还没有被暂存。\n1git status 3.提交更改 将更改提交到本地仓库，可以使用以下命令： 1git commit -m \u0026#34;[提交消息]\u0026#34; 可选参数：\n-a：提交所有已跟踪的文件。 --amend：修改最后一次提交。 --amend作用是对上一次的提交进行修改。这个命令会将暂存区中的更改添加到上一次提交中，而不是创建一个新的提交。 四、推送更改 要向远程仓库推送更改，你需要使用 git push 命令。以下是一些常用的 git push 命令和可选参数：\n基本推送：将本地分支的更改推送到远程仓库的对应分支。 1git push origin \u0026lt;分支名\u0026gt; 其中 \u0026lt;分支名\u0026gt; 是你想要推送的本地分支名，默认情况下，Git会将当前分支的更改推送到远程仓库中与之对应的同名分支。origin 是远程仓库的默认名称，但你可以根据需要更改它。\n如果你想要推送到远程仓库的其他分支，你需要指定远程分支的名称。例如，如果你想要将本地的 feature-branch 分支推送到远程仓库的 remote-feature-branch 分支，你可以这样做：\n1git push origin feature-branch:remote-feature-branch 在这个例子中，冒号前面的 feature-branch 是本地分支的名称，冒号后面的 remote-feature-branch 是远程分支的名称。\n如果你想要推送当前分支到远程仓库的一个不同名称的分支，你可以省略本地分支名称，只指定远程分支名称：\n1git push origin :remote-feature-branch 强制推送：使用 -f 或 --force 参数，可以强制推送，这会覆盖远程仓库中的历史记录。注意：这可能会丢失其他人的工作，因此请谨慎使用。 1git push -f origin \u0026lt;分支名\u0026gt; 删除远程分支：使用 --delete 参数，可以删除远程仓库中的分支。 1git push origin --delete \u0026lt;分支名\u0026gt; 跟踪分支：如果你刚刚克隆了一个仓库，并且想要推送一个新的分支到远程仓库，你可以使用 -u 或 --set-upstream 参数来设置跟踪分支。 1git push -u origin \u0026lt;分支名\u0026gt; 这样，以后你可以直接使用 git push 而不需要指定远程仓库和分支名。\n推送所有标签：如果你想推送所有本地标签到远程仓库，可以使用 --tags 参数。 1git push --tags dry run：使用 --dry-run 参数，可以模拟推送过程，但不会实际修改远程仓库。 1git push --dry-run origin \u0026lt;分支名\u0026gt; 安静模式：使用 -q 或 --quiet 参数，可以减少命令的输出。 1git push -q origin \u0026lt;分支名\u0026gt; 显示进度：使用 --progress 参数，可以显示推送的进度。 1git push --progress origin \u0026lt;分支名\u0026gt; 请记住，推送更改之前，通常需要先拉取远程仓库的最新更改，以避免冲突。你可以使用 git pull 命令来拉取远程分支的更新。\n1git pull origin \u0026lt;分支名\u0026gt; 在实际操作中，建议遵循团队的Git工作流程，并确保你的更改不会破坏其他人的工作。\n五、分支管理 1.创建新分支： 1git branch [分支名] 可选参数：\n-b：创建并切换到新分支。 2.切换分支： 1git branch //查看分支信息 2git branch -a //显示所有分支，包括远程分支 3git checkout [分支名] //切换分支 4git checkout -b [分支名] //创建并切换到新分支 3.合并分支： 1git merge [分支名] 可选参数：\n--no-ff：禁用快速前进合并。 六、撤销更改 1.撤销工作区更改： 1git checkout -- [文件名] 2.撤销提交： 1git reset --hard [提交哈希] 可选参数：\n--soft：保留工作区和暂存区的更改。 --mixed：保留工作区的更改（默认）。 --hard：不保留工作区和暂存区的更改。 七、版本回退 切换到历史版本： 1git checkout [提交哈希] 回退到历史版本 1git reset --hard [提交哈希] 可选参数：\n--soft：保留工作区和暂存区的更改。 --mixed：保留工作区的更改（默认）。 --hard：不保留工作区和暂存区的更改。 git checkout 命令用于切换分支或切换到特定的提交。git reset命令通常用于撤销提交，回到特定的旧版本，并且丢弃所有在指定提交之后所做的更改。 git checkout git reset 工作目录和暂存区 会保留工作目录和暂存区的更改 默认不保留暂存区的更改，保留工作区的更改，有\u0026ndash;soft,\u0026ndash;mixed,\u0026ndash;hard三种参数可选 用途 通常用于开发过程中的分支切换或历史版本切换 通常用于撤销提交或重置到特定的旧版本 强制推送更改： 1git push [远程仓库名] --force 2git push [远程仓库名] -f 可选参数：\n--set-upstream：将本地分支与远程分支关联。 八、查看和比较更改 1. 查看提交历史： 1git log 可选参数：\n--oneline：简化输出。 --graph：显示分支和合并的历史。 2. 查看文件更改： 1git diff [文件名] 九、保存当前的工作进度 git stash 命令用于暂时存储你的工作进度。当你需要暂时中断当前的工作，比如切换到另一个分支处理紧急问题，或者拉取远程仓库的最新代码，但又不想丢失当前的工作进度时，git stash 非常有用。 ①暂存当前工作进度：\n1git stash ②查看暂存列表：\n1git stash list ③应用暂存：\n1git stash apply ④删除暂存：\n1git stash drop ⑤清空暂存：\n1git stash clear 通过将这些命令按照类别进行整理，您可以更容易地找到并理解与您当前任务相关的Git命令。在使用Git时，建议从简单的命令开始，逐步学习并尝试更复杂的操作，以便更好地掌握Git的使用。\n","date":1708422142,"headings":[{"anchor":"1-查看提交历史","title":"1. 查看提交历史："},{"anchor":"1创建新分支","title":"1.创建新分支："},{"anchor":"1撤销工作区更改","title":"1.撤销工作区更改："},{"anchor":"1暂存更改","title":"1.暂存更改"},{"anchor":"1添加远程仓库","title":"1.添加远程仓库"},{"anchor":"2-查看文件更改","title":"2. 查看文件更改："},{"anchor":"2切换分支","title":"2.切换分支："},{"anchor":"2撤销提交","title":"2.撤销提交："},{"anchor":"2更改现有远程仓库的","title":"2.更改现有远程仓库的："},{"anchor":"2查看暂存更改","title":"2.查看暂存更改"},{"anchor":"3合并分支","title":"3.合并分支："},{"anchor":"3提交更改","title":"3.提交更改"},{"anchor":"3查看远程仓库列表","title":"3.查看远程仓库列表："},{"anchor":"一仓库初始化和克隆","title":"一、仓库初始化和克隆"},{"anchor":"七版本回退","title":"七、版本回退"},{"anchor":"三暂存并提交更改","title":"三、暂存并提交更改"},{"anchor":"九保存当前的工作进度","title":"九、保存当前的工作进度"},{"anchor":"二仓库管理","title":"二、仓库管理"},{"anchor":"五分支管理","title":"五、分支管理"},{"anchor":"八查看和比较更改","title":"八、查看和比较更改"},{"anchor":"六撤销更改","title":"六、撤销更改"},{"anchor":"四推送更改","title":"四、推送更改"}],"kind":"page","lang":"zh-hans","series":["环境配置"],"summary":"","title":"Git常用命令","url":"/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","year":"2024"},{"content":"在软件开发的世界中，版本控制是一个至关重要的工具。它允许开发者保存、追踪和恢复代码的各个版本。Git由 Linus Torvalds 创建，是目前最受欢迎的版本控制系统之一。在这篇博客中，我们将探讨 Git 是什么，为什么它是分布式的，以及如何使用它进行开发者之间的协作。\n一、什么是 Git？ Git 是一个开源的分布式版本控制系统，用于追踪文件更改和帮助多人协作开发。它被设计成能够快速、高效地处理从很小到非常大的项目。 Git 的核心概念包括：\n仓库（Repository）： 仓库是 Git 中存储所有项目文件和相关元数据的地方。这些文件被称为“仓库”是因为它们存储了项目的完整历史和状态。仓库通常是一个目录，其中包含多个文件和子目录，以及指向这些文件的指针。仓库还包含一个名为.git的子目录，该子目录存储了所有的元数据和版本历史记录。 提交（Commit）： 提交是 Git 中保存项目状态的一种方式，它代表项目在特定时间点的快照。每次提交都会保存一组父提交（即之前的提交），以及指向这些父提交的指针。提交还包含一个提交者信息，如提交者的用户名和电子邮件地址，以及一个提交消息，描述了本次提交的内容。 注意仓库、提交、工作区、暂存区之间的区别，仓库、工作区、暂存区均为存储目录/存储空间，而提交为动作。工作区、暂存区之间的区别见下文标题四。 分支（Branch）： 分支是 Git 中并行开发的关键特性。一个分支代表了一个独立的代码路径，允许开发者在不同的代码路径上工作，而不会相互干扰。创建分支时，Git 会复制当前分支的提交历史，并创建一个新的分支指向最后一个提交的副本。之后，开发者可以在新的分支上进行更改，并提交新的提交。 合并（Merge）： 合并是将两个或多个分支的更改整合到一起的过程。当两个或多个开发者在同一时间段内对同一部分代码进行了更改，并且这些更改需要合并在一起时，就需要进行合并。Git 提供了一种自动合并更改的方法，它会尝试找出两个分支的共同祖先，并合并更改。 远程仓库（Remote）： 远程仓库是存储在网络上的 Git 仓库，允许团队成员协作。远程仓库通常托管在代码托管平台（如 GitHub、GitLab 或 Bitbucket）上。通过将本地仓库与远程仓库关联，开发者可以推送更改到远程仓库，并与他人共享。其他开发者可以从远程仓库克隆或拉取更改，以便协作和同步。 二、Git 是分布式的，这意味着什么？ 1.集中式版本控制系统 想象一个实体文件柜，里面有一个文件夹，包含所有项目文件。每当有人需要操作一个文件时，他们必须拿起它，从文件夹中取出，然后在完成工作后放回文件夹。因此为了避免任何可能的冲突，不可能让两个人同时工作在同一个文件上。\n这是集中式版本控制系统的工作方式，用户需要“检出”和“检入”文件，即当有人需要编辑特定文件时，他们需要检出该文件，从仓库中移除，然后在完成工作后检入文件，将其返回仓库。\n2.分布式版本控制系统 在像Git这样的分布式系统中，多个用户可以同时访问同一远程仓库的文件。每当有人需要编辑文件时，他们可以简单地将文件（或整个仓库）克隆到本地机器上，然后将修改后的文件推送到远程仓库。这样，多人可以同时工作在同一个项目上，甚至可以编辑同一个文件。\n这就是大型开源项目能够分布式的原因，来自世界各地的人们可以共同工作在同一个项目上，管理修改和可能的冲突（在这里也会发生合并冲突）。\n3.分布式的优势 Git 的分布式特性是其最强大的特点之一。在分布式系统中，每个开发者的工作站上都有一个完整的代码库副本，包括所有历史提交记录和版本信息。这意味着开发者可以在本地进行大多数操作，如提交、创建分支、合并等，而不需要连接到网络或中央服务器。\n去中心化： 在 Git 中，没有中央服务器或单一的权威源。每个开发者的工作站上都有一个完整的代码库，这意味着他们可以在没有网络连接的情况下继续工作。 这种去中心化的结构提高了系统的可靠性，因为没有任何单一的故障点。即使某个中央服务器出现问题，开发工作仍然可以继续。 性能优化： 大多数 Git 操作，如提交、创建分支和合并，都可以在本地执行。这大大提高了操作的速度和效率，特别是在处理大型项目时。 本地操作减少了网络延迟和中央服务器的负载，使得团队可以更快地迭代和协作。 安全性： Git 使用加密哈希来确保数据的完整性和一致性。每次提交都会生成一个唯一的哈希值，用于标识该提交。这使得检测数据是否被篡改变得非常容易。 分布式结构意味着每个开发者都有责任确保他们的工作站上的代码库是完整和可信的。 灵活性： 开发者可以在本地创建分支、提交更改，并在准备好后推送这些更改到远程仓库。这使得并行开发变得简单，因为多个开发者可以在同一时间处理不同的任务。 即使在网络不可用的情况下，开发者也可以继续工作，这确保了开发的连续性。 协作简单： 开发者可以通过简单的命令，如 git pull 和 git push，从远程仓库拉取和推送更改。这使得团队成员之间的协作和同步变得非常直接和高效。 通过特性分支和合并请求（pull requests），团队成员可以在本地工作，并在合并到主分支之前与他人共享和讨论更改。 数据完整性： Git 中的数据完整性是通过一系列的加密哈希来保证的。每次提交都会生成一个唯一的哈希值，用于标识该提交。这使得检测数据是否被篡改变得非常容易。 三、安装和配置git 安装和设置 Git 是一个简单的过程，可以通过以下步骤来完成。以下指南适用于 Windows、macOS 和 Linux 系统。\n1.在 Windows 上安装 Git 下载 Git： 访问 Git 官网 并下载适用于 Windows 的安装程序。\n安装 Git： 运行下载的安装程序，并按照安装向导的指示进行安装。\n配置： 安装完成后，你可以选择配置 Git。打开命令提示符或 PowerShell，运行以下命令来设置你的 Git 用户名和电子邮件地址：\n1git config --global user.name \u0026#34;Your Name\u0026#34; 2git config --global user.email \u0026#34;your_email@example.com\u0026#34; 这些设置将用于所有你通过 Git 进行的提交。\n2.在 macOS 上安装 Git 使用 Homebrew 安装 Git： macOS 用户可以使用 Homebrew 包管理器来安装 Git。首先，打开终端并运行以下命令来安装 Homebrew（如果尚未安装）：\n1/bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 然后，使用 Homebrew 安装 Git：\n1brew install git 配置： 安装完成后，你可以配置 Git。在终端中运行以下命令来设置你的 Git 用户名和电子邮件地址：\n1git config --global user.name \u0026#34;Your Name\u0026#34; 2git config --global user.email \u0026#34;your_email@example.com\u0026#34; 3.在 Linux 上安装 Git 使用包管理器安装 Git： Linux 发行版的包管理器中通常都包含 Git。以下是使用一些常见发行版包管理器的示例： Ubuntu/Debian: 1sudo apt-get update 2sudo apt-get install git Fedora: 1sudo dnf install git Arch Linux: 1sudo pacman -S git 配置： 安装完成后，你可以配置 Git。在终端中运行以下命令来设置你的 Git 用户名和电子邮件地址： 1git config --global user.name \u0026#34;Your Name\u0026#34; 2git config --global user.email \u0026#34;your_email@example.com\u0026#34; 4.验证 Git 安装 安装 Git 后，打开命令提示符、PowerShell、终端（macOS/Linux）并运行以下命令来验证 Git 是否正确安装：\n1git --version 如果 Git 已正确安装，这将显示安装的 Git 版本号。 现在你已经安装了 Git，你可以开始使用它来管理你的代码仓库了。记得，Git 是一个分布式版本控制系统，这意味着你可以在本地执行大多数操作，然后将更改推送到远程仓库与他人共享。\n四、git的工作区和暂存区 工作区（Working Directory） 工作区是你电脑上的一个目录，它包含了你正在工作的文件。你可以在这个目录中编辑文件、创建新文件或删除文件。工作区是Git中文件更改的起始点。当你第一次克隆一个仓库时，工作区会包含所有文件的最新版本。 暂存区/索引区（Staging Area） 暂存区是一个介于工作区和仓库之间的小型区域，它用于暂存即将进行的提交。当你使用 git add命令时，文件的更改会被添加到暂存区。暂存区允许你选择性地将更改组织成更小、更有意义的提交。你可以添加一部分文件的更改到暂存区，然后提交它们，而不必将所有更改都包含在一个提交中。 简而言之，工作区是你实际编辑文件的地方，而暂存区是你准备下一次提交的地方。当你准备好提交更改时，你会将工作区中已完成的更改添加到暂存区，然后一次性提交暂存区中的所有更改。 下面是一个简单的例子，展示了工作区和暂存区的使用过程： 1# 编辑工作区中的文件 2edit file1.txt 3# 将更改添加到暂存区 4git add file1.txt 5# 编辑另一个文件 6edit file2.txt 7# 只暂存file1.txt的更改，file2.txt的更改不包含在这次提交中 8git commit -m \u0026#34;Update file1.txt\u0026#34; 9# 现在将file2.txt的更改添加到暂存区 10git add file2.txt 11# 提交file2.txt的更改 12git commit -m \u0026#34;Update file2.txt\u0026#34; 在这个例子中，我们首先在工作区中编辑了 file1.txt，然后将其更改添加到暂存区，并提交了一个包含这些更改的 commit。接着，我们编辑了 file2.txt，但没有立即提交它。最后，我们将 file2.txt的更改添加到暂存区，并提交了一个新的 commit。这样，我们就有了两个独立的提交，每个提交都包含了不同的文件更改。\n","date":1708417795,"headings":[{"anchor":"1在-windows-上安装-git","title":"1.在 Windows 上安装 Git"},{"anchor":"1集中式版本控制系统","title":"1.集中式版本控制系统"},{"anchor":"2分布式版本控制系统","title":"2.分布式版本控制系统"},{"anchor":"2在-macos-上安装-git","title":"2.在 macOS 上安装 Git"},{"anchor":"3分布式的优势","title":"3.分布式的优势"},{"anchor":"3在-linux-上安装-git","title":"3.在 Linux 上安装 Git"},{"anchor":"4验证-git-安装","title":"4.验证 Git 安装"},{"anchor":"一什么是-git","title":"一、什么是 Git？"},{"anchor":"三安装和配置git","title":"三、安装和配置git"},{"anchor":"二git-是分布式的这意味着什么","title":"二、Git 是分布式的，这意味着什么？"},{"anchor":"四git的工作区和暂存区","title":"四、git的工作区和暂存区"}],"kind":"page","lang":"zh-hans","series":["环境配置"],"summary":"","tags":["git"],"title":"Git指南：版本控制的力量","url":"/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git-%E6%8C%87%E5%8D%97%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E7%9A%84%E5%8A%9B%E9%87%8F/","year":"2024"},{"content":"Hugo 不仅支持常见的命令来创建和预览网站，还提供了一些高级命令和选项\n一、引言 Hugo 是一个广受欢迎的静态网站生成器，它使用 Go 语言编写，以其快速生成站点和灵活的模板系统而闻名。Hugo 不仅支持常见的命令来创建和预览网站，还提供了一些高级命令和选项，这些高级功能可以帮助你更好地控制网站生成和预览过程。本文将详细介绍 Hugo 的基础命令以及一些少用的命令和选项，帮助你更高效地进行网站开发。\n二、Hugo 基础命令 1.新建站点 1hugo new site [sitename] 这个命令用于创建一个新的 Hugo 站点。它会生成一个包含基本结构的目录，其中包含配置文件、内容、布局等。\n2.新建内容 1hugo new [content]/[filename].md 用于在指定的内容目录下创建一个新的 Markdown 文件。Hugo 会自动添加一些前置matter（Front Matter）字段，如标题、日期等。\n3.构建站点 1hugo 这个命令会构建你的站点，将 Markdown 文件和其他资源转换为静态 HTML 文件。默认情况下，生成的文件会存放在 public 目录中。\n4.本地服务器 1hugo server 启动一个本地服务器，让你可以在浏览器中预览站点。这个命令还支持实时刷新功能，当你修改内容时，站点会自动重新构建和刷新。\n三、Hugo 服务器高级参数 Hugo 服务器命令是进行网站开发和预览的常用方式。以下是一些高级参数，它们可以帮助你更好地控制服务器行为：\n1.指定端口 1hugo server -p 7070 指定 Hugo 服务器监听的端口。例如，-p 7070 表示服务器将在本地主机的 7070 端口上运行。\n2.垃圾回收 1hugo server --gc 在 Hugo 服务器每次启动时，清理掉旧的模块缓存，确保使用的是最新的依赖版本。\n3.构建草稿 1hugo server --buildDrafts 构建并显示所有草稿内容。草稿是标记为未完成或不想立即发布的页面。使用这个参数，可以预览这些内容而不必公开发布。\n4.启用 Git 信息 1hugo server --enableGitInfo 在生成的 HTML 文件中包含 Git 信息，如提交哈希、作者、日期等。这要求你的 Hugo 网站是放在 Git 仓库中的。\n四、高级选项 Hugo 还提供了一些其他的高级选项，这些选项可能不经常使用，但在某些情况下它们会非常有用：\n1.渲染到磁盘 1hugo --renderToDisk 将Markdown文件渲染为HTML文件到磁盘上，而不是只保存在内存中。这对于大型站点或者需要将渲染后的文件与其他工具一起使用的场景很有帮助。\n2.国际化警告 1hugo --i18n-warnings 输出国际化（i18n）相关的警告。如果你的网站支持多语言，这个参数可以帮助你确保所有翻译都是完整的。\n3.模板指标 1hugo --templateMetrics 输出有关模板执行的指标，包括每个模板的渲染时间和调用次数。这对于优化站点性能非常有用。\n4.路径警告 1hugo --path-warnings 在生成站点时警告关于无效的链接和路径问题。这有助于确保你的站点没有死链或错误的URL。\n五、其他少用命令 除了上述的高级命令和选项外，Hugo 还有一些其他少用的命令，这些命令在某些特定场景下可能会非常有用：\n1.模块管理 1hugo mod [subcommand] 管理 Hugo 模块。模块是 Hugo 用来管理依赖项的一种方式，这个命令可以帮助你添加、更新或删除模块。\n2.文件生成 1hugo gen [subcommand] 生成不同类型的文件，如 XML、JSON 等。这个命令可以帮助你生成站点地图、RSS 订阅源等。\n六、 结论 通过探索 Hugo 的这些基础和高级命令，你可以更好地控制网站生成和预览过程，提高网站开发的效率和质量。无论你是 Hugo 新手还是经验丰富的开发者，了解这些命令和选项都可以为你的工作带来便利。希望本文能够帮助你更好地利用 Hugo 的强大功能，打造出色的静态网站。\n","date":1708410369,"headings":[{"anchor":"1指定端口","title":"1.指定端口"},{"anchor":"1新建站点","title":"1.新建站点"},{"anchor":"1模块管理","title":"1.模块管理"},{"anchor":"1渲染到磁盘","title":"1.渲染到磁盘"},{"anchor":"2国际化警告","title":"2.国际化警告"},{"anchor":"2垃圾回收","title":"2.垃圾回收"},{"anchor":"2文件生成","title":"2.文件生成"},{"anchor":"2新建内容","title":"2.新建内容"},{"anchor":"3构建站点","title":"3.构建站点"},{"anchor":"3构建草稿","title":"3.构建草稿"},{"anchor":"3模板指标","title":"3.模板指标"},{"anchor":"4启用-git-信息","title":"4.启用 Git 信息"},{"anchor":"4本地服务器","title":"4.本地服务器"},{"anchor":"4路径警告","title":"4.路径警告"},{"anchor":"一引言","title":"一、引言"},{"anchor":"三hugo-服务器高级参数","title":"三、Hugo 服务器高级参数"},{"anchor":"二hugo-基础命令","title":"二、Hugo 基础命令"},{"anchor":"五其他少用命令","title":"五、其他少用命令"},{"anchor":"六-结论","title":"六、 结论"},{"anchor":"四高级选项","title":"四、高级选项"}],"kind":"page","lang":"zh-hans","series":["hugo博客"],"summary":"Hugo 不仅支持常见的命令来创建和预览网站，还提供了一些高级命令和选项\n","tags":["hugo"],"title":"探索 Hugo 静态网站生成器的高级命令和选项","url":"/hugo%E5%8D%9A%E5%AE%A2/%E5%B8%B8%E7%94%A8%E7%9A%84hugo%E5%91%BD%E4%BB%A4/","year":"2024"},{"content":"短代码是Hugo中的一种自定义标记语法，它允许你在Markdown文件中插入预定义的HTML代码片段。\n什么是短代码 Hugo 中的短代码（Shortcodes）是一个强大的功能，它允许你在Markdown文件中插入自定义的HTML代码，而不必编写HTML标签。Hugo会在生成静态网站时将短代码替换为相应的HTML代码，这使得Markdown文件的编写更加简洁和直观，同时保持了内容的纯文本格式。\n在Hugo主题的模板文件中，短代码会被定义为一个函数，它接受参数并返回HTML代码。例如，一个简单的短代码函数可能如下所示：\n1\u0026lt;!-- shortcode-name.html --\u0026gt; 2\u0026lt;div\u0026gt; 3 \u0026lt;!-- 短代码的实现 --\u0026gt; 4\u0026lt;/div\u0026gt; 在Markdown文件中使用短代码时，Hugo会在生成静态网站时将短代码替换为相应的HTML代码。\nHugo内置短代码 Figure： 是 Markdown 中图像语法的延伸。 Gist：显示 GitHub gist 代码。 Highlight：显示高亮代码。 Param：获取当前页面的参数，如无则回退到网站参数。 ref and relref：返回指定页面的固定链接（ref）或相对固定链接（relref）。 Bootstrap 短代码 此为HB主题中内置的短代码\nBootstrap 短代码列表。\nAlert：显示警告信息，支持多种样式、图标和标题。 Clearfix：清除浮动的内容，如浮动图片。 Collapse：隐藏和显示内容。 Config Toggle：从一个代码库中生成一个配置切换，支持 YAML、TOML 和 JSON。 Icon Grid：显示带有图标、标题和描述的 icon grid。 Lead：使一个段落脱颖而出。 Ratio：完美的响应式处理视频或幻灯片的嵌入，基于父体的宽度。 Toggle：比 config toggle 更加通用，设计用于任何内容，如 SDK 代码。 详情请参考文章：短代码 - 内容 - 用户手册 - HB 框架 (hbstack.dev)\n","date":1708363960,"headings":[{"anchor":"bootstrap-短代码","title":"Bootstrap 短代码"},{"anchor":"hugo内置短代码","title":"Hugo内置短代码"},{"anchor":"什么是短代码","title":"什么是短代码"}],"kind":"page","lang":"zh-hans","series":["hugo博客"],"summary":"短代码是Hugo中的一种自定义标记语法，它允许你在Markdown文件中插入预定义的HTML代码片段。\n","title":"短代码","url":"/hugo%E5%8D%9A%E5%AE%A2/%E7%9F%AD%E4%BB%A3%E7%A0%81/","year":"2024"},{"content":"文档属性的内容及含意介绍\n一、内容原型 在 Hugo 中，archetypes 文件夹用于存储内容原型。内容原型是一些模板文件，当使用 hugo new 命令创建新内容时，它们会用作默认的前置元数据文件。这些原型文件通常包含了一些基础的前置元数据(文档属性)，如标题、日期和布局设置。\n在 Hugo 中，当你使用 hugo new 命令创建一个新的内容文件时，Hugo 会按照以下顺序来检索内容原型（archetypes）：\n检查内容类型：Hugo 会首先确定你要创建的内容的类型。这通常是通过你提供的命令参数来确定的，例如 hugo new post/my-new-post.md 会创建一个类型为 \u0026ldquo;post\u0026rdquo; 的新内容文件。 查找内容原型：一旦内容类型被确定，Hugo 会尝试在 archetypes 目录中查找与内容类型相匹配的原型文件。原型文件的命名通常是基于内容类型的，例如 archetypes/post.md。 应用默认原型：如果你没有为特定内容类型提供原型文件，Hugo 会退而求其次，查找一个名为 default.md 的默认原型文件。 使用原型创建内容：找到合适的原型文件后，Hugo 会使用它来创建新的内容文件。原型文件中的前置元数据会被插入到新内容文件的前置元数据部分。 提示用户输入：在某些情况下，Hugo 可能会提示用户输入缺失的前置元数据值，尤其是如果原型文件中包含了占位符。 生成新内容文件：最后，Hugo 会生成新的内容文件，并将其保存在指定的目录中。 例如，如果你运行命令 hugo new post/my-first-post.md，Hugo 会：\n确定内容类型为 \u0026ldquo;post\u0026rdquo;。 查找 archetypes/post.md 文件。 如果找到，使用 archetypes/post.md 中的前置元数据来创建 content/post/my-first-post.md 文件。 如果没有找到特定于 \u0026ldquo;post\u0026rdquo; 的原型文件，Hugo 会尝试使用 archetypes/default.md。 如果连默认原型文件都没有，Hugo 会创建一个没有前置元数据的新内容文件。 内容原型是一个非常有用的功能，因为它可以帮助你确保所有新创建的内容都包含必要的前置元数据，从而保持网站的一致性和组织性。 二、文档属性 1.文章属性 在HB主题中，包含以下文档属性（元数据）：\n属性 说明 title 文档的标题。 date 文档的创建或最后修改日期。 draft 一个布尔值，表示文档是否为草稿。如果设置为 true，则不会在生成网站时显示。 layout 定义了页面的布局。在 Hugo 中，这通常是一个文件夹或模板的名称。HB主题里可选landing落地窗布局，文章首页展示大图。 type 文档的类型或部分。在 Hugo 中，这通常用于组织内容。HB主题里可选docs和blog linkTitle 如果文档是一个系列的一部分，linkTitle 用于定义在导航中的显示名称。 nav_weight 定义了文档在导航菜单中的权重或排序。越小越靠前。 authors 文档的作者列表。 series 文档所属的专栏。 tag 文档的标签列表。 nav_icon 定义了文档在导航菜单中的图标。这通常是一个字体图标或图像。 vendor 图标的来源库或框架名称。例如，bs 可能指的是 Bootstrap。nav_icon的子属性。 name 图标的名称。nav_icon的子属性。 menu （可选）在导航栏菜单栏名称，图标的设置 这些属性在 Hugo 博客中用于定义和自定义文档的各个方面，包括其结构、外观和导航菜单中的显示方式。\n2.导航栏属性 特别的关于menu属性：\n在 Hugo 主题中，menu 是一个用于定义导航菜单的结构，它允许您自定义菜单的布局、内容和外观。以下是 menu 属性及其含义的表格：\n属性 说明 main 定义主菜单的配置。 parent 定义菜单项的父容器。在 Hugo 中，这通常是一个布局文件或模板。 weight 定义菜单项的权重或排序。数值越小，菜单项在列表中的位置越靠前。 params 一个对象，用于定义菜单项的额外参数。这些参数可以用于自定义菜单项的显示和行为。 description 菜单项的描述文本，通常用于工具提示或菜单项的附加信息。 icon 定义菜单项的图标。这通常是一个字体图标或图像。 vendor 图标的来源库或框架名称。例如，bs 可能指的是 Bootstrap。 name 图标的名称。 className 添加到图标元素的类名，可以用于进一步自定义图标的外观。 color 图标的颜色 例如，以下是一个 Hugo 主题中 menu 部分的示例配置：\n1menu: 2 main: 3 parent: column 4 weight: 2 5 params: 6 description: 环境配置 7 icon: 8 vendor: bs 9 name: toggles 10 className: text-primary 11 # color: blue 在这个例子中，main 菜单项被定义为 column 布局的子元素，具有 2 的权重。params 对象包含了菜单项的描述和图标配置，其中图标来自 Bootstrap 框架，名称为 toggles，并且添加了一个名为 text-primary 的类名。 这些属性在 Hugo 主题的配置文件中用于定义和自定义菜单的各个方面，包括其结构、外观和导航菜单中的显示方式。\n三、图标 尽管图标的根参数不同，如 icon 或 nav_icon，但成员参数是相同的。\n1.成员参数 vendor\n图标供应商名称，默认支持 bootstrap（bs），要使用其他供应商，需要导入相应的模块，以 Font Awesome 图标为例。\nhugo.yaml\n1module: 2 imports: 3 - path: github.com/hugomods/icons/vendors/font-awesome 现在你可以使用 Font Awesome 实体（fas）、常规（far）和品牌（fab）图标了。\nname\n图标的名称，如 book、house。\ncolor\n图标的十六进制颜色，如 green, #7952B3。\nclassName\n图标样式的附加类名，如 text-success、text-primary。\n1\u0026lt;p class=\u0026#34;text-primary\u0026#34;\u0026gt;.text-primary\u0026lt;/p\u0026gt; 2\u0026lt;p class=\u0026#34;text-secondary\u0026#34;\u0026gt;.text-secondary\u0026lt;/p\u0026gt; 3\u0026lt;p class=\u0026#34;text-success\u0026#34;\u0026gt;.text-success\u0026lt;/p\u0026gt; 4\u0026lt;p class=\u0026#34;text-danger\u0026#34;\u0026gt;.text-danger\u0026lt;/p\u0026gt; 5\u0026lt;p class=\u0026#34;text-warning\u0026#34;\u0026gt;.text-warning\u0026lt;/p\u0026gt; 6\u0026lt;p class=\u0026#34;text-info\u0026#34;\u0026gt;.text-info\u0026lt;/p\u0026gt; 7\u0026lt;p class=\u0026#34;text-light bg-dark\u0026#34;\u0026gt;.text-light\u0026lt;/p\u0026gt; 8\u0026lt;p class=\u0026#34;text-dark\u0026#34;\u0026gt;.text-dark\u0026lt;/p\u0026gt; 9\u0026lt;p class=\u0026#34;text-muted\u0026#34;\u0026gt;.text-muted\u0026lt;/p\u0026gt; 10\u0026lt;p class=\u0026#34;text-white bg-dark\u0026#34;\u0026gt;.text-white\u0026lt;/p\u0026gt; 2.供应商Vendor Vendor Vendor Name Shorthand Module Path Bootstrap Icons bootstrap bs github.com/hugomods/icons/vendors/bootstrap Feather Icons feather - github.com/hugomods/icons/vendors/feather Font Awesome Brands Icons font-awesome-brands fab github.com/hugomods/icons/vendors/font-awesome Font Awesome Regular Icons font-awesome-regular far github.com/hugomods/icons/vendors/font-awesome Font Awesome Solid Icons font-awesome-solid fas github.com/hugomods/icons/vendors/font-awesome Lucide Icons lucide - github.com/hugomods/icons/vendors/lucide Material Design Icons mdi - github.com/hugomods/icons/vendors/mdi Simple Icons simple-icons simple github.com/hugomods/icons/vendors/simple-icons Tabler Icons tabler - github.com/hugomods/icons/vendors/tabler 3.图标搜索 所有可用的图标都可以在 Hugo Icons Module 上找到\n也可在官网查询\nBootstrap Icons :Bootstrap 图标库 · Bootstrap 官方开源图标（icon）库 (bootcss.com) Simple Icons:Simple Icons ","date":1708359820,"headings":[{"anchor":"1成员参数","title":"1.成员参数"},{"anchor":"1文章属性","title":"1.文章属性"},{"anchor":"2供应商vendor","title":"2.供应商Vendor"},{"anchor":"2导航栏属性","title":"2.导航栏属性"},{"anchor":"3图标搜索","title":"3.图标搜索"},{"anchor":"一内容原型","title":"一、内容原型"},{"anchor":"三图标","title":"三、图标"},{"anchor":"二文档属性","title":"二、文档属性"}],"kind":"page","lang":"zh-hans","series":["hugo博客"],"summary":"文档属性的内容及含意介绍\n","title":"文档属性","url":"/hugo%E5%8D%9A%E5%AE%A2/%E6%96%87%E6%A1%A3%E5%B1%9E%E6%80%A7/","year":"2024"},{"content":"关于markdown语法的速查\nMarkdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成结构化的 HTML 文档。Markdown 语法简洁明了，易于学习，因此在程序员和写作者中广受欢迎。下面将详细介绍 Markdown 的基本语法。\n标题 Markdown 支持六级标题，分别使用 # 符号表示。# 的数量代表标题的级别。\n1# 一级标题 2## 二级标题 3### 三级标题 4#### 四级标题 5##### 五级标题 6###### 六级标题 段落与换行 段落之间使用一个或多个空行分隔。如果需要在段落内强制换行，可以在行尾添加两个或更多的空格然后回车。\n1这是一个段落。 2这是另一个段落。 强调 斜体 ：将文字包围在 * 或 _ 符号之间。 粗体 ：将文字包围在 ** 或 __ 符号之间。 粗斜体 ：将文字包围在 *** 或 ___ 符号之间。 列表 无序列表使用 *、+ 或 - 作为列表标记。 有序列表使用数字后跟英文句点。 1- 无序列表项一 2- 无序列表项二 3- 无序列表项三 4 51. 有序列表项一 62. 有序列表项二 73. 有序列表项三 链接与图片 链接：使用 [文本](链接地址 \u0026quot;标题\u0026quot;) 的格式。 图片：使用 ![替代文本](图片地址 \u0026quot;标题\u0026quot;) 的格式。 1[这是一个链接](https://www.example.com \u0026#34;示例网站\u0026#34;) 2![这是一张图片](https://www.example.com/image.jpg \u0026#34;示例图片\u0026#34;) 引用 使用 \u0026gt; 符号表示引用，符号后需紧跟一个空格。\n1\u0026gt; 这是一个引用。 代码 行内代码：使用一对反引号 ` 包围代码。 代码块：使用三个反引号 ``` 包围代码，并可选指定语言。 1`这是行内代码` 2 3```python 4这是代码块 表格 使用 | 和 - 来创建表格。\n1| 标题1 | 标题2 | 标题3 | 2|-------|-------|-------| 3| 单元格1 | 单元格2 | 单元格3 | 4| 单元格4 | 单元格5 | 单元格6 | 标题1 标题2 标题3 单元格1 单元格2 单元格3 单元格4 单元格5 单元格6 分隔线 使用三个或更多的 *、- 或 _ 来创建分隔线。\n1--- HTML 元素 Markdown 支持直接插入 HTML 元素。\n1\u0026lt;p\u0026gt;这是一个 HTML 段落。\u0026lt;/p\u0026gt; 自动链接 使用 \u0026lt; 和 \u0026gt; 包围 URL 或邮箱地址，自动生成链接。\n1\u0026lt;https://www.example.com\u0026gt; 以上是 Markdown 的基本语法指南，掌握这些基本用法后，可以更高效地编写文档和博客。Markdown 的简洁性和易用性使其成为文本处理的理想选择。\n","date":1708358595,"headings":[{"anchor":"html-元素","title":"HTML 元素"},{"anchor":"代码","title":"代码"},{"anchor":"分隔线","title":"分隔线"},{"anchor":"列表","title":"列表"},{"anchor":"引用","title":"引用"},{"anchor":"强调","title":"强调"},{"anchor":"标题","title":"标题"},{"anchor":"段落与换行","title":"段落与换行"},{"anchor":"自动链接","title":"自动链接"},{"anchor":"表格","title":"表格"},{"anchor":"链接与图片","title":"链接与图片"}],"kind":"page","lang":"zh-hans","series":["hugo博客"],"summary":"关于markdown语法的速查\n","tags":["markdown"],"title":"Markdown语法","url":"/hugo%E5%8D%9A%E5%AE%A2/markdown%E8%AF%AD%E6%B3%95/","year":"2024"},{"content":"本博客平台使用到的技术，hugo和HB框架的安装使用\n一、简介 我在大四寒假期间搭建了这个博客平台，这个专栏记录了我搭建这个博客平台的过程，并且汇集了一些使用HB框架写文章时经常用到的函数或者说方法，方便查阅。\n这个网站是基于hugo框架搭建的静态博客 主题是HB Framework 网站托管在github page上 使用自定义域名yaoyifeng.top 使用腾讯云的cdn来加快国内的访问速度 二、环境安装 1.安装hugo Hugo 是一个广受欢迎的静态网站生成器，由 Go 语言编写。它能够将Markdown、HTML等格式的文件和模板转换为静态网页。Hugo 以其快速生成网站的能力而闻名，这使得它成为许多开发者和博客作者的首选工具。 安装 Hugo 的方法取决于操作系统。以下是几种常见操作系统的安装步骤：\nWindows\n访问 Hugo 的 GitHub 发布页面。 下载适合你系统的 .exe 文件（例如 hugo_extended_0.111.3_windows-amd64.zip）。 解压下载的文件，并将 hugo.exe 文件移动到一个在系统 PATH 环境变量中的目录下，这样你就可以在命令行中全局访问 Hugo 命令。 打开命令提示符或 PowerShell，输入 hugo version 来验证安装是否成功。 HB 使用 Hugo Pipes 来编译 SCSS，因此需要扩展版（extended）的 Hugo。 建议将hugo.exe添加到系统/用户环境变量中，否则只能在当前目录下访问hugo，给使用带来不便 macOS\n打开终端。 使用 Homebrew 安装 Hugo。如果尚未安装 Homebrew，请先安装它。安装 Homebrew 后，输入以下命令： 1brew install hugo 安装完成后，输入 hugo version 来验证安装是否成功。 Linux\n打开终端。 使用包管理器安装 Hugo。例如，在 Ubuntu 或 Debian 上，可以使用以下命令： 1sudo apt-get install hugo 安装完成后，输入 hugo version 来验证安装是否成功。 通过 Go 语言安装 如果已经安装了 Go 语言环境，也可以通过以下命令安装 Hugo：\n1go install github.com/gohugoio/hugo@latest 安装完成后，应该能够通过在命令行中输入 hugo 来访问 Hugo 命令。\n2.安装go 一般来说使用hugo时并不需要使用go，但我用的HB Framework主题是一个模块化的框架，需要使用go语言来下载和更新hugo模块，具体见HB - Hugo Bootstrap 框架 (hbstack.dev)\n要下载和安装 Go 语言（也称为 Golang），请遵循以下步骤。请注意，步骤可能会因您的操作系统而异。\nWindows\n访问 Go 官方下载页面。 根据系统是 32 位还是 64 位，下载相应的 .msi 安装包。 运行下载的 .msi 文件，并按照安装向导的指示完成安装。 安装过程中，确保将 Go 安装路径添加到系统环境变量的 PATH 中。 安装完成后，重启任何已打开的命令提示符或 PowerShell 窗口。 在命令行中输入 go version 来验证安装是否成功。 同安装hugo一样，安装go不会自动将安装路径添加到环境变量里，需要手动添加 macOS\n访问 Go 官方下载页面。 下载适用于 macOS 的 .pkg 安装包。 打开下载的 .pkg 文件，并按照安装向导的指示完成安装。 安装完成后，在终端中输入 go version 来验证安装是否成功。 Linux\n访问 Go 官方下载页面。 下载适用于 Linux 的 .tar.gz 压缩包。 打开终端，切换到您想要安装 Go 的目录（例如 cd /usr/local）。 使用 tar 命令解压下载的文件，例如： 1sudo tar -C /usr/local -xzf go$VERSION.$OS-$ARCH.tar.gz 将 $VERSION、$OS 和 $ARCH 替换为适当的值，例如 go1.18.3.linux-amd64.tar.gz。 将 Go 的 bin 目录添加到 PATH 环境变量中。可以通过修改 ~/.profile 或 ~/.bashrc 文件来实现这一点，例如： 1export PATH=$PATH:/usr/local/go/bin 在终端中输入 source ~/.profile 或 source ~/.bashrc 来更新当前会话的环境变量。 输入 go version 来验证安装是否成功。 3.安装git 关于git的介绍，安装使用方法详见环境配置专栏\n4.安装node.js 要求 Node.js 16 或后续版本。\nWindows\n访问 Node.js 官方网站 nodejs.org。 下载适合系统的安装包（建议选择 LTS 版本，因为它更稳定）。 运行下载的安装程序 .msi 文件。 按照安装向导的指示完成安装。默认情况下，安装程序会自动将 Node.js 添加到系统路径中。 安装完成后，打开命令提示符或 PowerShell。 输入 node -v 和 npm -v 来验证 Node.js 和 npm 是否正确安装。 node.js安装过程中会自动添加到系统环境变量中，无需手动添加 macOS\n访问 Node.js 官方网站 nodejs.org。 下载适合系统的安装包（建议选择 LTS 版本）。 打开下载的 .pkg 文件。 按照安装向导的指示完成安装。 安装完成后，打开终端。 输入 node -v 和 npm -v 来验证 Node.js 和 npm 是否正确安装。 Linux\n对于大多数 Linux 发行版，可以使用包管理器来安装 Node.js，以下是一些示例：\n使用 Ubuntu 或 Debian 的 apt-get：\n1curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - 2sudo apt-get install -y nodejs 使用 CentOS 或 Fedora 的 yum：\n1curl -sL https://rpm.nodesource.com/setup_14.x | sudo bash - 2sudo yum install -y nodejs 使用 Arch Linux 的 pacman：\n1sudo pacman -S nodejs npm 安装完成后，打开终端并输入 node -v 和 npm -v 来验证 Node.js 和 npm 是否正确安装。\n使用 nvm (Node Version Manager)\n如果需要管理多个 Node.js 版本，可以使用 nvm（Node Version Manager）\n安装 nvm：\n对于 macOS 和 Linux，可以使用以下命令：\n1curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash 2# 或 3wget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash 对于 Windows，可以使用 nvm-windows。\n使用 nvm 安装 Node.js：\n1nvm install node # 安装最新版本 2nvm install --lts # 安装 LTS 版本 3nvm use node # 使用已安装的最新版本 4nvm use --lts # 使用已安装的 LTS 版本 安装完成后，可以通过输入 node -v 和 npm -v 来验证 Node.js 和 npm 是否正确安装。\n安装node.js包 HB 依赖以下 Node.js 包。\n名称 描述 PostCSS CLI 用于转变样式。 RTLCSS 将 LTR CSS 转换为 RTL，如果你没有 RTL 网站则可选。 Autoprefixer 解析 CSS 并在 Can I Use 规则中添加对应的前缀。 PurgeCSS 移除未使用的 CSS。 NPM 已被包含于 Node.js 安装中，你可以选择局部或全局地安装这些包。\n局部安装 1npm i -D postcss-cli @fullhuman/postcss-purgecss autoprefixer rtlcss 局部安装将依赖写入 package.json，以便部署时通过 npm i 安装这些包，而无需记住这些繁杂的包名。\n全局安装 1sudo npm i -g postcss-cli @fullhuman/postcss-purgecss autoprefixer rtlcss 该命令只需执行一次，后续的 HB 站点无需再次执行此命令。\n两者都是有效的，HB 会优先局部查找需要的包。\n三、HB主题安装 1.克隆仓库 1git clone --depth 1 https://github.com/hbstack/theme blog 2cd blog 其中的 blog 是本地目录名称，请随意修改。\n2.修改模块路径 首先修改位于 go.mod 的模块路径，将其中的 module github.com/hbstack/theme 替换为你的，如：module github.com/user/repo。\n11sed -i -e \u0026#39;s/module\\ github.com\\/hbstack\\/theme/module\\ github.com\\/user\\/repo/\u0026#39; go.mod 3.提交改动到本地仓库 1git add . 2git commit --amend 修改提交信息保存即可，如：First commit。\n4.修改远程仓库 1git remote set-url origin https://github.com/user/repo 5.推送 1git push origin main 四、Hugo 模块代理 Go 官方的模块代理服务器于国内是无法正常使用的。不过可以通过设置代理服务器解决，本文将列出一些可用的 Go 代理服务器。而这也同样适用于 Hugo 模块。\n代理服务器 URL GOPROXY.CN (七牛云) https://goproxy.cn/ GOPROXY.IO https://goproxy.io/ 阿里云 https://mirrors.aliyun.com/goproxy/ 腾讯云 https://mirrors.tencent.com/go/ 下面给出在windows上设置代理服务器的方法：\n1$env:GOPROXY = \u0026#34;https://goproxy.cn/,direct\u0026#34; 2$env:HUGO_MODULE_PROXY = \u0026#34;https://goproxy.cn/,direct\u0026#34; 五、启动 Hugo 服务器 1.安装构建工具 1npm ci 2.启动hugo服务器 于开发模式下预览\n1npm run dev 于生产模式下预览\n1npm run prod package.json文件里面记录了npm所能运行的脚本\n{ \u0026#34;devDependencies\u0026#34;: { \u0026#34;glob\u0026#34;: \u0026#34;^10.3.10\u0026#34;, \u0026#34;prettier\u0026#34;: \u0026#34;^3.0.0\u0026#34;, \u0026#34;prettier-plugin-go-template\u0026#34;: \u0026#34;^0.0.15\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;hugo server -p 7070 --gc --buildDrafts --enableGitInfo\u0026#34;, \u0026#34;prod\u0026#34;: \u0026#34;npm run clean \u0026amp;\u0026amp; hugo server -e production --minify --gc --renderToDisk --disableFastRender --enableGitInfo -b http://localhost:7080 -p 7080\u0026#34;, \u0026#34;docker\u0026#34;: \u0026#34;docker run -v $PWD:/src -p 7070:7070 -p 7071:7071 -p 7072:7072 hugomods/hugo:exts hugo server --bind 0.0.0.0 -p 7070\u0026#34;, \u0026#34;docker-prod\u0026#34;: \u0026#34;docker run -v $PWD:/src -p 7080:7080 -p 7081:7081 -p 7082:7082 hugomods/hugo:exts hugo server --bind 0.0.0.0 -e production --minify --gc --renderToDisk --disableFastRender --enableGitInfo -b http://localhost:7080 -p 7080\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;hugo --gc --minify --enableGitInfo\u0026#34;, \u0026#34;clean\u0026#34;: \u0026#34;del hugo_stats.json \u0026amp;\u0026amp; rmdir /s /q public\u0026#34;, \u0026#34;clean-build\u0026#34;: \u0026#34;npm run clean \u0026amp;\u0026amp; npm run build\u0026#34;, \u0026#34;update\u0026#34;: \u0026#34;hugo mod get -u \u0026amp;\u0026amp; hugo mod tidy\u0026#34;, \u0026#34;translate\u0026#34;: \u0026#34;node ./scripts/translate.js\u0026#34;, \u0026#34;decap-server\u0026#34;: \u0026#34;npx decap-server\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;@fullhuman/postcss-purgecss\u0026#34;: \u0026#34;^5.0.0\u0026#34;, \u0026#34;autoprefix\u0026#34;: \u0026#34;^1.0.1\u0026#34;, \u0026#34;autoprefixer\u0026#34;: \u0026#34;^10.4.13\u0026#34;, \u0026#34;postcss-cli\u0026#34;: \u0026#34;^10.1.0\u0026#34;, \u0026#34;postcss-purgecss\u0026#34;: \u0026#34;^5.0.0\u0026#34;, \u0026#34;rtlcss\u0026#34;: \u0026#34;^4.0.0\u0026#34; } } Hugo Server 生产模式的必要参数\n若需要在生产模式下使用 Hugo Server，需要指定 --disableFastRender 和 --renderToDisk，否则 PurgeCSS 和 PostCSS 会出现意想不到的问题。\n1hugo server \\ 2 --disableFastRender \\ 3 --renderToDisk \\ 4 -e production \\ 5 -b http://localhost:1314 \\ 6 -p 1314 ","date":1708353009,"headings":[{"anchor":"1克隆仓库","title":"1.克隆仓库"},{"anchor":"1安装hugo","title":"1.安装hugo"},{"anchor":"1安装构建工具","title":"1.安装构建工具"},{"anchor":"2修改模块路径","title":"2.修改模块路径"},{"anchor":"2启动hugo服务器","title":"2.启动hugo服务器"},{"anchor":"2安装go","title":"2.安装go"},{"anchor":"3安装git","title":"3.安装git"},{"anchor":"3提交改动到本地仓库","title":"3.提交改动到本地仓库"},{"anchor":"4修改远程仓库","title":"4.修改远程仓库"},{"anchor":"4安装nodejs","title":"4.安装node.js"},{"anchor":"5推送","title":"5.推送"},{"anchor":"一简介","title":"一、简介"},{"anchor":"三hb主题安装","title":"三、HB主题安装"},{"anchor":"二环境安装","title":"二、环境安装"},{"anchor":"五启动-hugo-服务器","title":"五、启动 Hugo 服务器"},{"anchor":"四hugo-模块代理","title":"四、Hugo 模块代理"}],"kind":"page","lang":"zh-hans","series":["hugo博客"],"summary":"本博客平台使用到的技术，hugo和HB框架的安装使用\n","tags":["hugo"],"title":"简介\u0026安装","url":"/hugo%E5%8D%9A%E5%AE%A2/%E7%AE%80%E4%BB%8B%E5%92%8C%E5%AE%89%E8%A3%85/","year":"2024"},{"content":"油猴可以帮你干什么：全网VIP视频，下载全网音乐，右键复制限制解除，百度文库下载……\n一、前提准备：edge浏览器 要下载油猴，那首先不得不提的就是微软2020年发布的新款edge浏览器，edge是真香真香！有了edge再也不用Chrome了。edge浏览器让能登陆微软拓展商店和Chrome拓展商店，可以使用Tampermonkey等等功能丰富的拓展。什么是拓展插件呢，拓展插件就是可以让你个性化定义自己浏览器的工具，让你的浏览器超乎你想象。\nwin10系统的电脑会自带老版edge浏览器，你要把它首先升级到最新版，如果不是win10系统的电脑直接下载最新版edge浏览器就可。升级与下载操作都在edge官方网站上进行即可\n官网上会有这个浏览器的功能介绍，往下翻会有下载或更新入口。下载或更新完成后会在桌面创立一个快捷方式图标\n二、油猴的下载安装 双击桌面图标打开新版edge浏览器后，点击右上角的…，再点击拓展\n我浏览器已经下载了好多插件，所以右侧是满满的，大家的右侧应该是空空如也，点击获取Microsoft Edge拓展即可。\n然后会进入到如下页面\n然后网页下翻找到Tampermonkey\n或者直接搜索Tampermonkey\n点击图标进入后再点击获取\n再点击添加拓展\n成功后浏览器工具栏会出现这个标志\n出现这个图标即是成功安装好了，如果没有出现这个图标的话打开拓展页面，点击右侧开关打开\n这就安装好了脚本管理器，但我们还没有脚本，下一步就是安装相应脚本\n三、脚本的安装使用 一般人会直接给你油猴脚本网站地址去安装相应脚本，但我想先推荐个新建标签的拓展插件，通过这个你可以探索好多好玩有趣的网站\n按同样的方式添加拓展并启用后就可，这个可以自定义你的网址导航主页（要首先关掉电脑管家或杀毒软件的锁定浏览器主页）\n它会推荐很多有用的网址，比如拓展迷等等，也具有十分强大的网址搜索能力，点击右上角的无限符号\n然后搜索油猴脚本，点击打开\n即进入这个网站\n你可以随意查找或搜索自己想要的脚本安装并使用，一般脚本安装页都会有相应脚本的使用方法。我随便点击一个打开，下翻网页即会有使用说明，点击安装此脚本及进入安装页面\n然后点击安装即可\n安装完成后鼠标左键点击油猴图标，点击管理面板，查看相应脚本是否安装成功，是否启用。已启用开关打开即大功告成。\n如果你觉得这上的脚本不能满足你的需求，你也可以自己写脚本来满足自己的特定需求。\n因本人水平有限，只是一点经验之谈，如有错误请多多指教。（懵懂大一计算机学生突发奇想写此博客 ）\n","date":1708002462,"headings":[{"anchor":"一前提准备edge浏览器","title":"一、前提准备：edge浏览器"},{"anchor":"三脚本的安装使用","title":"三、脚本的安装使用"},{"anchor":"二油猴的下载安装","title":"二、油猴的下载安装"}],"kind":"page","lang":"zh-hans","series":["环境配置"],"summary":"","tags":["浏览器"],"title":"油猴脚本管理器的超详细下载安装使用教程——新手必看","url":"/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/%E7%8E%A9%E6%9C%BA%E6%8A%80%E5%B7%A7/%E6%B2%B9%E7%8C%B4%E8%84%9A%E6%9C%AC/","year":"2024"},{"content":"PyTorch环境搭建（windows版）\n首先确定自己电脑上是否有nvidia的显卡（就是游戏显卡RTX3050，RTX3060\u0026hellip;\u0026hellip;这些，必须是nvidia的显卡）\n如果自己电脑上没有显卡，就配置cpu版的pytorch即可。安装cpu版的pytorch参考步骤1，4，如果自己电脑上有gpu,就安装gpu版的pytorch，参考步骤1，2，3。\n1.Anaconda安装 anaconda是python的包管理器，可以很方便的管理不同项目的python环境，解决不同项目python包的环境冲突问题。\nTIPS：我们做python项目时要养成良好的习惯，不同的python项目要采取不同的python虚拟环境，不同的虚拟环境之间相互隔离，python版本和包均不共用。python虚拟环境的创建和管理常用anaconda。 安装步骤： 1、官网下载安装包：https://www.anaconda.com/distribution/ 2、运行并选择安装路径，等待安装完成。(要记得勾选 Add Anaconda to the system PATH environment variable，是为了将Anaconda添加到环境变量中。是的它显示不建议你这样做，但我建议你这样做，要不然还要自己手动把他添加到环境变量里)\n3、查看是否安装成功，cmd中输入conda回车，是否出现如下信息，有则说明安装成功。\n2.CUDA与CuDNN安装 (1)先检查自己的电脑所支持的CUDA版本是多少。 桌面右键点击进去NVIDIA控制面板，找到左下角的系统信息，点击组件，出现如下界面。\n从NVCUDA.DLL 这一行后面的CUDA 11.4说明我的电脑所支持的最高版本是11.4。\n(2)官网下载相对应的CUDA (https://developer.nvidia.com/cuda-toolkit-archive)\n我所支持的版本是11.4，所以我下载的是红色箭头所标出的那行。点击以后出现如下页面，选择第一个下载即可。\n下载完成后，在所在的文件夹下运行安装即可。 然后查看CUDA是否安装成功： cmd中运行到安装的文件目录下：\n1cd C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\bin 然后执行nvcc -V，查看是否出现如下信息，有则说明CUDA安装成功。\n如果输入nvcc -V 出现错误，考虑是否将Anaconds加入环境变量PATH中。\n(3)安装相对应版本的cuDNN。 进入官网： https://developer.nvidia.com/rdp/cudnn-download 需要注册并登录账号（这个需要一段时间），然后选择相对应的版本下载。\n我的是CUDA11.4，所以我选择的是第一个。等待下载完成后进行解压，得到一个cuda文件夹，进入之后，全选，复制到之前CUDA所安装的文件夹下，有重复的进行替换即可。\n查看cuDNN是否安装成功： 步骤如下：（进入安装的路径）\n出现如下Result = PASS 说明cuDNN安装成功。 可以再接着执行deviceQuery.exe，如果出现Result = PASS 说明CUDA和cuDNN都已经安装成功了。\n3.gpu版Pytorch安装 （1）先配置torch环境。 先打开Anaconda Prompt(anaconda)\n下面我们分析一下anaconda prompt每一条命令行的结构。（base）指的是当前所在的python环境是base环境。C:UsersYYF\u0026gt;指的是当前anaconda prompt所在的文件夹位置，我们要执行相关指令只需要在\u0026gt;后面输入指令，回车运行即可。\n然后我们然后输入\n1conda env list 这条语句会显示出当前已存在的python虚拟环境，如果是刚安装anaconda,应该只有一个base基环境。 下面我们新建立一个python虚拟环境(命名为new)\n1conda create –n new python=3.9.10 -n就相当于参数\u0026ndash;name,上面这条语句也可改为conda create \u0026ndash;name python=3.9.10 (这儿python=xxx可以自己指定python版本，这儿的new是你所创建的虚拟环境的名称，大家可以自己取) 然后激活环境： 在anaconda prompt中输入：\n1conda activate new 此时我们可以看到（）里面已经变为new，说明我们已经进入new这个虚拟环境。\n此时再进行python包的安装就是对这个虚拟环境操作，比如我们 pip install numpy（或者 conda install numpy）,再输入\n1conda list # 显示当前虚拟环境的所有包环境 此时我们看到new这个虚拟环境里面已经有numpy这个包了。\n（2）pytorch的安装\n法一：打开pytorch官网：https://pytorch.org/get-started/locally/（pytorch当前建议版本）或者 https://pytorch.org/get-started/previous-versions/ （pytorch的老版本）找到自己所对应版本的使用conda命令安装即可（会慢一些，但建议新手这样做）。\n法二：进入如下网址：https://download.pytorch.org/whl/torch_stable.html，下载自己所需要的torch和torchvision。 可以按快捷键ctrl+F进行搜索。 （不建议新手这样做）\n（3）等待安装完成。 查看pytorch环境是否安装成功：\n要记得先进入之前创建的环境中，然后依次输入蓝色方格中的代码，没有报错，且最后输出True，则说明pytorch环境安装完成。\n4.cpu版PyTorch安装 （1）先配置torch环境。 先打开Anaconda Prompt(anaconda)\n下面我们分析一下anaconda prompt每一条命令行的结构。（base）指的是当前所在的python环境是base环境。C:UsersYYF\u0026gt;指的是当前anaconda prompt所在的文件夹位置，我们要执行相关指令只需要在\u0026gt;后面输入指令，回车运行即可。\n然后我们然后输入\n1conda env list 这条语句会显示出当前已存在的python虚拟环境，如果是刚安装anaconda,应该只有一个base基环境。 下面我们新建立一个python虚拟环境(命名为new)\n1conda create –n new python=3.9.10 -n就相当于参数\u0026ndash;name,上面这条语句也可改为conda create \u0026ndash;name python=3.9.10 (这儿python=xxx可以自己指定python版本，这儿的new是所创建的虚拟环境的名称) 然后激活环境： 在anaconda prompt中输入：\n1conda activate new 此时我们可以看到（）里面已经变为new，说明我们已经进入new这个虚拟环境。\n此时再进行python包的安装就是对这个虚拟环境操作，比如我们 pip install numpy（或者 conda install numpy）,再输入\n1conda list # 显示当前虚拟环境的所有包环境 此时我们看到new这个虚拟环境里面已经有numpy这个包了。\n（2）pytorch的安装\n打开pytorch官网：https://pytorch.org/get-started/locally/（pytorch当前建议版本）或者 https://pytorch.org/get-started/previous-versions/ （pytorch的老版本）找到自己所对应版本的使用conda命令安装即可（会慢一些，但建议新手这样做）。\n（3）等待安装完成。 查看pytorch环境是否安装成功：\n要记得先进入之前创建的环境中，然后依次输入蓝色方格中的代码，没有报错，则说明pytorch环境安装完成。\n参考资料： 深度学习 | NVIDIA 开发者 浅析三种Anaconda虚拟环境创建方式和第三方包的安装-腾讯云开发者社区-腾讯云 (tencent.com) 《PyTorch深度学习实践》完结合集_哔哩哔哩_bilibili PyTorch\n","date":1707985156,"headings":[{"anchor":"1anaconda安装","title":"1.Anaconda安装"},{"anchor":"1先检查自己的电脑所支持的cuda版本是多少","title":"(1)先检查自己的电脑所支持的CUDA版本是多少。"},{"anchor":"2cuda与cudnn安装","title":"2.CUDA与CuDNN安装"},{"anchor":"2官网下载相对应的cuda","title":"(2)官网下载相对应的CUDA"},{"anchor":"3gpu版pytorch安装","title":"3.gpu版Pytorch安装"},{"anchor":"3安装相对应版本的cudnn","title":"(3)安装相对应版本的cuDNN。"},{"anchor":"4cpu版pytorch安装","title":"4.cpu版PyTorch安装"}],"kind":"page","lang":"zh-hans","series":["环境配置"],"summary":"","tags":["pytorch"],"title":"Pytorch安装教程","url":"/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/python/pytorch%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/","year":"2024"},{"content":"在使用github等网站时，我们有时会遇到访问不稳定或无法访问的问题。这时，很多人会选择使用代理来解决问题。但挂上代理之后，我们仍然可能会遇到一个新问题：在命令行中进行下载或配置时，网络问题依然存在。比如，使用pip进行软件包的下载和安装（pip install -r requirements.txt），或者使用git进行代码的下载(git clone ,git push)，都可能因为网络问题而受阻。在我确认已经打开了全局代理的情况下，仍然出现了网络问题，这说明使用命令行进行的操作并没有走代理。\n有三种常用方式：\n①永久设置： linux系统下：\n1vim /etc/profile： 2 export http_proxy=\u0026#39;http://代理服务器IP:端口号\u0026#39; 3 export https_proxy=\u0026#39;http://代理服务器IP:端口号\u0026#39; 4source /etc/profile windows系统下：\n在C:\\User\\用户目录下，新建pip文件夹，然后在该文件夹下新建pip.ini文件。填写如下内容：\n1[global] 2index-url = https://pypi.tuna.tsinghua.edu.cn/simple 3proxy = http://XXXX.com:port 4[install] 5trusted-host=pypi.tuna.tsinghua.edu.cn ②临时设置（重连后失效）： 可以直接在此次命令行窗口运行:\n1export http_proxy=\u0026#39;http://代理服务器IP:端口号\u0026#39; 2export https_proxy=\u0026#39;http://代理服务器IP:端口号\u0026#39; 注意：设置之后可能使用ping时还是无法连接外网，但是pip时可以的，因为ping的协议不一样不能使用这个代理\n③单次设置： 直接在pip时设置代理也是可以的：\n1pip install -r requirements.txt --proxy=代理服务器IP:端口号 ","date":1707984496,"headings":[{"anchor":"临时设置重连后失效","title":"②临时设置（重连后失效）："},{"anchor":"单次设置","title":"③单次设置："},{"anchor":"永久设置","title":"①永久设置："}],"kind":"page","lang":"zh-hans","series":["环境配置"],"summary":"","tags":["python"],"title":"Pip设置代理","url":"/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/python/pip%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/","year":"2024"},{"content":"一、操作系统的基本概念 1. 操作系统的特征 (1)并发 并发：同一时间间隔内发生 并行：同一时刻发生 并发，并行的区别辨析非常重要 (2)共享(资源共享方式) 互斥共享 一段时间内只允许一个进程访问该资源（打印机、磁带机） 临界资源（独占资源）：一段时间内只允许一个进程访问的资源 同时访问 一段时间内允许多个进程访问该资源（磁盘、可重入代码） (3)虚拟 空分复用技术是指在物理内存（主存）不够用时，通过将部分数据暂时存储到磁盘上的虚拟内存中，从而在逻辑上扩展了存储器的容量。这样，多个程序可以共享物理内存，每个程序都认为自己拥有连续的、足够的内存空间，而实际上它们的地址空间是交叉存储的，这种技术使得多个程序可以同时运行，而不会相互干扰。 时分复用技术是指将时间分片，轮流分给各个用户或者进程使用，通常用于处理器的分配，如多道程序设计中的时间共享，允许操作系统在很短的时间内切换多个任务，使得每个任务都感觉自己在连续不断地使用处理器。\n总结来说，虚拟存储器使用的是空分复用技术，而虚拟处理机使用的是时分复用技术。\n复用技术 示例 时分复用技术 虚拟处理机（多道程序并发执行分时使用一个处理器）、虚拟设备（spooling技术将一台物理设备虚拟为多台逻辑设备，从而将独占设备变为共享设备） 空分复用技术 虚拟存储器（从逻辑上扩展了存储器的容量） 实际上虚拟存储器既用了时分复用技术，又用了空分复用技术。 空分复用技术体现在虚拟存储器允许将物理内存（RAM）和磁盘存储（通常是硬盘）结合起来使用，形成一个连续的、统一的地址空间。这样，程序的地址空间可以远远大于实际的物理内存大小，因为不常用的数据可以暂时存储在磁盘上，只在需要时才加载到内存中。这种技术使得多个程序可以共享有限的物理内存资源，提高了内存的使用效率。 时分复用技术体现在虚拟存储器的管理上。由于物理内存的大小是有限的，操作系统需要不断地在内存中的程序和数据之间进行切换，以保持所有活动程序的进展。这种切换类似于时分复用技术中的时间片轮转，只不过它是基于内存页面的换入和换出，而不是基于CPU时间片的切换。操作系统会根据程序的访问模式和内存需求，动态地将内存页面在物理内存和磁盘之间移动，这要求操作系统具有高效的数据换入换出算法，如LRU（最近最少使用）算法等。 因此，虚拟存储器同时利用了空分复用技术来扩展地址空间，以及时分复用技术来有效管理有限的物理内存资源。这两种技术的结合，使得虚拟存储器能够提供大容量的地址空间，并且高效地使用有限的物理内存 (4)异步 进程走走停停，以人们不可预知的速度推进 2. 操作系统的目标和功能 （1）计算机系统资源的管理者\n处理机管理、存储器管理、文件管理、设备管理（后面章节细讲） （2）用户与计算机硬件系统的接口\n接口类型 接口子类型 描述 适用场景 用户接口 联机用户接口 一次一句 分时系统、实时系统 用户接口 脱机用户接口 一次一批 批处理系统 用户接口 图形用户接口 使用图形元素（如按钮、窗口）进行交互 个人电脑、图形界面操作系统 程序接口 是用户程序取得操作系统服务的唯一途径，由一组系统调用（广义指令）组成 所有需要操作系统服务的用户程序 （3）对计算机资源的扩充\n没有任何软件的计算机称为裸机；覆盖了软件的计算机称为扩充机器或虚拟机 二、操作系统发展历程 1. 手工操作阶段 程序的装入、运行、结果的输出等所有工作都需要人工干预，资源利用率低，CPU利用不充分 2. 批处理系统 ———\u0026lt;br\u0026gt; 单道批处理系统 多道批处理系统 前提 - 中断技术和通道技术，让CPU和外设能并行工作（2016） 特点 1.自动性：磁带上的一批作业能自动逐个运行\n2.顺序性：磁带上的作业顺序进入内存执行完成\n3.单道性：内存中仅有一道程序运行 1.多道性：内存中有多道程序交替运行`\n2.宏观上并行，微观上串行 优点 相比手工操作系统提高了资源利用率 资源利用率高、CPU利用充分、系统吞吐量大（2017） 缺点 资源利用率还是低 用户响应时间长，不提供人机交互能力（相比于分时系统而言） 3. 分时操作系统 定义：把处理器的运行时间分片，按时间片轮流把处理器分配给各个作业使用 特点：人机交互，多用户共享主机，响应速度快 4. 实时操作系统 目标：及时性、可靠性 特点：资源利用率较低、一般使用高优先级抢占式调度算法 分类 硬实时系统（工业、武器、飞行器控制） 软实时任务（飞机订票系统、银行管理系统、信息查询系统） 5. 网络操作系统、分布式计算机系统、个人操作系统 略微了解 三、操作系统运行环境 1. 处理器运行模式 (1)指令类别\n指令类别 描述 示例 特权指令 不允许用户直接使用的指令 I/O指令、置中断、设置系统时间、存取用于内存保护的寄存器、清理内存、修改权限、进程切换 非特权指令 在用户态可以运行的指令 读写内存、算术运算、命令解释程序 寄存器清零无法判断是特权指令还是非特权指令 (2)CPU运行模式\nCPU运行模式 运行的程序和指令类别 用户态（目态） 用户自编程序和非特权指令运行在用户态 内核态（管态、核心态） 操作系统内核程序和特权指令运行在内核态 (3)转换\n内核态\u0026ndash;\u0026gt;用户态 执行一条特权指令——修改PSW的标志位为“用户态”，这个动作意味着操作系统将主动让出CPU使用权 用户态\u0026ndash;\u0026gt;内核态 由“中断”引发，硬件自动完成变态过程，触发中断信号意味着操作系统将强行夺回CPU的使用权 (4)时钟管理\n向用户提供标准的系统时间 分时系统中时间片轮转调度 实时系统中按截止时间控制运行 批处理系统中衡量一个作业的运行程度 (5)中断机制\n子程序调用只保存PC;中断程序需要保存PC和PSW（2012） 由硬件找到中断向量表，但中断向量表的初始化由操作系统完成（2020） (6)原语操作\n由若干指令组成的、用于完成一定功能的一个过程 执行过程中不允许被中断（可以通过关中断方法实现） 原子操作在系统态下执行，常驻内存 2. 中断和异常的概念 (1)内部异常\n分类方式 类别 描述 示例 发生原因 硬故障中断 硬件线路出现异常 电源掉电、存储器线路错误 发生原因 程序性异常 CPU执行某个指令引起 溢出、地址越界、整数除零、非法指令、时间片中断、单步跟踪 报告和返回方式 故障 操作系统检测到的错误 非法操作码、缺段缺页、整数除零、保护错 报告和返回方式 陷入 程序执行到特定点时故意引发的中断 程序调试断点、系统调用（用户程序的I/O请求）、条件自陷指令 报告和返回方式 终止 需要操作系统进行干预来停止程序的执行的中断 电源掉电、线路故障 (2)中断（外中断）\n示例：I/O设备中断、定时器到时、时钟中断、打印机缺纸、磁盘缓冲满\n阶段 操作 详情 硬件完成 关中断 防止其他中断打断当前中断的处理过程 保存断点（PC和PSW） 记录下被中断的程序计数器和程序状态字 识别中断源 确定是哪个设备或事件触发了中断 操作系统完成 保护现场（寄存器信息） 保存当前执行的程序的寄存器值，以便中断服务完成后能够恢复 屏蔽字 根据需要设置屏蔽字，控制哪些中断可以被响应，哪些需要被忽略 执行中断服务程序 调用相应的中断处理程序来响应和处理中断请求 中断和异常的概念辨析非常重要！！！异常和中断是操作系统处理意外或特定事件时使用的两种机制，它们有一些关键的区别： 来源不同： 中断（Interrupt）通常是由外部设备发出的信号，通知CPU有一个需要立即处理的紧急事件。例如，当用户输入数据时，键盘会产生一个中断信号。 异常（Exception）是由CPU在执行内部指令时产生的，通常是因为内部错误或程序执行了某些特殊的指令（如系统调用）。异常是同步发生的，即在指令执行期间或之后立即被识别和处理的。 处理方式不同： 中断通常是异步的，它们的处理程序需要能够处理随机发生的中断，并且在处理中断时可能需要保存当前处理的上下文（如程序计数器和其他寄存器的值），以便之后能够恢复被中断的任务。 异常是同步的，它们在特定的指令执行时被触发，操作系统在处理异常时通常不需要保存和恢复上下文，因为异常是在控制流顺序中的。 类型划分不同： 中断可以分为可屏蔽中断和非可屏蔽中断。可屏蔽中断可以被CPU忽略，而非可屏蔽中断则必须立即处理。 异常可以分为多种类型，如硬件故障导致的故障、程序执行了非法操作码导致的陷阱、程序请求操作系统服务时的系统调用等。 目的不同： 中断的目的是为了响应外部事件，如I/O请求、时钟信号等。 异常的目的是为了处理程序执行中的错误或特殊请求。 总的来说，中断和异常都是操作系统用来处理不同类型事件的重要机制，它们在处理时机、来源和处理方式上有所不同。操作系统需要通过合理地处理这些事件来保证系统的稳定性和响应性。 总结为如下表格：\n特征 中断 异常 来源 外部设备信号 CPU执行指令时产生的内部事件 发生方式 异步 同步 处理方式 需保存和恢复上下文 通常不需要保存和恢复上下文 类型 可屏蔽/非可屏蔽 故障、陷阱、系统调用等 目的 响应外部事件（如I/O请求、时钟信号） 处理程序执行中的错误或特殊请求 3. 系统调用(广义指令) 系统调用过程 （传递调用参数、执行陷入指令、执行服务程序、返回用户态） 特点 系统调用是操作系统提供给应用程序的接口（2010、2019） 每个系统有许多系统调用，每个系统调用有唯一的系统调用号 一个操作系统所有的系统调用都通过一个中断入口来实现，不同操作系统为用户提供的系统调用接口不同（2019） 在执行系统调用服务程序的过程中，CPU处于内核态（2019） 系统调用只能通过用户程序间接使用 访管指令 名称：访管指令、陷入指令、trap指令 在用户态使用，不是特权指令，用户程序借此发起系统调用 广义指令的调用可能在用户态，但执行一定在内核态 四、操作系统结构 五、操作系统引导 步骤描述：\n①激活CPU。激活的CPU读取 ROM中的 boot（自举）程序，开始执行BIOS的指令 ②硬件自检。启动BIOS程序后，先进行硬件自检，检查硬件是否出现故障 ③加载带有操作系统的硬盘。BIOS读取Boot Sequence，然后CPU将存储设备引导扇区的内容加载到内存中 ④加载主引导记录 MBR。轮流查找引导硬盘（主引导记录MBR的作用是告诉CPU去硬盘的哪个主分区去找操作系统） ⑤扫描硬盘分区表并加载硬盘活动分区。主引导记录扫描硬盘分区表，识别并加载含有操作系统的硬盘分区（活动分区) ⑥加载分区引导记录PBR。读取分区引导记录(PBR)，其作用是寻找并激活分区根目录下用于引导操作系统的启动管理器 ⑦加载启动管理器。分区引导记录搜索活动分区中的启动管理器，加载启动管理器 ⑧加载操作系统到内存RAM（2013） 引导程序分为两种，分别是位于ROM中的自举程序和位于引导扇区的启动管理器。 操作系统引导只是将操作系统内核加载到内存，其它部分仅在需要时才调入。 六、虚拟机 虚拟内核态：虚拟机上的操作系统认为自己运行在内核态（并不是）\n用户态：虚拟机中的用户进程认为自己运行在用户态（确实是）\n描述\n虚拟机可以用软件实现也可以用硬件实现 虚拟机是运行在计算机中的一个应用程序 真实硬件不会执行虚拟机中的敏感指令 ","date":1707845958,"headings":[{"anchor":"1-处理器运行模式","title":"1. 处理器运行模式"},{"anchor":"1-手工操作阶段","title":"1. 手工操作阶段"},{"anchor":"1-操作系统的特征","title":"1. 操作系统的特征"},{"anchor":"1并发","title":"(1)并发"},{"anchor":"2-中断和异常的概念","title":"2. 中断和异常的概念"},{"anchor":"2-批处理系统","title":"2. 批处理系统"},{"anchor":"2-操作系统的目标和功能","title":"2. 操作系统的目标和功能"},{"anchor":"2共享资源共享方式","title":"(2)共享(资源共享方式)"},{"anchor":"3-分时操作系统","title":"3. 分时操作系统"},{"anchor":"3-系统调用广义指令","title":"3. 系统调用(广义指令)"},{"anchor":"3虚拟","title":"(3)虚拟"},{"anchor":"4-实时操作系统","title":"4. 实时操作系统"},{"anchor":"4异步","title":"(4)异步"},{"anchor":"5-网络操作系统分布式计算机系统个人操作系统","title":"5. 网络操作系统、分布式计算机系统、个人操作系统"},{"anchor":"一操作系统的基本概念","title":"一、操作系统的基本概念"},{"anchor":"三操作系统运行环境","title":"三、操作系统运行环境"},{"anchor":"二操作系统发展历程","title":"二、操作系统发展历程"},{"anchor":"五操作系统引导","title":"五、操作系统引导"},{"anchor":"六虚拟机","title":"六、虚拟机"},{"anchor":"四操作系统结构","title":"四、操作系统结构"}],"kind":"page","lang":"zh-hans","summary":"","tags":["操作系统"],"title":"第一章：操作系统引论","url":"/408/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%AC%AC%E4%B8%80%E7%AB%A0%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%BC%95%E8%AE%BA/","year":"2024"},{"content":"anaconda下载地址（官网）：\nFree Download | Anaconda\n一、创建Anaconda虚拟环境 步骤1：打开Anaconda Prompt (终端) 首先，在Windows系统中，通过开始菜单或搜索找到“Anaconda Prompt”，在Mac或Linux系统中，可以在终端中直接操作。\n步骤2：创建虚拟环境 在命令行界面输入以下命令来创建一个新的虚拟环境。这里以创建一个名为 my_project_env，并指定Python版本为3.9.10（请根据实际情况替换）的环境为例：\n1conda create --name my_project_env python=3.9.10 注意：此处——name和—n等效\n解决创建环境时出现的： Collecting package \u0026hellip; failed\n创建环境时，可能会出现以下问题\n问题分析：因为网络问题导致的创建失败\n解决方法：多试几次，仍然失败更换国内镜像源\n找到C盘用户文件夹下的.condarc文件 \\2. 编辑.condarc文件，替换成以下内容，保存，重新打开cmd即可\n1ssl_verify: true 2channels: 3 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/win-64/ 4 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/win-64 show_channel_urls: true 此方法直接更换成了清华源，速度更快，更稳，通过conda向虚拟环境安装第三方包时，用的也是清华源。\n步骤3：激活虚拟环境 虚拟环境创建完成后，需要激活它以便在该环境中执行后续操作。激活环境的命令如下：\n1conda activate my_project_env 当你成功激活虚拟环境后，命令行提示符前通常会显示当前活动环境的名称，例如 (my_project_env)。\n查看所有虚拟环境的命令：\n1conda env list 二、在虚拟环境中安装第三方包 方法1：使用Conda安装 对于那些在Conda仓库中存在的包，你可以直接用 conda install 命令进行安装。例如，要安装numpy库：\n1conda install numpy 方法2：使用pip安装 对于Conda仓库中没有或者你想从PyPI获取的包，可以使用 pip 在虚拟环境中安装：\n1pip install pandas pip安装速度过慢时，可以将pip更换为国内镜像源：\n安装特定版本的包 如果需要安装特定版本的第三方包，只需在包名后面加上版本号即可：\n1conda install scipy=1.7.3 # 使用conda安装Scipy的1.7.3版本 2pip install tensorflow==2.8.0 # 使用pip安装TensorFlow的2.8.0版本 三、检查已安装的包 安装完成后，可以通过下面的命令查看虚拟环境中已经安装的所有包及其版本信息：\n1conda list 或者使用pip列出所有已安装的pip包：\n1pip list 四、关闭/退出虚拟环境 当完成工作并希望回到系统默认Python环境时，执行以下命令：\n1conda deactivate 至此，您已成功地使用Anaconda创建了一个虚拟环境，并在其中安装了所需的第三方包。这种做法有助于保持项目之间的依赖独立，使得代码更易于管理和部署。\n五、删除虚拟环境 当某个项目完成或者不再需要某个虚拟环境时，可以使用以下命令将其彻底删除：\n1conda remove --name my_project_env --all 这里的 my_project_env 是你想要删除的虚拟环境名称。执行上述命令后，Anaconda将会从系统中移除该虚拟环境及其所有安装的包和配置文件。\n注意事项：\n删除操作不可逆，请在执行此命令前确保您确实不再需要该虚拟环境中的任何内容。 确认环境名称无误，避免误删其他正在使用的虚拟环境。 请根据实际需求和最新版Anaconda的更新情况调整上述命令中的具体版本信息。\n","date":1707845958,"headings":[{"anchor":"一创建anaconda虚拟环境","title":"一、创建Anaconda虚拟环境"},{"anchor":"三检查已安装的包","title":"三、检查已安装的包"},{"anchor":"二在虚拟环境中安装第三方包","title":"二、在虚拟环境中安装第三方包"},{"anchor":"五删除虚拟环境","title":"五、删除虚拟环境"},{"anchor":"四关闭退出虚拟环境","title":"四、关闭/退出虚拟环境"},{"anchor":"安装特定版本的包","title":"安装特定版本的包"},{"anchor":"方法1使用conda安装","title":"方法1：使用Conda安装"},{"anchor":"方法2使用pip安装","title":"方法2：使用pip安装"},{"anchor":"步骤1打开anaconda-prompt-终端","title":"步骤1：打开Anaconda Prompt (终端)"},{"anchor":"步骤2创建虚拟环境","title":"步骤2：创建虚拟环境"},{"anchor":"步骤3激活虚拟环境","title":"步骤3：激活虚拟环境"}],"kind":"page","lang":"zh-hans","series":["环境配置"],"summary":"","tags":["python"],"title":"使用Anaconda管理python虚拟环境与安装第三方包","url":"/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/python/%E4%BD%BF%E7%94%A8anaconda%E8%BD%BB%E6%9D%BE%E7%AE%A1%E7%90%86python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E4%B8%8E%E5%AE%89%E8%A3%85%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85/","year":"2024"},{"content":"1.临时换源： 清华源\n1pip install xxxx -i https://pypi.tuna.tsinghua.edu.cn/simple 阿里源\n1pip install xxxx -i https://mirrors.aliyun.com/pypi/simple/ 腾讯源\n1pip install xxxx -i http://mirrors.cloud.tencent.com/pypi/simple 豆瓣源\n1pip install xxxx -i http://pypi.douban.com/simple/ 将xxxx换成需要安装的包的名字\n2.永久换源： 清华源\n1pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple 阿里源\n1pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/ 腾讯源\n1pip config set global.index-url http://mirrors.cloud.tencent.com/pypi/simple 豆瓣源\n1pip config set global.index-url http://pypi.douban.com/simple/ 3.换回默认源 1pip config unset global.index-url ","date":1707844801,"headings":[{"anchor":"1临时换源","title":"1.临时换源："},{"anchor":"2永久换源","title":"2.永久换源："},{"anchor":"3换回默认源","title":"3.换回默认源"}],"kind":"page","lang":"zh-hans","series":["环境配置"],"summary":"","tags":["python"],"title":"pip修改国内镜像源（临时/永久）","url":"/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/python/pip%E6%8D%A2%E6%BA%90/","year":"2024"},{"content":"1091促销计算 题目描述\nTime Limit: 1000 ms\nMemory Limit: 256 mb\n某百货公司为了促销，采用购物打折的优惠方法，每位顾客一次购物：在1000元以上者，按9.5折优惠；在2000以上者，按9折优惠；在3000以上者，按8.5折优惠；在5000以上者，按8折优惠；编写程序，购物款数，计算并输出优惠价。\n输入描述:\n1如题 输出描述:\n1如题 输入样例:\n1850 21230 35000 43560 输出样例:\n1discount=1,pay=850 2discount=0.95,pay=1168.5 3discount=0.8,pay=4000 4discount=0.85,pay=3026 1#include\u0026lt;bits/stdc++.h\u0026gt; 2using namespace std; 3int main(){ 4\tint price; 5\twhile(cin\u0026gt;\u0026gt;price){ 6 if(price\u0026lt;1000){ 7 cout\u0026lt;\u0026lt;\u0026#34;discount=1,pay=\u0026#34;\u0026lt;\u0026lt;price; 8 } 9 else if(price\u0026lt;2000){ 10 cout\u0026lt;\u0026lt;\u0026#34;discount=0.95,pay=\u0026#34;\u0026lt;\u0026lt;price*0.95; 11 } 12 else if(price\u0026lt;3000){ 13 cout\u0026lt;\u0026lt;\u0026#34;discount=0.9,pay=\u0026#34;\u0026lt;\u0026lt;price*0.9; 14 } 15 else if(price\u0026lt;5000){ 16 cout\u0026lt;\u0026lt;\u0026#34;discount=0.85,pay=\u0026#34;\u0026lt;\u0026lt;price*0.85; 17 } 18 else{ 19 cout\u0026lt;\u0026lt;\u0026#34;discount=0.8,pay=\u0026#34;\u0026lt;\u0026lt;price*0.8; 20 } 21\t} 22 return 0; 23} 1133求1到n的和 题目描述\nTime Limit: 1000 ms\nMemory Limit: 256 mb\n输入一个整数n，请你求出1+2+3+4+\u0026hellip;.+n的和是多少？\n输入描述:\n1输入一个整数n 输出描述:\n1输出1到n的和是多少 2n\u0026lt;=100 输入样例:\n15 输出样例:\n115 1#include\u0026lt;iostream\u0026gt; 2using namespace std; 3int main(){ 4 int n,sum=0; 5 while(cin\u0026gt;\u0026gt;n){ 6 sum+=n; 7 while(n--){ 8 sum+=n; 9 } 10 cout\u0026lt;\u0026lt;sum; 11 } 12 return 0; 13} 1043计算Sn 题目描述\nTime Limit: 1000 ms\nMemory Limit: 256 mb\n求Sn=a+aa+aaa+…+aa…aaa（有n个a）之值，其中a是一个数字。 例如：2+22+222+2222+22222（n=5），\n输入描述:\n1输入两个数．第一个为a ，第二个为n（表示有多少个数相加），其中a和n都是大于１且小于１０的整数． 输出描述:\n输出其和． 输入样例:\n12 5 输出样例:\n124690 1#include\u0026lt;iostream\u0026gt; 2#include\u0026lt;math.h\u0026gt; 3using namespace std; 4int main(){ 5 int a,n,sum; 6 while(cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;n){ 7 sum=0; 8 for(int i=0;i\u0026lt;n;i++){ 9 sum+=a*pow(10,i)*(n-i); 10 } 11 cout\u0026lt;\u0026lt;sum; 12 } 13 return 0; 14} 1040利润提成 题目描述\nTime Limit: 1000 ms\nMemory Limit: 256 mb\n企业发放的奖金根据利润提成。利润低于或等于100000元的，奖金可提10%;\n利润高于100000元，低于200000元（100000\u0026lt;I≤200000）时，低于100000元的部分按10％提成，高于100000元的部分，可提成 7.5%;\n200000\u0026lt;I≤400000时，低于200000元部分仍按上述办法提成，（下同），高于200000元的部分按5％提成；\n400000\u0026lt;I≤600000元时，高于400000元的部分按3％提成；600000\u0026lt;I≤1000000时，高于600000元的部分按1.5%提成；\nI\u0026gt;1000000时，超过1000000元的部分按1%提成。从键盘输入当月利润I,求应发奖金总数。\n输入描述:\n1一个整数，当月利润。 输出描述:\n1一个整数，奖金。 输入样例:\n1900 输出样例:\n190 1#include\u0026lt;iostream\u0026gt; 2using namespace std; 3int main(){ 4 long long profile, adware; 5 while(cin \u0026gt;\u0026gt; profile){ 6 if(profile \u0026lt;= 100000){ 7 adware = profile * 0.1; 8 } 9 else if(profile \u0026lt;= 200000){ 10 adware = 10000 + (profile - 100000) * 0.075; 11 } 12 else if(profile \u0026lt;= 400000){ 13 adware = 10000 + 7500 + (profile - 200000) * 0.05; 14 } 15 else if(profile \u0026lt;= 600000){ 16 adware = 10000 + 7500 + 10000 +(profile-400000) * 0.03; 17 } 18 else if(profile \u0026lt;= 1000000){ 19 adware = 10000 + 7500 + 10000 + 200000 * 0.03 + (profile - 600000) * 0.015; 20 } 21 else{ 22 adware = 10000 + 7500 + 10000 + 200000 * 0.03 + 400000 * 0.015 + (profile - 1000000) * 0.01; 23 } 24 cout\u0026lt;\u0026lt;adware; 25 } 26 return 0; 27} 1722身份证校验 题目描述\nTime Limit: 1000 ms\nMemory Limit: 256 mb\n身份证号的校验身份证号码共18位，最后一位是校验位。 A[18] : aaaaaabbbbbbbbccc d\n校验的规则如下： 身份证的前十七位数字和对应的权值相乘后相加后所得的和对11取余的余数与校验位（身份证最后一位）相同则身份证合法。\n前十七位的权值分别是：7 9 10 5 8 4 2 1 6 3 7 9 10 5 8 4 2\n余数x和校验位y的对应规则对应如下：\nx:0 1 2 3 4 5 6 7 8 9 10\ny:1 0 x 9 8 7 6 5 4 3 2\n输入描述:\n1多组数据输入 2输入身份证号码 输出描述:\n1如果所输入身份证号码合法，输出ID Corrent，否则输出ID Wrong。 输入样例:\n11222222222 211111111111111111111 3341181198809150011 411010119900307387X 5150102199003075131 6150102200003075131 输出样例:\n1ID Wrong 2ID Wrong 3ID Corrent 4ID Corrent 5ID Corrent 6ID Wrong 1#include\u0026lt;iostream\u0026gt; 2#include\u0026lt;array\u0026gt; 3using namespace std; 4string id; 5 6array\u0026lt;int,17\u0026gt; wg = {7,9,10,5,8,4,2,1,6,3,7,9,10,5,8,4,2}; 7array\u0026lt;char,11\u0026gt; val = {\u0026#39;1\u0026#39;,\u0026#39;0\u0026#39;,\u0026#39;X\u0026#39;,\u0026#39;9\u0026#39;,\u0026#39;8\u0026#39;,\u0026#39;7\u0026#39;,\u0026#39;6\u0026#39;,\u0026#39;5\u0026#39;,\u0026#39;4\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;2\u0026#39;}; 8 9bool check(string s){ 10 if(s.size()!=18){ 11 return false; 12 } 13 int weight=0; 14 for(int i=0;i\u0026lt;s.size()-1;i++){ 15 weight+=(s[i]-\u0026#39;0\u0026#39;)*wg[i]; 16 } 17 18 if(val[weight%11]==s[17]){ 19 return true; 20 } 21 else{ 22 return false; 23 } 24} 25 26int main(){ 27 while(cin\u0026gt;\u0026gt;id){ 28 if(check(id)){ 29 cout\u0026lt;\u0026lt;\u0026#34;ID Corrent\u0026#34;\u0026lt;\u0026lt;endl; 30 } 31 else{ 32 cout\u0026lt;\u0026lt;\u0026#34;ID Wrong\u0026#34;\u0026lt;\u0026lt;endl; 33 } 34 } 35} ","date":-62135596800,"headings":[{"anchor":"1040利润提成","title":"1040利润提成"},{"anchor":"1043计算sn","title":"1043计算Sn"},{"anchor":"1091促销计算","title":"1091促销计算"},{"anchor":"1133求1到n的和","title":"1133求1到n的和"},{"anchor":"1722身份证校验","title":"1722身份证校验"}],"kind":"page","lang":"zh-hans","summary":"","title":"简单模拟","url":"/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E5%85%A5%E9%97%A8%E7%BB%8F%E5%85%B8/%E7%AE%80%E5%8D%95%E6%A8%A1%E6%8B%9F/","year":"0001"}]